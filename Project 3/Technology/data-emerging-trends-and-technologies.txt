Data: Emerging Trends and Technologies Make Data Work strataconf.com Presented by OReilly and Cloudera, Strata + Hadoop World is where cutting-edge data science and new business fundamentals intersect and merge. n Learn business applications of data technologies n Develop new skills through trainings and in-depth tutorials n Connect with an international community of thousands who work with data Job # 15420 http://strataconf.com?cmp=pd-data-confreg-lp-na_free_report_ad Alistair Croll Data: Emerging Trends and Technologies How sensors, fast networks, AI, and distributed computing are affecting the data landscape 978-1-491-92073-2 [LSI] Data: Emerging Trends and Technologies by Alistair Croll Copyright  2015 OReilly Media, Inc. All rights reserved. Printed in the United States of America. Published by OReilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472. OReilly books may be purchased for educational, business, or sales promotional use. Online editions are also available for most titles ( http://safaribooksonline.com ). For more information, contact our corporate/institutional sales department: 800-998-9938 or corporate@oreilly.com . Editor: Tim McGovern Interior Designer: David Futato Cover Designer: Karen Montgomery December 2014: First Edition Revision History for the First Edition 2014-12-12: First Release The OReilly logo is a registered trademark of OReilly Media, Inc. Data: Emerging Trends and Technologies, the cover image, and related trade dress are trademarks of OReilly Media, Inc. Many of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks. Where those designations appear in this book, and OReilly Media, Inc. was aware of a trademark claim, the designations have been printed in caps or initial caps. While the publisher and the author(s) have used good faith efforts to ensure that the information and instructions contained in this work are accurate, the publisher and the author(s) disclaim all responsibility for errors or omissions, including without limitation responsibility for damages resulting from the use of or reliance on this work. Use of the information and instructions contained in this work is at your own risk. If any code samples or other technology this work contains or describes is sub ject to open source licenses or the intellectual property rights of others, it is your responsibility to ensure that your use thereof complies with such licenses and/or rights. http://safaribooksonline.com Table of Contents Introduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . vii Cheap Sensors, Fast Networks, and Distributed Computing. . . . . . . . 1 Clouds, edges, fog, and the pendulum of distributed computing 1 Machine learning 2 Computational Power and Cognitive Augmentation. . . . . . . . . . . . . . 5 Deciding better 5 Designing for interruption 6 The Maturing Marketplace. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 Graph theory 9 Inside the black box of algorithms: whither regulation? 9 Automation 10 Data as a service 11 The Promise and Problems of Big Data. . . . . . . . . . . . . . . . . . . . . . . . . 13 Solving the big problems 13 The death spiral of prediction 14 Sensors, sensors everywhere 15 v Introduction Now in its fifth year, the Strata + Hadoop World conference has grown substantially from its early days. Its expanded to cover not only how we handle the flood of data our modern lives create, but also how that data is collected, governed, and acted upon. Strata now deals with sensors that gather, clean, and aggregate infor mation in real time, as well as machine learning and specialized data tools that make sense of such data. And it tackles the issue of inter faces by which that sense is conveyed, whether theyre informing a human or directing a machine. In this ebook, Strata + Hadoop World co-chair Alistair Croll dis cusses the emerging trends and technologies that will transform the data landscape in the months to come. These ideas relate to our investigation into the forces shaping the big data space, from cogni tive augmentation to artificial intelligence. vii http://strataconf.com/ http://radar.oreilly.com/2014/10/big-datas-big-ideas.html Cheap Sensors, Fast Networks, and Distributed Computing The trifecta of cheap sensors, fast networks, and distributing com puting are changing how we work with data. But making sense of all that data takes help, which is arriving in the form of machine learn ing. Heres one view of how that might play out. Clouds, edges, fog, and the pendulum of distributed computing The history of computing has been a constant pendulum, swinging between centralization and distribution. The first computers filled rooms, and operators were physically within them, switching toggles and turning wheels. Then came mainframes, which were centralized, with dumb terminals. As the cost of computing dropped and the applications became more democratized, user interfaces mattered more. The smarter cli ents at the edge became the first personal computers; many broke free of the network entirely. The client got the glory; the server merely handled queries. Once the web arrived, we centralized again. LAMP (Linux, Apache, MySQL, PHP) buried deep inside data centers, with the computer at the other end of the connection relegated to little more than a smart terminal rendering HTML. Load-balancers sprayed traffic across thousands of cheap machines. Eventually, the web turned from static sites to complex software as a service (SaaS) applications. 1 Then the pendulum swung back to the edge, and the clients got smart again. First with AJAX, Java, and Flash; then in the form of mobile apps where the smartphone or tablet did most of the hard work and the back-end was a communications channel for reporting the results of local action. Now were seeing the first iteration of the Internet of Things (IoT), in which small devices, sipping from their batteries, chatting care fully over Bluetooth LE, are little more than sensors. The prepon derance of the work, from data cleaning to aggregation to analysis, has once again moved to the core: the first versions of the Jawbone Up band doesnt do much until they send their data to the cloud. But already we can see how the pendulum will swing back. Theres a renewed interest in computing at the edgesCisco calls it fog com puting: small, local clouds that combine tiny sensors with more powerful local computingand this may move much of the work out to the device or the local network again. Companies like realm.io are building databases that can run on smartphones or even wearables. Foghorn Systems is building platforms on which devel opers can deploy such multi-tiered architectures. Resin.io calls this strong devices, weakly connected. Systems architects understand well the tension between putting everything at the core, and making the edges more important. Cen tralization gives us power, makes managing changes consistent and easy, and cuts on costly latency and networking; distribution gives us more compelling user experiences, better protection against cen tral outages or catastrophic failures, and a tiered hierarchy of pro cessing that can scale better. Ultimately, each swing of the pendulum gives us new architectures and new bottlenecks; each rung we climb up the stack brings both abstraction and efficiency. Machine learning Transcendence aside, machine learning has come a long way. Deep learning approaches have significantly improved the accuracy of speech recognition, and many of the advances in the field have come from better tools and parallel computing. Critics charge that deep learning cant account for changes over time, and as a result its categories are too brittle to use in many applications: just because something hurt yesterday doesnt mean 2 | Cheap Sensors, Fast Networks, and Distributed Computing http://radar.oreilly.com/iot http://resin.io/blog/the-internet-of-autonomous-things-strong-devices-weakly-connected/ http://radar.oreilly.com/2014/07/what-is-deep-learning-and-why-should-you-care.html http://radar.oreilly.com/2014/07/what-is-deep-learning-and-why-should-you-care.html you should never try it again. But investment in deep learning approaches continues to pay off. And not all of the payoff comes from the fringes of science fiction. Faced with a torrent of messy data , machine-driven approaches to data transformation and cleansing can provide a good first pass, de-duplicating and clarifying information and replacing manual methods. Whats more, with many of these tools now available as hosted, pay- as-you-go services, its far easier for organizations to experiment cheaply with machine-aided data processing. These are the same economics that took public cloud computing from a fringe tool for early-stage startups to a fundamental building block of enterprise IT. (More on this in Data as a service, below.) Were keenly watching other areas where such technology is taking root in otherwise tradi tional organizations. Machine learning | 3 Computational Power and Cognitive Augmentation Heres a look at a few of the ways that humansstill the ultimate data processorsmesh with the rest of our data systems: how com putational power can best produce true cognitive augmentation. Deciding better Over the past decade, we fitted roughly a quarter of our species with sensors. We instrumented our businesses, from the smallest market to the biggest factory. We began to consume that data, slowly at first. Then, as we were able to connect data sets to one another, the appli cations snowballed. Now that both the front-office and the back- office are plugged into everything, business cares. A lot. While early adopters focused on sales, marketing, and online activ ity, today, data gathering and analysis is ubiquitous. Governments, activists, mining giants, local businesses, transportation, and virtu ally every other industry lives by data. If an organization isnt har nessing the data exhaust it produces, itll soon be eclipsed by more analytical, introspective competitors that learn and adapt faster. Whether were talking about a single human made more productive by a smartphone turned prosthetic brain; or a global organization gaining the ability to make more informed decisions more quickly, ultimately, Strata + Hadoop World has become about deciding bet ter. What does it take to make better decisions? How will we balance machine optimization with human inspiration, sometimes making 5 http://radar.oreilly.com/tag/cognitive-augmentation the best of the current game and other times changing the rules? Will machines that make recommendations about the future based on the past reduce risk, raise barriers to innovation, or make us vul nerable to improbable Black Swans because they mistakenly con clude that tomorrow is like yesterday, only more so? Designing for interruption Tomorrows interfaces wont be about mobility, or haptics, or aug mented reality (AR), or HUDs, or voice activation. I mean, they will be, but thats just the icing. Theyll be about interruption. In his book Consilience, E. O. Wilson said: We are drowning in informationthe world henceforth will be run by synthesizers, peo ple able to put together the right information at the right time, think critically about it, and make important choices wisely. Only it wont be people doing that synthesis, itll be a hybrid of humans and machines. Because after all, the right information at the right time changes your life. That interruption will take many formsa voice on a phone; a buzz on a bike handlebar; a heads-up display over actual heads. But behind it is a tremendous amount of context that helps us to decide better. Right now, there are three companies on the planet that could do this. Microsofts Cortana; Googles Now; and Apples Siri are all start ing down the path to prosthetic brains. A few othersSamsung, Facebook, Amazonmight try to make it happen, too. When it finally does happen, itll be the fundamental shift of the twenty-first century, the way machines were in the nineteenth and computers were in the twentieth, because it will create a new species. Call it Homo Conexus. Add iBeacons and health data to things like GPS, your calendar, crowdsourced map congestion, movement, and temperature data, etc., and machines will be more intimate, and more diplomatic, than even the most polished personal assistants. These agents will empathize better and far more quickly than humans can. Consider two users, Mike and Tammy. Mike hates being interrupted: when his device interrupts, and it senses his rac ing pulse and the stress tones in his voice, it will stop. When Tammys device interrupts, and her pupils dilate in technological 6 | Computational Power and Cognitive Augmentation http://www.amazon.com/Consilience-Knowledge-Edward-Osborne-Wilson/dp/067976867X http://en.wikipedia.org/wiki/Information_wants_to_be_free http://en.wikipedia.org/wiki/Information_wants_to_be_free lust, it will interrupt more often. Factor in heart rate, galvanic response, and multiply by a million users with a thousand data points a day, and its a simple baby-step toward the human-machine hybrid. Weve seen examples of contextual push models in the past. Doc Searls suggestion of Vendor Relationship Management (VRM), in which consumers control what they receive by opting in to that in which theyre interested, was a good idea. Those plans came before their time; today, however, a huge and still-increasing percentage of the world population has some kind of push-ready mobile device and a data plan. The rise of design-for-interruption might also lead to an interrup tion arms race of personal agents trying to filter out all but the most important content, and third-party engines competing to be the most important thing in your notification center. In discussing this with Jon Bruner, he pointed out that some of these changes will happen over time, as we make peace with our second brains: Theres a process of social refinement that takes place when new things become widespread enough to get annoying. Everything from carsfor which traffic rules had to be invented after a couple years of gridlockto cell phones (guy talking loudly in a public place is, I think, a less common nuisance than it used to be) have threatened to overload social convention when they became univer sal. Theres a strong reaction, and then a reengineering of both con vention and behavior results in a moderate outcome. This trend leads to fascinating moral and ethical questions:  Will a connected, augmented species quickly leave the disconnec ted in its digital dust, the way humans outstripped Neanderthals?  What are the ethical implications of this?  Will such brains make us more vulnerable?  Will we rely on them too much?  Is there a digital equivalent of eminent domain? Or simply the equivalent of an Amber Alert?  What kind of damage might a powerful and politically motivated attacker wreak on a targeted nation, and how would this affect pro ductivity or even cost lives? Designing for interruption | 7 http://cyber.law.harvard.edu/projectvrm/Main_Page http://radar.oreilly.com/jbruner  How will such machines dream and work on sense-making and garbage collection in the background the way humans do as they sleep?  What interfaces are best for human-machine collaboration?  And what protections of privacy, unreasonable search and seizure, and legislative control should these prosthetic brains enjoy? There are also fascinating architectural changes. From a systems perspective, designing for interruption implies fundamental rethinking of many of our networks and applications, too. Systems architecture shifts from waiting and responding to pushing out smart interruptions based on data and context. 8 | Computational Power and Cognitive Augmentation The Maturing Marketplace Heres a look at some options in the evolving, maturing marketplace of big data components that are making the new applications and interactions that weve been looking at possible. Graph theory First used in social network analysis, graph theory is finding more and more homes in research and business. Machine learning sys tems can scale up fast with tools like Parameter Server, and the TitanDB project means developers have a robust set of tools to use. Are graphs poised to take their place alongside relational database management systems (RDBMS), object storage, and other funda mental data building blocks? What are the new applications for such tools? Inside the black box of algorithms: whither regulation? Its possible for a machine to create an algorithm no human can understand. Evolutionary approaches to algorithmic optimization can result in inscrutableyet demonstrably bettercomputational solutions. If youre a regulated bank, you need to share your algorithms with regulators. But if youre a private trader, youre under no such con straints. And having to explain your algorithms limits how you can generate them. 9 http://radar.oreilly.com/2014/07/there-are-many-use-cases-for-graph-databases-and-analytics.html http://parameterserver.org As more and more of our lives are governed by code that decides whats best for us, replacing laws, actuarial tables, personal trainers and personal shoppers, oversight means opening up the black box of algorithms so they can be regulated. Years ago, Orbitz was shown to be charging web visitors who owned Apple devices more money than those visiting via other platforms, such as the PC. Only thats not the whole story: Orbitzs machine learning algorithms, which optimized revenue per customer, learned that the visitors browser was a predictor of their willingness to pay more. Is this digital goldlining an upselling equivalent of redlining? Is a black-box algorithm inherently dangerous, brittle, vulnerable to runaway trading and ignorant of unpredictable, impending catastro phes? How should we balance the need to optimize quickly with the requirement for oversight? Automation Marc Andreesens famous line that software eats everything is pretty true. Its already finished its first course. Zeynep Tufecki says that first, machines came for physical labor like the digging of trenches; then for mental labor (like Logarithm tables); and now for mental skills (which require more thinking) and possibly robotics. Is this where automation is headed? For better or for worse, modern automation isnt simply repetition. It involves adaptation, dealing with ambiguity and changing circumstance. Its about causal feed back loops, with a system edging ever closer to an ideal state. Past Strata speaker Avinash Kaushik chides marketers for wanting real-time data, observing that we humans cant react fast enough for it to be useful. But machines can, and do, adjust in real time, turning every action into an experiment. Real-time data is the basis for a perfect learning loop. Advances in fast, in-memory data processing deliver on the promise of cyberneticsmechanical, physical, biological, cognitive, and social systems in which an action that changes the environment in turn changes the system itself. 10 | The Maturing Marketplace http://online.wsj.com/articles/SB10001424052702304458604577488822667325882 https://twitter.com/zeynep https://medium.com/message/failing-the-third-machine-age-1883e647ba74 https://medium.com/message/failing-the-third-machine-age-1883e647ba74 http://www.kaushik.net/avinash/is-real-time-really-relevant/ http://www.kaushik.net/avinash/is-real-time-really-relevant/ Data as a service The programmable web was a great idea, here far too early. But if the old model of development was the LAMP stack, the modern equivalent is cloud, containers, and GitHub.  Cloud services make it easy for developers to prototype quickly and test a market or an idea  building atop Paypal, Google Maps, Facebook authentication, and so on.  Containers, moving virtual machines from data center to data cen ter, are the fundamental building blocks of the parts we make our selves.  And social coding platforms like GitHub offer fecundity, encourag ing re-use and letting a thousand forks of good code bloom. Even these three legs of the modern application are getting simpler. Consumer-friendly tools like Zapier and IFTTT let anyone stitch together simple pieces of programming to perform simple, repetitive tasks across myriad web platforms. Moving up the levels of com plexity, theres now Stamplay for building web apps as well. When it comes to big data, developers no longer need to roll their own data and machine learning tools, either. Consider Googles pre diction API and BigQuery, Amazon Redshift and Kinesis. Or look at the dozens of start-ups offering specialized on-demand functions for processing data streams or big data applications. What are the trade-offs between standing on the shoulders of giants and rolling your own? When is it best to build things from scratch in the hopes of some proprietary advantage, and when does it make sense to rely on others economies of scale? The answer isnt clear yet, but in the coming years the industry is going to find out where that balance lies, and it will the decide the fate of hundreds of new companies and technology stacks. Data as a service | 11 https://zapier.com/ https://ifttt.com/ http://stamplay.com/ https://cloud.google.com/prediction/docs https://cloud.google.com/prediction/docs https://cloud.google.com/bigquery/what-is-bigquery http://aws.amazon.com/redshift/ http://aws.amazon.com/kinesis/ http://gnip.com/ http://cask.co/ The Promise and Problems of Big Data Finally, well look at both the light and the shadows of this new dawn, the social and moral implications of living in a deeply con nected, analyzed, and informed world. This is both the promise and the peril of big data in an age of widespread sensors, fast networks, and distributed computing. Solving the big problems The planets systems are under strain from a burgeoning population. Scientists warn of rising tides, droughts, ocean acidity, and accelerat ing extinction. Medication-resistant diseases, outbreaks fueled by globalization, and myriad other semi-apocalyptic Horsemen ride across the horizon. Can data fix these problems? Can we extend agriculture with data? Find new cures? Track the spread of disease? Understand weather and marine patterns? General Electrics Bill Ruh says that while the company will continue to innovate in materials sciences, the place where it will see real gains is in analytics. Its often been said that theres nothing new about big data. The iron triangle of Volume, Velocity, and Variety that Doug Laney coined in 2001 has been a constraint on all data since the first database. Basi cally, you can have any two you want fairly affordably. Consider:  A coin-sorting machine sorts a large volume of coins rapidlybut assumes a small variety of coins. It wouldnt work well if there were hundreds of coin types. 13 http://billruh.geblogs.com/author/215000441/ http://blogs.gartner.com/doug-laney/ http://blogs.gartner.com/doug-laney/files/2012/01/ad949-3D-Data-Management-Controlling-Data-Volume-Velocity-and-Variety.pdf http://blogs.gartner.com/doug-laney/files/2012/01/ad949-3D-Data-Management-Controlling-Data-Volume-Velocity-and-Variety.pdf  A public library, organized by the Dewey Decimal System, has a wide variety of books and topics, and a large volume of those books  but stacking and retrieving the books happens at a slow velocity. No, whats new about big data is that the cost of getting all three Vs has become so cheap, its almost not worth billing for. A Google search happens with great alacrity, combs the sum of online knowl edge, and retrieves a huge variety of content types. With new affordability comes new applications. Where once a small town might deploy another garbage truck to cope with growth, today it can affordably analyze routes to make the system more effi cient. Ten years ago, a small town didnt rely on data scientists; today, it scarcely knows its using them. Gluten-free dieters aside, Norman Borlaug saved billions by care fully breeding wheat and increasing the worlds food supply. Will the next billion meals come from data? Monsanto thinks so, and is mak ing substantial investments in analytics to increase farm productiv ity. While much of todays analytics is focused on squeezing the most out of marketing and advertising dollars, organizations like Data kind are finding new ways to tackle modern challenges. Govern ments and for-profit companies are making big bets that the answers to our most pressing problems lie within the very data they generate. The death spiral of prediction The city of Chicago thinks a computer can predict crime. But does profiling doom the future to look like the past? As Matt Stroud asks: is the computer racist? When governments share data, that data changes behavior. If a city publishes a crime map, then the police know where they are most likely to catch criminals. Homeowners who can afford to leave will flee the area, businesses will shutter, and that high-crime prediction turns into a self-fulfilling prophecy. Call this, somewhat inelegantly, algorithms that shit where they eat. As we consume data, it influences us. Microsofts Kate Crawford points to a study that shows Googles search results can sway an elec tion. 14 | The Promise and Problems of Big Data http://en.wikipedia.org/wiki/Norman_Borlaug http://www.techrepublic.com/article/how-big-data-is-going-to-help-feed-9-billion-people-by-2050/ http://www.techrepublic.com/article/how-big-data-is-going-to-help-feed-9-billion-people-by-2050/ http://www.theverge.com/2014/2/19/5419854/the-minority-report-this-computer-predicts-crime-but-is-it-racist https://twitter.com/katecrawford http://www.washingtonpost.com/blogs/the-switch/wp/2014/05/12/research-in-india-suggests-google-search-results-can-influence-an-election/ http://www.washingtonpost.com/blogs/the-switch/wp/2014/05/12/research-in-india-suggests-google-search-results-can-influence-an-election/ Such feedback loops can undermine the utility of algorithms. How should data scientists deal with them? Do they mean that every algo rithm is only good for a limited amount of time? When should the algorithm or the resulting data be kept private for the public good? These are problems that will dog the data scientists in coming years. Sensors, sensors everywhere In a Craigslist post that circulated in mid-2014 (since taken down), a restaurant owner ranted about how clients had changed. Hoping to boost revenues, the story went, the restaurant hired consultants who reviewed security footage to detect patterns in diner behavior. The restaurant happened to have 10-year-old footage of their dining area, and the consultants compared the older footage to the new recordings, concluding that smartphones had significantly altered diner behavior and the time spent in the restaurant. If true, thats interesting news if youre a restaurateur. For the rest of us, its a clear lesson of just how much knowledge is lurking in pic tures, audio, and video that we dont yet know how to read but soon will. Image recognition and interpretationlet alone video analysisis a Very Hard Problem, and it may take decades before we can say, Computer, review these two tapes and tell me whats different about them and get a useful answer in plain English. But that day will come  computers have already cracked finding cats in online vid eos. When that day arrives, every video weve shot and uploadedeven those from a decade agowill be a kind of retroactive sensor. We havent been very concerned about being caught on camera in the past because our behavior is hidden by the burden of reviewing footage. But just as yesterdays dumpster-diving and wiretaps gave way to todays effortless surveillance of whole populations, well real ize that the sensors have always been around us. Already obvious are the smart devices on nearly every street and in every room. Crowdfunding sites are a treasure-trove of such things, from smart bicycles to home surveillance. Indeed, littleBits makes it so easy to create a sensor, its literally kids play. And when Tesla pushes software updates to its cars, the company can change what it Sensors, sensors everywhere | 15 http://www.technologyreview.com/featuredstory/513696/deep-learning/ http://www.technologyreview.com/featuredstory/513696/deep-learning/ https://www.kickstarter.com/projects/1931822269/vanhawks-valour-first-ever-connected-carbon-fibre https://www.indiegogo.com/projects/canary-the-first-smart-home-security-device-for-everyone https://littlebits.cc/cloud http://www.cnet.com/news/tesla-model-s-avoids-traffic-with-new-software-update/ collects and how it analyzes it long after the vehicle has left the showroom. The evolution of how we collect data in a world where every output is also an intputwhen you cant read a thing without it reading you backposes immense technical and ethical challenges. But its also a massive business opportunity, changing how we build, maintain, and recover almost everything in our lives. 16 | The Promise and Problems of Big Data Cover Table of Contents Introduction Chapter 1. Cheap Sensors, Fast Networks, and Distributed Computing Clouds, edges, fog, and the pendulum of distributed computing Machine learning Chapter 2. Computational Power and Cognitive Augmentation Deciding better Designing for interruption Chapter 3. The Maturing Marketplace Graph theory Inside the black box of algorithms: whither regulation? Automation Data as a service Chapter 4. The Promise and Problems of Big Data Solving the big problems The death spiral of prediction Sensors, sensors everywhere
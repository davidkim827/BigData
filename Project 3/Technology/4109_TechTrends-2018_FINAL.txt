Tech Trends 2018 The symphonic enterprise COVER IMAGE BY: MARTIN SATI Deloitte Consulting LLPs Technology Consulting practice is dedicated to helping our clients build tomorrow by solving todays complex business problems involving strategy, procurement, design, delivery, and assurance of technology solutions. Our service areas include analytics and information management, delivery, cyber risk services, and technical strategy and architecture, as well as the spectrum of digital strategy, design, and development services offered by Deloitte Digital. Learn more about our Technology Consulting practice on www.deloitte.com. Trending the Trends: Nine years of research DIGITAL ANALYTICS CYBER BUSINESS OF IT Cyber intelligence No such thing as hacker-proof Cyber security Digital identities Almost-enterprise applications Value-driven application management Business of IT Right- speed IT IT unboundedExponentials watch list No-collar workforce Reengineering technology Measured innovation Design as a discipline IT worker of the future Social impact of exponentials Exponentials Exponentials CLOUD CORE Machine intelligence Best-of-breed enterprise applications Services thinking The end of the death of ERP Reinventing the ERP engine In-memory revolution Technical debt reversal Core renaissance Reimagining core systems Outside-in architecture User empowerment User engagement User engagement Digital engagement Dimensional marketing AR and VR go to work Mixed reality Digital reality Wireless and mobility Applied mobility Enterprise mobility unleashed Mobile only (and beyond) Wearables Ambient computing Internet of Things Real analytics Amplified intelligence Dark analytics Information automation Big data goes to work Cognitive analytics Visualization Information management Geospatial visualization Virtualization Software- defined everything Autonomic platforms Inevitable architecture IPv6 (and this time we mean it) Real-time DevOps Gamification Gamification goes to work Industrialized crowdsourcing Social business Social reengineering by design Social activation Social computing Finding the face of your data Industrialized analytics Capability clouds Hyper-hybrid cloud Cloud orchestration API economy Everything- as-a-service API imperative The new core Cloud revolution Asset intelligence Risk implications Blockchain: Democratized trust Blockchain: Trust economy Blockchain to blockchains Cyber security CIO operational excellence CIOs as revolutionaries CIO as postdigital catalyst CIO as venture capitalist CIO as chief integration officer 20 10 20 11 20 12 20 13 20 14 20 15 20 16 20 17 20 18 Enterprise data sovereignty Exponential technology watch list Introduction | 2 Reengineering technology | 4 Building new IT delivery models from the top down and bottom up No-collar workforce | 24 Humans and machines in one loopcollaborating in roles and new talent models Enterprise data sovereignty | 40 If you love your data, set it free The new core | 56 Unleashing the digital potential in heart of the business operations Digital reality | 74 The focus shifts from technology to opportunity Blockchain to blockchains | 94 Broad adoption and integration enter the realm of the possible API imperative | 110 From IT concern to business mandate Exponential technology watch list | 132 Innovation opportunities on the horizon Authors | 150 Contributors and research team | 157 Special thanks | 158 CONTENTS 1 Introduction THE renowned German conductor Kurt Masur once noted that an orchestra full of stars can be a disaster. Though we have no reason to believe the maestro was speaking metaphorically, his observation does suggest something more universal: Without unity and harmony, discord prevails. Many companies competing in markets that are being turned upside down by technology innovation are no strangers to discord. Today, digital reality, cognitive, and blockchainstars of the enterprise technology realmare redefining IT, business, and society in general. In the past, organizations typically responded to such disruptive opportunities by launching transformation initiatives within technology domains. For example, domain-specific cloud, analytics, and big data projects represented bold, if singleminded, embraces of the future. Likewise, C-suite positions such as chief digital officer or chief analytics officer reinforced the primacy of domain thinking. But it didnt take long for companies to realize that treating some systems as independent domains is suboptimal at best. Complex predictive analytics capabilities delivered little value without big data. In turn, big data was costly and inefficient without cloud. Everything required mobile capabilities. After a decade of domain-specific transformation, one question remains unanswered: How can disruptive technologies work together to achieve larger strategic and operational goals? We are now seeing some forward-thinking organizations approach change more broadly. They are not returning to sins of the past by launching separate, domain-specific initiatives. Instead, they are thinking about exploration, use cases, and deployment more holistically, focusing on how disruptive technologies can complement each other to drive greater value. For example, blockchain can serve as a new foundational protocol for trust throughout the enterprise and beyond. Cognitive technologies make automated response possible across all enterprise domains. Digital reality breaks down geographic barriers between people, and systemic barriers between humans and data. Together, these technologies can fundamentally reshape how work gets done, or set the stage for new products and business models. The theme of this years Tech Trends report is the symphonic enterprise, an idea that describes strategy, technology, and operations working together, in harmony, across domains and boundaries. This is the ninth edition of Tech Trends, and in a way, it represents the culmination of our dogged efforts to examine the powerful technology forces that are remaking our world. The trends we discussed early on in the series, such as digital, cloud, and analytics, are now embraced across industries. Meanwhile, more recent trends, such as autonomic platforms, machine intelligence, and digital reality, continue to gain momentum. This year, we invite you to look at emerging technology trends from a different angle. When technologies act in unison, we no longer see the enterprise vertically (focused on line of business or isolated industries) or horizontally (focused on business processes or enabling technologies). In the symphonic enterprise, the old lines become blurred, thus creating a diagonal view that illuminates new business opportunities and creative ways of solving problems. For example, in the new core chapter, we discuss how in the near future, digitized Tech Trends 2018: The symphonic enterprise 2 finance and supply chain organizations could blur the lines between the two functions. Sound unlikely? Consider this scenario: IoT sensors on the factory floor generate data that supply chain managers use to optimize shipping and inventory processes. When supply chain operations become more efficient and predictable, finance can perform more accurate forecasting and planning. This, in turn, allows dynamic pricing or adjustments to cash positions based on real-time visibility of operations. Indeed, the two functions begin sharing investments in next-generation ERP, the Internet of Things, machine learning, and RPA. Together, finance and supply chain functions shift from projects to platforms, which expands the potential frame of impact. Meanwhile, business leaders and the C-suite are increasingly interested only in strategy and outcomes, not the individual technologies that drive them. Does the convergence of finance and supply chain really seem so unlikely? Of course, some domain-specific approaches remain valuable. Core assets still underpin the IT ecosystem. Cyber and risk protocols are as critical as ever. CIO strategies for running the business of IT are valuable and timeless. Yet we also recognize a larger trend at work, one that emphasizes the unified orchestra over individual advances in technology. We hope this latest edition of Tech Trends helps you develop a more in-depth understanding of technology forces at work today. We also hope it can help you begin building a symphonic enterprise of your own. Beautiful music awaits. Bill Briggs Chief technology officer Deloitte Consulting LLP wbriggs@deloitte.com Twitter: @wdbthree Craig Hodgetts US national managing principalTechnology Deloitte Consulting LLP chodgetts@deloitte.com Twitter: @craig_hodgetts Introduction 3 Reengineering technology Building new IT delivery models from the top down and bottom up FOR nine years, Deloitte Consulting LLPs an-nual Tech Trends report has chronicled the steps that CIOs and their IT organizations have taken to harness disruptive technology forces such as cloud, mobile, and analytics. Throughout, IT has adapted to new processes, expectations, and opportunities. Likewise, it has worked more closely with the business to develop increasingly tech- centric strategies. Yet as growing numbers of CIOs and enterprise leaders are realizing, adapting incrementally to market shifts and disruptive innovation is no lon- ger enough. At a time when blockchain, cognitive, and digital reality technologies are poised to rede- fine business models and processes, ITs traditional reactive, siloed ways of working cannot support the rapid-fire change that drives business today. With technologys remit expanding beyond the back of- fice and into the product-management and custom- er-facing realms, the problem is becoming more pressing. This evolving dynamic carries some risk for CIOs. While they enjoy unprecedented opportunities to impact the business and the greater enterprise, these opportunities go hand-in-hand with growing expectationsand the inevitable challenges that With business strategies linked inseparably to technology, leading organiza- tions are fundamentally rethinking how they envision, deliver, and evolve technology solutions. They are transforming IT departments into engines for driving business growth, with responsibilities that span back-office systems, operations, and even product and platform offerings. From the bottom up, they are modernizing infrastructure and the architecture stack. From the top down, they are organizing, operating, and delivering technology capabilities in new ways. In tandem, these approaches can deliver more than efficiency they offer the tools, velocity, and empowerment that will define the technol- ogy organization of the future. Reengineering technology 5 CIOs encounter in meeting these expectations. In a 201617 Deloitte survey of executives on the topic of IT leadership transitions, 74 percent of respon- dents said that CIO transitions happen when there is general dissatisfaction among business stake- holders with the support CIOs provide. Not surpris- ingly, 72 percent of those surveyed suggested that a CIOs failure to adapt to a significant change in cor- porate strategy may also lead to his transition out of the company.1 For years, IT has faithfully helped reengineer the business, yet few shops have reengineered themselves with the same vision, discipline, and rigor. Thats about to change: Over the next 18 to 24 months, we will likely see CIOs begin reengineering not only their IT shops but, more broadly, their ap- proaches to technology. The goal of these efforts will be to transform their technology ecosystems from collections of working parts into high-performance engines that deliver speed, impact, and value. Reengineering approaches may vary, but expect to see many CIOs deploy a two-pronged strategy. From the bottom up, they can focus on creating an IT environment in which infrastructure is scalable and dynamic and architecture is open and extend- able. Importantly, automation (driven by machine learning) will likely be pervasive, which can accel- erate the processes of standing up, building on top of, and running the IT stack. These principles are baked into infrastructure and applications, thus becoming elemental to all aspects of the operation. From the top down, CIOs and their teams have an opportunity to transform how the shop budgets, or- ganizes, staffs, and delivers services. Figure 1. Two-pronged reengineering technology approach Top-down capabilities are amplified by a revamped bottom-up architecture, and bottom-up efficiency gains become more strategic and impactful when coupled with top-down transformation. Deloitte Insights | Deloitte.com/insightsSource: Deloitte analysis. Step 1: Modernized infrastructure Virtualized, containerized, and cloud-ready Step 2: Pervasive automation With infrastructure-as-code, provisioning and maintenance can be automated Step 3: New operating model Modernized, automated tech stack demands new skills, organization, and delivery model Results: Outcome-based budgeting Agile delivery allows continuous budgeting against changing priorities Bottom up Operating model Automation Architecture Infrastructure Budgeting Mission Example reengineering technology scenario Top down Tech Trends 2018: The symphonic enterprise 6 The reengineering technology trend is not an exercise in retooling. Rather, it is about challenging every assumption, designing for better outcomes, and, ultimately, creating an alternate IT delivery model for the future. Enough with the tasks, already In their best-selling book Reengineering the Corporation, Michael Hammer and James Champy defined business processes as an entire group of activities that when effectively brought together, create a result customers value. They went on to argue that by focusing on processes rather than on individual taskswhich, by themselves, accomplish nothing for the customercompanies can achieve desired outcomes more efficiently. The difference between process and task is the difference between whole and part, between ends and means, Ham- mer and Champy wrote.2 Today, many IT organizations take the oppo- site approach. As IT scaled continuously over the last three decades, it became excruciatingly task- focused, not just in applications and infrastructure but in networks, storage, and administration. Today, IT talent with highly specialized skillsets may work almost exclusively within a single functional area. Because they share few common tools with their highly specialized counterparts in other functional areas, low-bandwidth/high-latency human inter- faces proliferate among network engineers, system administrators, and security analysts. Until recently, efforts to transform IT typically focused on adopting new technologies, outsourcing, or offshoring. Few emphasized the kind of systemat- ic, process-focused reengineering that Hammer and Champy advocated. Meanwhile, consumerization of technology, the publics enduring fascination with young technology companies, and the participation of some IT functions in greenfield projects have put pressure on CIOs to reengineer. Yet, approaches that work well for start-ups and new company spinoffs might be unrealistic for larger companies or agen- cies. These organizations can tackle reengineering challenges by broadening the frame to include open source, niche platforms, libraries, languages and tools, and by creating the flexibility needed to scale. Reengineering from the bottom up One dimension of reengineering focuses on modernizing underlying infrastructure and archi- tecture. To jump-start bottom-up initiatives, for- ward-thinking companies can focus their planning on three major areas of opportunity:  Automation: Automation is often the primary goal of companies reengineering efforts. There are automation opportunities throughout the IT life cycle. These include, among others, au- tomated provisioning, testing, building, deploy- ment, and operation of applications as well as large-scale autonomic platforms that are self- monitoring, self-learning, and self-healing. Al- most all traditional IT operations can be candi- dates for automation, including anything that is workflow-driven, repetitive, or policy-based and requires reconciliation between systems. Ap- proaches have different names: robotic process automation, cognitive automation, intelligent automation, and even cognitive agents. However, their underlying stories are similar: applying new technologies to automate tasks and help workers handle increasingly complex workloads.3 As part of their automation efforts, some companies are deploying autonomic platforms that layer in the ability to dynamically manage resources while integrating and orchestrating more of the end-to-end activities required to build and run IT solutions. When discussing the concept of autonomics, we are really talking about automation + robotics, or taking automa- tion to the next level by basing it in machine learning. Autonomic platforms build upon two important trends in IT: software-defined every- things climb up the tech stack, and the overhaul of IT operating and delivery models under the DevOps movement. With more of IT becoming Reengineering technology 7 expressible as codefrom underlying infrastruc- ture to IT department tasksorganizations now have a chance to apply new architecture patterns and disciplines. In doing so, they can remove de- pendencies between business outcomes and un- derlying solutions, and redeploy IT talent from rote low-value work to the higher-order capa- bilities. Organizations also have an opportunity to improve productivity. As one oft-repeated ad- age reminds us, The efficiency of an IT process is inversely correlated to the number of unique humans it takes to accomplish it. Another opportunity lies in self-service au- tomation, an important concept popularized by some cloud vendors. Through a web-based por- tal, users can access IT resources from a catalog of standardized service options. The automated system controls the provisioning process and enforces role-based access, approvals, and pol- icy-based controls. This can help mitigate risk and accelerate the marshaling of resources.  Technical debt: Technical debt doesnt hap- pen just because of poor code quality or shoddy design. Often its the result of decisions made over timeactions individually justified by their immediate ROI or the needs of a project. Orga- nizations that regularly repay technical debt by consolidating and revising software as needed will likely be better positioned to support invest- ments in innovation. Companies can also accrue technical debt in physical infrastructure and applications, and maintaining legacy systems carries certain costs over an extended period of time. Re-platforming apps (via bare metal or cloud) can help offset these costs and accelerate speed-to-market and speed-to-service. As with financial debt, organizations that dont pay it back may end up allocating the bulk of their budgets to interest (that is, system maintenance), leaving little for new opportuni- ties. Consider taking the following two-step ap- proach to addressing technical debt:  Quantify it: Reversal starts with visibilitya baseline of lurking quality and architectural is- sues. Develop simple, compelling ways that de- scribe the potential impact of the issues in order to foster understanding by those who determine IT spending. Your IT organization should apply a technical debt metric not only to planning and portfolio management but to project delivery as well.  Manage it: Determine what tools and systems you will need over the next year or two to achieve your strategic goals. This can help you to identify the parts of your portfolio to address. Also, when it comes to each of your platforms, dont be afraid to jettison certain parts. Your goal should be to reduce technical debt, not just monitor it.  Modernized infrastructure: There is a flex- ible architecture model whose demonstrated ef- ficiency and effectiveness in start-up IT environ- ments suggest that its broader adoption in the marketplace may be inevitable. In this cloud- first modeland in the leading practices emerg- ing around itplatforms are virtualized, con- tainerized, and treated like malleable, reusable resources, with workloads remaining indepen- dent from the operating environment. Systems are loosely coupled and embedded with policies, controls, and automation. Likewise, on-premis- es, private cloud, or public cloud capabilities can be employed dynamically to deliver any given workload at an effective price and performance point. Taken together, these elements can make it possible to move broadly from managing in- stances to managing outcomes. Its not difficult to recognize a causal rela- tionship between architectural agility and any number of potential strategic and operational benefits. For example, inevitable architecture provides the foundation needed to support rap- id development and deployment of flexible solu- tions that, in turn, enable innovation and growth. In a competitive landscape being redrawn con- tinuously by technology disruption, time-to- market can be a competitive differentiator.4 Tech Trends 2018: The symphonic enterprise 8 Reengineering from the top down Though CIOs influence and prestige have grown markedly over the last decade, the primary source of their credibility continues to lie in maintaining efficient, reliable IT operations. This is, by any mea- sure, a full-time job. Yet along with that responsi- bility, they are expected to harness emerging tech- nology forces. They stay ahead of the technology curve by absorbing the changes that leading-edge tools introduce to operational, organizational, and talent models. Finally, an ever-growing cadre of en- terprise leaders with C in their titlesthink chief digital officer, chief data officer, or chief algorithm officerdemand that CIOs and their teams pro- vide: 1) new products and services to drive revenue growth, 2) new ways to acquire and develop talent, and 3) a means to vet and prototype what the com- pany wants to be in the future. As growing numbers of overextended CIOs are realizing, the traditional operating model that IT has used to execute its mission is no longer up to the job. Technological advances are creating en- tirely new ways of getting work done that are, in some cases, upending how we think about people and machines complementing one another. More- over, the idea that within an organization there are special types of people who understand technology and others who understand business is no longer valid. Technology now lies at the core of the busi- ness, which is driving enterprise talent from all op- erational areas to develop tech fluency.5 The time has come to build a new operating model. As you explore opportunities to reengineer your IT shop from the top down, consider the fol- lowing areas of opportunity:  Reorganizing teams and breaking down silos: In many IT organizations, workers are organized in siloes by function or skillset. For example, network engineering is distinct from QA, which is different from system administra- tion. In this all-too-familiar construct, each skill group contributes its own expertise to different project phases. This can result in projects be- coming rigidly sequential and trapped in one speed (slow). It also encourages over the wall engineering, a situation in which team members work locally on immediate tasks without know- ing about downstream tasks, teams, or the ulti- mate objectives of the initiative. Transforming this model begins by breaking down skillset silos and reorganizing IT workers into multi-skill, results-oriented teams. These teams focus not on a specific development step say, early-stage design or requirementsbut more holistically on delivering desired outcomes. A next step might focus on erasing the boundar- ies between macro IT domains such as applica- tions and infrastructure. Ask yourself: Are there opportunities to share resources and talent? For new capabilities, can you create greenfield teams that allow talent to rotate in or out as needed? Can some teams have budgets that are commit- ted rather than flexible? The same goes for the siloes within infrastructure: storage, networks, system administration, and security. What skill- sets and processes can be shared across these teams?6 A final note on delivery models: Much of the hype surrounding Agile and DevOps is merited. Reorganizing teams will likely be wasted effort if they arent allowed to develop and deliver products in a more effective way. If you are cur- rently testing the Agile-DevOps waters, its time to wade in. Be like the explorer who burned his boat so that he couldnt return to his familiar life.  Budgeting for the big picture: As functional silos disappear, the demarcation line between applications and infrastructure fades, and pro- cesses replace tasks, IT shops may have a prime opportunity to liberate their budgets. Many older IT shops have a time-honored budget planning process that goes something like this: Business leaders make a list of wants and cat- egorize them by priority and cost. These proj- ects typically absorb most of ITs discretionary budget, with care and maintenance claiming the rest. This basic budget blueprint will be good for a year, until the planning process begins again. Reengineering technology 9 We are beginning to see a new budgeting model emerge in which project goals reorient toward achieving a desired outcome. For exam- ple, if customer experience becomes an area of focus, IT could allocate funds to e-commerce or mobile products or capabilities. Specific fea- tures remain undetermined, which gives strate- gists and developers more leeway to focus effort and budgetary resources on potentially valuable opportunities that support major strategic goals. Standing funding for rolling priorities offers greater flexibility and responsiveness. It also aligns technology spend with measurable, at- tributable outcomes. When revising your budgeting priorities, keep in mind that some capital expenses will become operating expenses as you move to the cloud. Also, keep an eye out for opportunities to replace longstanding procurement policies with outcome-based partner and vendor arrange- ments or vehicles for co-investment.  Managing your portfolio while embrac- ing ambiguity: As IT budgets focus less on specifics and more on broad goals, it may be- come harder to calculate the internal rate of re- turn (IRR) and return on investment (ROI) of initiatives. Consider a cloud migration. During planning, CIOs can calculate project costs and net savings; moreover, they can be held account- able for these calculations. But if an initiative in- volves deploying sensors throughout a factory to provide greater operational visibility, things may get tricky: There may be good outcomes, but its difficult to project with any accuracy what they might be. Increasingly, CIOs are becoming more deliberate about the way they structure and manage their project portfolios by deploying a 70/20/10 allocation: Seventy percent of proj- ects focus on core systems, 20 percent focus on adjacencies (such as the live factory example above), and 10 percent focus on emerging or un- proven technologies that may or may not deliver value in the short term. Projects at the core typi- cally offer greater surety of desired outcomes. But the further projects get away from the core, the less concrete their returns become. As CIOs move into more fluid budgeting cycles, they should recognize this ambiguity and embrace it. Effectively balancing surety with ambiguity can help them earn the right over time to explore un- certain opportunities and take more risks.  Guiding and inspiring: IT has a unique op- portunityand responsibilityto provide the bigger picture as business leaders and strate- gists prioritize their technology wish lists. For example, are proposed initiatives trying to solve the right problem? Are technology-driven goals attainable, given the realities of the organiza- tions IT ecosystem? Importantly, can proposals address larger operational and strategic goals? IT can play two roles in the planning process. One is that of shaman who inspires others with the possibilities ahead. The other role is that of the sherpa, who guides explorers to their desired destination using only the tools currently avail- able. Tech Trends 2018: The symphonic enterprise 10 Skeptics corner The term reengineer may give some CIOs pause. The idea of challenging assumptions and transforming systems may seem like an open invitation to dysfunction, especially as the operational realities of the existing enterprise remain. In the paragraphs that follow, we will try to correct several misconceptions that skeptical CIOs may harbor about the growing reengineering technology trend. Misconception: Technology will always be complex and require architects and engineers to decipher it for the business. Reality: When they are new, technologies often seem opaque, as do the possibilities they offer the enterprise. But as we have seen time and again, yesterdays disruptive enigma quickly evolves into another entry in the tech fluency canon. Consider artificial intelligence, for example. In the beginning, it was the near-exclusive domain of the computer-savvy. Today, kids, their grandparents, and your board members use AI daily in the computer vision that dynamically focuses their smartphone cameras, and in the natural language processing engine powering their virtual personal assistants. Consistently, early adopters have a way of bringing the less technologically dexterous with them on the path to broad adoption. Misconception: By distributing tech across the business, you lose efficiency that goes with having a centralized enterprise architecture. Reality: We understand your point, but in fact, the process of reengineering technology can make federated architecture a viable alternative, in terms of efficiency, to traditional centralized models. For example, architectural standards and best practices for security, monitoring, and maintenance can be embedded in the policies and templates of software-defined infrastructure. When a new environment is provisioned, the architecture is built into the stack, becoming automatic and invisible. Instead of enterprise architecture being a religious argument requiring the goodwill of developers, it becomes codified in the fabric of your technology solutions. Rather than playing the thankless role of ivory-tower academic or evangelist (hoping-wishing-praying for converts), architects can focus on evolving platforms and tooling. Misconception: Breaking down organizational silos sounds like a recipe for organizational chaos. IT functions and teams are delineated for a reason. Reality: The issue of organizational siloes boils down to one question: Should IT remain a collection of function-specific fiefdoms, or should you organize it around processes and outcomes? By focusing on and organizing around outcomes, you are not introducing disorderyou are simply reordering the IT organization so that it can partner more effectively with the business, and maximize the value it brings to the enterprise. This is particularly true with bottom-up investments focusing on standardizing platforms, automation, and delivery. Reengineering technology 11 Syscos secret sauce Sysco, a leading food marketing and distribution company, took a bold stance to reevaluate a tech- nology transformation initiative that was well under way. Twelve of Syscos 72 domestic operating com- panies had gone live with a new ERP solution meant to standardize processes, improve operations, and protect against outdated legacy systems with loom- ing talent shortages. The problem: Those businesses that were up and running on the new ERP solution were seeing no significant operating advantages. Worse: Even as Sysco was outspending its indus- try peers in technology, competitors were focusing their investments on new digital capabilities that facilitated and simplified the customer experience. Syscos sizable back-office implementation, on the other hand, was perceived as an obstacle by custom- ers doing business with the company. Syscos IT leadership considered an alternate approach. They reevaluated those same legacy sys- tems with an eye on modernizing and amplifying the intellectual property and secret sauce embed- ded in decades of customized order management, inventory management, and warehouse manage- ment solutions. At the same time, they recognized the need to fundamentally transform the IT depart- ment, shifting from an org that had evolved to sup- port large-scale packaged software configuration to one that could move with more agility to engineer new capabilities and offeringsespecially custom- er-facing solutions. IT leadership needed the corporate manage- ment teams buy-in to pivot strategies and alter its current trajectory, into which they had sunk signifi- cant time, resources, and dollars. From an architec- ture perspective, many of the technologies central to the new approachcloud, application modern- ization platforms, microservices, and autonomics didnt exist or were not mature when the original ERP strategy was formed. Explaining how technol- ogy, tools, and methodologies had advanced over the past several years, the IT team made the case to the executive leadership team to modernize the core with these tested technologies, which would position Sysco for the future more effectively and with greater flexibility, while costing far less than it would if they continued to roll out the ERP solution to the other operating companies. Our legacy systems are customized specifically for what we do, says Wayne Shurts, executive vice president and chief technology officer at Sysco. The systems are old, but they work great. Operat- ing companies were so happy to be back on famil- iar ground, even while we were modernizing the underlying technologythe hardware they run on, LE SS O N S FR O M T H E FR O N T LI N ES Tech Trends 2018: The symphonic enterprise 12 the language they are built on, the way we manage them.7 To achieve these results, Shurts also convinced company leadership to completely reorganize IT operations: He wanted software product, platform, and service teams working in an Agile framework embracing DevOps rather than the traditional wa- terfall processes that were characteristic of Syscos IT organization. First came the why, then came the how. We are changing everything about the way we work, Shurts says. We are changing the technology and method- ologies that we use, which requires new tools and processes. Ultimately, it means we change how we are organized. With more than half of the IT or- ganization having made the shift, teams are em- bracing new tools, techniques, and methods. Each individual team can stand up a fully functioning new application organized around the teams prod- uct and customer experiences, owning a mandate to not just continually innovate but own both feature/ function development and ongoing operational sup- port. Plans are in place to transform the rest of IT in the year ahead. In addition to reorganizing the internal IT team, Shurts brought in experienced third-party archi- tects, engineers, and developers to build Syscos microservices capabilities and help codify the new Agile behavior. His team worked side by side with surgically placed experts, with the goal of creating our own disciples so we could be self-sufficient. So began a systemic effort to retool and rewire Sysco IT in order to broaden the organizations skillset, balanced with teams of veteran employees familiar with the companys legacy systems. Shurts continues to evolve the IT processes to meet his teams goal of delivering new releases dailyto bring new ideas, innovation, and help to customers every day. Our competition and our customers expect to see things theyve never seen before in heavy doses. If you believe that the pace of change in the world today will only accelerate, then you need to move to not only a new method but a new mind-set. My advice to other CIOs? Every shop needs to go down this pathfrom the top down, and the bottom up. Vodafone Germany develops great customer experiences Vodafone Germany is one of the countrys lead- ing telecom operators, offering mobile, broadband, TV, and enterprise services. In order to support its business needs and better integrate its markets, the company launched a multi-year program to mod- ernize its infrastructure and ready its IT stack for digital. The initiative also required implementing new work processes and retraining workers to bet- ter support end-to-end customer experiencesre- engineering IT to respond to the future of technol- ogy. The first step was virtualizing the infrastructure enabling local market legacy systems. Vodafone Germany migrated from its own data centers to a cloud-dominant model, modernizing IT operations according to the evolved architecture, tools, and potential for automation. The reengineered stack drove down costs while improving resiliency; it made disaster recovery easier, facilitated scaling up to capacity, and gave Vodafone Germany the agility to position IT activities for transformationnot just net-new digital initiatives but areas requiring deep integration to the legacy core. The organization did face challenges in the mi- gration, which included some legacy systems that didnt fit in a virtualized infrastructure. Those sys- tems would have required significant development costs to prepare them for migration. So, Vodafone Germany coupled the infrastructure effort with a broader modernization missionchanging legacy core applications so that they could serve as the foundation for new products, experiences, and cus- tomer engagement, or decommissioning end-of-life legacy systems. As they did so, Vodafone Germany built a new definition of their core and pushed their IT operating model to undergo a similar transfor- mation. LESSO N S FRO M TH E FRO N T LIN ES Reengineering technology 13 LE SS O N S FR O M T H E FR O N T LI N ES Most IT organizations are cautious about re- placing legacy systems due to the risks and business disruption, but we saw it as a way to accelerate the migration, says Vodafone Germany chief technol- ogy officer Eric Kuisch. Aging systems presented roadblocks that made it difficult or impossible to meet even four-to-six-month timeframes for new features. Our goal was to deliver initiatives in weeks or a couple of months. We believed that moderniza- tion of technology capabilities could improve time to market while lowering cost of ownership for IT.8 The next step in Vodafone Germanys modern- ization is an IT transformation for which it will in- vest in network virtualization, advanced levels of automation, and making the entire IT stack digital- ready. To accomplish so much so fast, Kuischs team chose a multi-modal IT model, incorporating both Agile and waterfall methodologies. They used an Agile framework for the front-end customer touch- points and online experience, while implementing the back-end systems legacy migration with the more traditional waterfall methodology. The com- pany undertook a massive insourcing initiative, putting resources into training its own IT team to create business architects to manage end-to-end service-level agreements for a service rather than for individual systems. Vodafone Germanys transformation will en- able the company to provide end-to-end customer experiences that were not possible with its legacy systems. The results so far have been increased ef- ficiency and significant cost savings. The infrastruc- ture virtualization alone realized a 3040 percent efficiency. The potential around improvements to digital experience, new feature time to market, and even new revenue streams are tougher to quantify but likely even more profound. Beachbodys digital reengineering workout Since 1998, Beachbody, a provider of fitness, nu- trition, and weight-loss programs, has offered cus- tomers a wide variety of instructional videos, first in VHS and then in DVD format. The companys busi- ness modelthe way it priced, packaged, and trans- actedwas to a large extent built around DVD sales. Roughly three years ago, Beachbodys leadership team recognized that people were rapidly changing the way they consumed video programming. Digi- tal distribution technology can serve up a much bigger catalog of choices than DVDs and makes it possible for users to stream their selections directly to mobile devices, TVs, and PCs. As a result of the new technology and changes in consumer behavior, Beachbody subsequently decided to create an on- demand model supported by a digital platform. From an architectural standpoint, Beachbody built the on-demand platform in the public cloud. And once the cloud-specific tool sets and team skills were in place, other teams began developing busi- ness products that also leverage the public cloud. Beachbody has developed its automation ca- pabilities during the last few years, thanks in part to tools and services available through the public cloud. For example, teams in Beachbodys data cen- ter automated several workload and provisioning tasks that, when performed manually, required the involvement of five or more people. As Beachbodys data center teams transitioned to the cloud, their roles became more like software engineers than sys- tem administrators. To create the on-demand model, Beachbody es- tablished a separate development team that focused exclusively on the digital platform. When the time came to integrate this team back into the IT orga- nization, they reorganized ITs operations to sup- port the new business model. IT reoriented teams around three focal areas to provide customers a consistent view across all channels: the front end, delivering user experiences; the middle, focusing on API and governance; and the back end, focusing on enterprise systems.9 Tech Trends 2018: The symphonic enterprise 14 Michael Dell, chairman and CEO DELL TECHNOLOGIES Digital transformation is not about ITeven though technology often is both the driver and the enabler for dramatic change. It is a boardroom conversation, an event driven by a CEO and a line-of-business executive: How do you fundamentally reimagine your business? How do you embed sensors, connectivity, and intelligence in products? How do you reshape customer engagement and outcomes? The wealth of data mined from the increasing number of sensors and connected nodes, advanced computing power, and improvements in connectivity, along with rapid advances in machine intelligence and neural networks, are motivating companies to truly transform. Its an overarching priority for a company to quickly evolve into a forward-thinking enterprise. Digital is a massive opportunity, to be sure, and most likely to be top of the executive teams agenda. But there are three other areas in which were seeing significant investment, either as stand-alone initiatives or as components of a broader digital transformation journey. We took a look at each of these to determine how we could best assist our customers in meeting their goals. Close to our heritage is helping IT itself transform to dramatically improve how organizations harness technology and deliver value. Companies want to use software-defined everything, to automate platforms, and to extrapolate infrastructure to code. It is not atypical these days for a company to have thousands of developers and thousands of applications but only a handful of infrastructure or operations resources. Of course, they still need physical infrastructure, but they are automating the management, optimization, and updating of that infrastructure with software. Our customers want to put their money into changing things rather than simply running them; they want to reengineer their IT stacks and organizations to be optimized for speed and results. In doing so, IT is being seen as BT business technology, with priorities directly aligned to customer impact and go-to-market outcomes. In doing so, IT moves from chore to coreat the heart of delivering the business strategy. The changing nature of work is driving the next facet of transformation. Work is no longer a place but, rather, a thing you do. Companies are recognizing they must provide the right tools to their employees to make them more productive. There has been a renaissance in people understanding that the PC and other client devices are important for productivity. For example, we are seeing a rise in popularity of thinner, lighter notebooks with bigger screens, providing people with tools to do great work wherever they are located. Companies are rethinking how work could and should get done, with more intuitive and engaging experiences, as business processes are rebuilt to harness the potential of machine learning, blockchain, the Internet of Things, digital reality, and cloud-native development. Last but definitely not least, we are seeing an increased interest in securing networks against cyber- attacks and other threats. The nature of the threats is constantly changing, while attack surfaces are growing exponentially due to embedded intelligence and the increased number of sensors and expansions in nodes. Security must be woven into infrastructure and operations. Companies are bolstering their own security-operation services with augmented threat intelligence, and they are segmenting, virtualizing, and automating their networks to protect their assets. We realize we need to be willing to change as well, and our own transformation began with a relentless focus on fulfilling these customer needs. At a time when other companies were downsizing and streamlining, Dell went big. We acquired EMC, which included VMware, and along with other technology assetsBoomi, Pivotal, RSA, SecureWorks, and Virtustreamwe became Dell Technologies. We created My take 15 a family of businesses to provide our customers with what they need to build a digital future for their own enterprise: approaches for hybrid cloud, software-defined data centers, converged infrastructure, platform-as-a-service, data analytics, mobility, and cybersecurity. Like our customers, we are using these new capabilities internally to create better products, services and opportunities. Our own IT organization is a test bed and proof-of-concept center for the people, process, and technology evolution we need to digitally transform Dell and our customers for the future. In our application rationalization and modernization journey, we are architecting global common services such as flexible billing, global trade management, accounts receivable, and indirect taxation, to deliver more functionality faster without starting from scratch each time. By breaking some components out of our monolithic ERPs, we significantly improved our time to market. We implemented Agile and DevOps across all projects, which is helping tear down silos between IT and the business. And, our new application development follows a cloud native methodology with scale out microservices. From a people standpoint, we are also transforming the culture and how our teams work to foster creative thinking and drive faster product deployment. If we dont figure it out, our competitors will. The good news: We now have a culture that encourages people to experiment and take risks. Ive always believed that the IT strategy must emanate from the companys core strategy. This is especially important as IT is breaking out of IT, meaning that a company cant do anythingdesign a product, make a product, have a service, sell something, or manufacture somethingwithout IT. Technology affects everything, not just for giant companies but for all companies today. The time is now to reengineer the critical technology discipline, and to create a foundation to compete in the brave new digital world. 1616 Reengineering technology RISK IM PLICATIO N S As we modernize technology infrastructure and operations, it is critical to build in modernized risk management strategies from the start. Given that nearly every company is now a technology company at its core, managing cyber risk is not an IT prob- lem but an enterprise-wide responsibility:  Executives, often with the help of the CIO, should understand how entering a new market, opening a new sales channel, acquiring a new company, or partnering with a new vendor may increase attack surfaces and expose the organi- zation to new threats.  CIOs should work with their cyber risk leaders to transform defensive capabilities and become more resilient.  Risk professionals should get comfortable with new paradigms and be willing to trade methodi- cal, waterfall-type approaches for context, speed, and agility. Increasingly, government and regulators expect executives, particularly those in regulated indus- tries, to understand the risks associated with their decisionsand to put in place the proper gover- nance to mitigate those risks during execution and ongoing operations. Historically, cyber risk has fallen under the pur- view of the information or network security team. They shored up firewalls and network routers, seek- ing to protect internal data and systems from exter- nal threats. Today, this approach to cybersecurity may be ineffective or inadequate. In many cases, or- ganizations have assets located outside their walls in the cloud or behind third-party APIsand end- points accessing their networks and systems from around the globe. Additionally, as companies adopt IoT-based models, they may be expanding their ecosystems to literally millions of connected de- vices. Where we once thought about security at the perimeter, we now expand that thinking to consider managing cyber risk in a far more ubiquitous way. From an architecture (bottom up) perspective, cloud adoption, software-defined networks, inten- sive analytics, tighter integration with customers, and digital transformation are driving IT decisions that expand the risk profile of the modern technol- ogy stack. However, those same advancements can be leveraged to transform and modernize cyber de- fense. For example, virtualization, micro-segmenta- tion, and infrastructure as code (automation) can enable deployment and teardown of environments in a far faster, more secure, more consistent, and agile fashion than ever before. Additionally, as part of a top-down reengineer- ing of technology operating and delivery models, risk and cybersecurity evaluation and planning should be the entire organizations responsibility. Development, operations, information security, and the business should be in lockstep from the begin- ning of the project life cycle so that everyone col- lectively understands the exposures, trade-offs, and impact of their decisions. To manage risk proactively in a modernized in- frastructure environment, build in security from the start:  Be realistic. From a risk perspective, acknowl- edge that some things are outside of your control and that your traditional risk management strat- egy may need to evolve. Understand the broader landscape of risks, your priority use cases, and revisit your risk tolerance while considering au- tomation, speed, and agility.  Adapt your capabilities to address in- creased risk. This could mean investing in new tools, revising or implementing technology management processes, and standing up new services, as well as hiring additional talent.  Take advantage of enhanced security capabilities enabled by a modern infra- structure. The same changes that can help IT become faster, agile, and more efficientauto- mation and real-time testing, for examplecan help make your systems and infrastructure more secure.  Build secure vendor and partner rela- tionships. Promote resilience across your sup- ply chain, and develop an operating model to determine how they (and you) would address a breach in the ecosystem. 17 G LO BA L IM PA CT The reengineering technology trend is a global phenomenon. In a survey of Deloitte leaders across 10 global regions, respondents consistently find companies in their market looking for opportuni- ties to enhance the speed and impact of technology investments. Several factors make the trend highly relevant across regions: increasing CIO influence, ITs desire to drive innovation agendas, and the scale and complexity of many existing IT portfolios and technology assets. Expected timeframes for adoption vary around the globe. Survey respondents in all regions are see- ing many companies express an active interest in adopting Agile or implementing DevOps, regardless of whether their investments in ITIL and IT service management are mature. In Asia Pacific and Latin America, this tension between desire and readiness may actually be impeding reengineering progress. In southern Europe, we are seeing some companies building digital teams that operate independently of existing processes and systems. North America is the only region where organizations across many industry sectors are taking on the kind of overarch- ing top-down and bottom-up transformation this chapter describes, though there are some emerging discrete examples elsewherefor example, in UK fi- nancial services and Asia high tech. Finally, survey results indicate that company readiness to embrace the reengineering technology trend differ region to region. Regional economic downturns of the last few years and weakened cur- rencies have compressed IT budgets in southern Europe and Latin America. Cultural dynamics and skillsets are also impacting trend readiness. For ex- ample, in northern Europe, factors range from po- tential delays due to hierarchical biases and a lack of executive mandates, to optimism and clear desire for change in companies where building and team- ing leadership styles are the norm. Broadly, howev- er, lack of expertise and landmark proof points are common obstacles to executing ambitious change. Deloitte Insights | Deloitte.com/insights Figure 2. Global impact Relevance Significant High Medium Low None Timeliness Now 1 year 12 years 25 years 5+ years Readiness Significant High Medium Low None N. America N. Europe C. Europe Israel Asia S. America S. Europe S. Africa Middle East Australasia Global impact measures Source: Deloitte analysis. Tech Trends 2018: The symphonic enterprise 18 Reengineering technology Where do you start? Reengineering IT shops from the top down and bottom up is no small order. Though a major goal of the reengineering trend is moving beyond in- cremental deployments and reacting to innovation and market demands, few companies likely have the resources to full-stop reengineer themselves in a single, comprehensive project. Before embarking on your journey, consider taking the following pre- liminary steps. Each can help you prepare for the transformation effort ahead, whether it be incre- mental or comprehensive.  Know thy organization: People react to change in different ways. Some embrace it en- thusiastically; others resist it. The same can be said for organizations. Before committing to any specific reengineering strategy, take a clear-eyed look at the organization you are looking to im- pact. Failure to understand its culture and work- ers can undermine your authority and make it difficult to lead the transformation effort ahead. Typically, IT organizations fall into one of three categories:  There is a will, but no way. The organiza- tion may operate within strict guidelines or may not react well to change; any shifts should be incremental.  If there is a will, there is a way. People in these IT shops may be open to change, but actually getting them to learn new tools or approaches may take effort.  Change is the only constant. These IT organiza- tions embrace transformational change and re- spond well to fundamental shifts in the way that IT and the business operate. By understanding an organizations culture, working style, and morale drivers, you can tai- lor your reengineering strategy to accommodate both technological and human considerations. This may mean offering training opportunities to help IT talent become more comfortable with new systems. Or, piloting greenfield develop- ment teams that feature rotational staffing to ex- pose workers from across IT to new team models and technologies.  Know thyself: Just as CIOs should understand their IT organizations, so should they under- stand their own strengths and weaknesses as leaders before attempting to reengineer a com- panys entire approach to technology. There are three leadership patterns that can add value in distinct ways:  Trusted operator. Delivers operational disci- pline within their organizations by focusing on cost, operational efficiency, and performance reliability. Also provides enabling technologies, supports business transformation efforts, and aligns to business strategy.  Change instigator. Takes the lead on tech- nology-enabled business transformation and change initiatives. Allocates significant time to supporting business strategy and delivering emerging technologies.  Co-creator. Spends considerable time collabo- rating with the business, working as a partner in strategy and product development, and execut- ing change across the organization. Examining your own strengths and weakness as a technology leader is not an academic exer- cise. With explicit understanding of different leadership patterns and of your own capabili- ties, you can better set priorities, manage rela- tionships, and juggle responsibilities. Moreover, this leadership framework may even inspire some constructive soul-searching into how you are spending your time, how you would like to spend your time, and how you can shift your fo- cus to deliver more value to your organizations.  Change your people or change your peo- ple? Most successful tech workers are success- ful in IT because they like change. Even so, many have gotten stuck in highly specialized niches, siloed functions, and groupthink. As part of any 19 Bottom line In many companies, ITs traditional delivery models can no long keep up with the rapid-fire pace of technology innovation and the disruptive change it fuels. The reengineering technology trend offers CIOs and their teams a roadmap for fundamentally overhauling IT from the bottom up and the top down. Pursued in concert, these two approaches can help IT address the challenges of today and prepare for the realities of tomorrow. reengineering initiative, these workers should changeor consider being changed out. Given reengineerings emphasis on automation, there should be plenty of opportunities for IT talent to upskill and thrive. Of course, its possible there will be fewer IT jobs in the future, but more of the jobs that remain will likely be more satisfy- ing oneschallenging, analytical, creativethat allow people to work with technologies that can deliver more impact than ever before. Tech Trends 2018: The symphonic enterprise 20 Reengineering technology KEN CORLESS Ken Corless is a principal with Deloitte Consulting LLPs Cloud practice and serves as the groups chief technology officer. As CTO, he specializes in evangelizing the use of cloud at enterprise scale, prioritizing Deloitte investment in cloud assets, and driving technology partnerships in the ecosystem. Corless has received industry accolades for his leadership, innovative solutions to business problems, and bold approaches to disruption, including being named to Computerworld Premier 100 IT Leaders and CIO Magazines Ones to Watch. JACQUES DE VILLIERS Jacques de Villiers is a managing director with Deloitte Consulting LLPs cloud and engineering service line and serves as the national leader of the Google Cloud practice. With deep domain and cloud experience, he helps clients transition applications and infrastructure from legacy and on premise environments to private and public clouds, leveraging Deloittes best-in-breed cloud methodologies along the way. CHRIS GARIBALDI Chris Garibaldi is a principal with Deloitte Consulting LLP and has more than 25 years of experience in business strategy and management. He also leads Deloittes enterprise platforms offering where he helps clients materially improve their business using the portfolio management, service management, and enterprise architecture competencies. Risk implications KIERAN NORTON Kieran Norton is a principal with the Cyber Risk Services practice for Deloitte Risk and Financial Advisory and has more than 20 years of industry experience. He also leads Deloittes infrastructure security offering, where he helps clients transform their traditional security approaches in order to enable digital transformation, supply chain modernization, speed to market, cost reduction, and other business priorities. AUTHORS 21 1. Khalid Kark, Charles Dean, Minu Puranik, and Caroline Brown, Taking charge: The essential guide to CIO transitions, Deloitte University Press, September 11, 2017. 2. Hammer and Co., The process concept, accessed October 8, 2017. 3. Ranjit Bawa, Jacques de Villiers, and George Collins, Autonomic platforms: Building blocks for labor-less IT, Deloitte University Press, February 24, 2016. 4. Ranjit Bawa, Scott Buchholz, Jacques de Villiers, Ken Corless, and Evan Kaliner, Inevitable architecture: Complexity gives way to simplicity and flexibility, Deloitte University Press, February 7, 2017. 5. John Hagel, Jeff Schwartz, and Josh Bersin, Navigating the future of work, Deloitte Review 21, July 31, 2017. 6. Atilla Terzioglu, Martin Kamen, Tim Boehm, and Anthony Stephan, IT unbounded: The business potential of IT transformation, Deloitte University Press, February 7, 2017. 7. Interview with Wayne Shurts, executive VP and chief technology officer, Sysco Corp., October 30, 2017. 8. Interview with Eric Kuisch, chief technology officer, Vodafone Germany, on November 2, 2017. 9. Interview with Gerry Campbell, chief technology officer, and Grant Leathers, VP of technology operations, Beach- body, October 13, 2017. ENDNOTES Tech Trends 2018: The symphonic enterprise 22 Reengineering technology 23 No-collar workforce Humans and machines in one loop collaborating in roles and new talent models WITH intelligent automation marching steadily toward broader adoption, me-dia coverage of this historic technology disruption is turning increasingly alarmist. New study: Artificial intelligence is coming for your jobs, millennials,1 announced one business news outlet recently. US workers face higher risk of being re- placed by robots,2 declared another. These dire headlines may deliver impressive click stats, but they dont consider a much more hopefuland likelyscenario: In the near future, human workers and machines will work together seamlessly, each complementing the others efforts in a single loop of productivity. And, in turn, HR organizations will begin developing new strategies and tools for recruiting, managing, and training a hybrid human-machine workforce. Notwithstanding sky-is-falling predictions, ro- botics, cognitive, and artificial intelligence (AI) will probably not displace most human workers. Yes, these tools offer opportunities to automate some re- petitive low-level tasks. Perhaps more importantly, As automation, cognitive technologies, and artificial intelligence gain traction, companies may need to reinvent worker roles, assigning some to humans, others to machines, and still others to a hybrid model in which technology augments human performance. Managing both humans and machines will present new challenges to the human resources organization, including how to simultaneously retrain augmented workers and to pioneer new HR pro- cesses for managing virtual workers, cognitive agents, bots, and the other AI-driven capabilities comprising the no-collar workforce. By redesigning legacy practices, systems, and talent models around the tenets of autonom- ics, HR groups can begin transforming themselves into nimble, fast-moving, dynamic organizations better positioned to support the talentboth mecha- nized and humanof tomorrow. No-collar workforce 25 Figure 1. A new mind-set for the no-collar workforce SocialContent, process, systemPsychomotor, sensory, physical CognitiveAbilities Skills Deloitte Insights | Deloitte.com/insights Humans and machines can develop a symbiotic relationship, each with specialized skills and abilities, in a unified workforce that delivers multifaceted benefits to the business. Social perceptiveness EmpathyPersuasion Emotional intelligence Negotiation ComputationFact recall Scalable processing capacity Management Complex problem-solving Active listening Critical thinking Judgment Handling ambiguity Ethics Applying expertise Operations analysis Pattern recognition Novelty detection Equipment operation & repair System design Routine reading comprehension Logic Structured inference Condition monitoring Data discovery Impartiality Category flexibility Oral & written comprehension Inductive & deductive reasoning Problem sensitivity Selective attention Oral & written expression Creativity Near visionSpeech clarity Perception Fine manual dexterity Regular object manipulation Basic speech Sound localization Reaction time Dynamic flexibility Night & peripheral vision Stamina Speech recognition Rate control Coordination Precision Strength ENHANCED ROLE SPECIALIZATION INTELLIGENT AUTOMATION INCREASED PRODUCTIVITY, INNOVATION, EFFICIENCY IMPROVED DECISION-MAKING HUMANS MACHINES Sources: Deloitte LLP, Talent for Survival: Essential skills for humans working in the machine age, 2016; Deloitte LLP, From brawn to brains: The impact of technology on jobs in the UK, 2015; Jim Guszcza, Harvey Lewis, and Peter Evans-Greenwood, Cognitive collaboration: Why humans and computers think better together, Deloitte University Press, January 23, 2017; Carl Benedikt Frey and Michael A. Osborne, The Future of Employment: How Susceptible are Jobs to Computerisation?, University of Oxford, September 17, 2013; O*NET, US Department of Labor. Tech Trends 2018: The symphonic enterprise 26 intelligent automation solutions may be able to aug- ment human performance by automating certain parts of a task, thus freeing individuals to focus on more human aspects that require empathic prob- lem-solving abilities, social skills, and emotional intelligence. For example, if retail banking transac- tions were automated, bank tellers would be able to spend more time interacting with and advising cus- tomersand selling products. Consider this: In a survey conducted for De- loittes 2017 Global Human Capital Trends report, more than 10,000 HR and business leaders across 140 countries were asked about the potential im- pact of automation on the future of work. Only 20 percent said they would reduce the number of jobs at their companies. Most respondents (77 percent) said they will either retrain people to use new tech- nology or will redesign jobs to better take advantage of human skills.3 Recent Deloitte UK research sug- gests that despite inroads by digital and smart tech- nologies in the workplace, essential human skills will remain important for the foreseeable future.4 The future that this research foresees has ar- rived. During the next 18 to 24 months, expect more companies to embrace the emerging no-collar workforce trend by redesigning jobs and reimag- ining how work gets done in a hybrid human-and- machine environment. For HR organizations in particular, this trend raises a number of fundamental questions. For ex- ample, how can companies approach performance management when the workforce includes bots and virtual workers? What about onboarding or retir- ing non-human workers? These are not theoretical questions. One critical dimension of the no-collar workforce trend involves creating an HR equivalent to support mechanical members of the worker co- hort. Given how entrenched traditional work, career, and HR models are, reorganizing and reskilling workers around automation will likely be challeng- ing. It will require new ways of thinking about jobs, enterprise culture, technology, and, most impor- tantly, people. Even with these challenges, the no- collar trend introduces opportunities that may be too promising to ignore. What if by augmenting a humans performance, you could raise his produc- tivity on the same scale that we have driven produc- tivity in technology? As they explore intelligent automations possibil- ities, many of those already embracing the no-collar trend no longer ask what if. For these pioneering companies, the only question is, How soon? Workers (and bots) of the world, unite! According to the 2017 Global Human Capital Trends report, 41 percent of executives surveyed said they have fully implemented or have made sig- nificant progress in adopting cognitive and AI tech- nologies within their workforce. Another 34 percent of respondents have launched pilot programs. Yet in the midst of such progress, only 17 per- cent of respondents said they are ready to manage a workforce in which people, robots, and AI work side by side.5 At this early stage of the no-collar workforce trend, there is no shame in being counted among the 83 percent who dont have all the answers. Giv- en the speed with which AI, cognitive, and robotics are evolving, todays clear-cut answers will likely have limited shelf lives. Indeed, this trend, unlike some others examined in Tech Trends 2018, is more like a promising journey of discovery than a clearly delineated sprint toward a finish line. Every company has unique needs and goals and thus will approach questions of reorganization, talent, tech- nology, and training differently. There are, however, several broad dimensions that will likely define any workforce transformation journey: Culture. Chances are, your company culture is grounded in humans working in defined roles, per- forming specific tasks within established processes. These workers likely have fixed ideas about the na- ture of employment, their careers, and about tech- nologys supporting role in the bigger operational No-collar workforce 27 picture. But what will happen to this culture if you begin shifting some traditionally human roles and tasks to bots? Likewise, will workplace morale suf- fer as jobs get redesigned so that technology aug- ments human performance? Finally, is it realistic to think that humans and technology can complement each other as equal partners in a unified seamless workforce? In the absence of hard answers to these and similar questions, workers and management alike often assume the worst, hence the raft of AI Will Take Your Job headlines. The no-collar trend is not simply about deploy- ing AI and bots. Rather, it is about creating new ways of working within a culture of human/machine col- laboration. As you begin building this new culture, think of your hybrid talent base as the fulcrum that makes it possible for you to pivot toward the digi- tal organization of the future. Workers accustomed to providing standard responses within the con- straints of rigid processes become liberated by me- chanical co-workers that not only automate entire processes but augment human workers as they per- form higher-level tasks. Work culture becomes one of augmentation, not automation. As they acclimate to this new work environment, humans may begin reflexively looking for opportunities to leverage au- tomation for tasks they perform. Moreover, these human workers can be held accountable for improv- ing the productivity of their mechanical co-workers. Finally, in this culture, management can begin rec- ognizing human workers for their creativity and social contributions rather than their throughput (since most throughput tasks will be automated). Tech fluency. As companies transition from a traditional to an augmented workforce model, some may struggle to categorize and describe work in a way that connects it to AI, robotic process automa- tion (RPA), and cognitive. Right now, we speak of these tools as technologies. But to understand how an augmented workforce can and should operate, we will need to speak of these technologies as com- ponents of the work. For example, we could map machine learning to problem solving; RPA might map to operations management. But to categorize technologies as components of work, we must first understand what these technol- ogies are, how they work, and how they can poten- tially add value as part of an augmented workforce. This is where tech fluency comes in. Being fluent in your companys technologies means understand- ing critical systemstheir capabilities and adjacen- cies, their strategic and operational value, and the particular possibilities they enable.6 In the context of workforce transformation, workers who possess an in-depth understanding of automation and the specific technologies that enable it will likely be able to view tech-driven transformation in its proper strategic context. They may also be able to adjust more readily to redesigned jobs and augmented processes. Today, many professionalsand not just those working in ITare dedicated to remaining tech fluent and staying on top of the latest innovations. However, companies planning to build an augment- ed workforce cannot assume that workers will be sufficiently fluent to adapt quickly to new technolo- gies and roles. Developing innovative ways of learn- ing and institutionalizing training opportunities can help workers contribute substantively, creatively, and consistently to transformational efforts, no matter their roles. This may be particularly impor- tant for HR employees who will be designing jobs for augmented environments. HR for humans and machines. Once you begin viewing machines as workforce talent,7 you will likely need to answer the following questions about sourcing and integrating intelligent machines into your work environments:  What work do we need to do that is hard to staff and hard to get done? What skills do we need to accomplish the work? How do we evaluate if a prospective hires skills match the skills we are looking for?  How do we onboard new members of the work- force and get them started on the right foot?  How do we introduce the new talent to their colleagues? Tech Trends 2018: The symphonic enterprise 28 No-collar workforce  How do we provide new hires with the secu- rity access and software they need to do their jobs? How do we handle changes to access and audit requirements?  How do we evaluate their performance? Like- wise, how do we fire them if they are not right for the job? These questions probably sound familiar. HR organizations around the world already use them to guide their recruiting and talent management pro- cesses for human workers. As workforces evolve to include mechanical tal- ent, HR and IT may have to develop entirely new ap- proaches for managing these workersand the real risk of automating bad or inaccurate processes. For example, machine learning tools might begin deliv- ering inaccurate outcomes, or AI algorithms could start performing tasks that add no value. In these scenarios, HR will manage automated workers by designing governance and control capabilities into them. Meanwhile, HR will continue its traditional role of recruiting, training, and managing human work- ers, though its approach may need to be tailored to address potential issues that could arise from aug- mentation. For example, augmented workers will likely need technology- and role-specific training in order to upskill, cross-train, and meet the evolving demands of augmented roles. Likewise, to accurate- ly gauge their performance, HRworking with IT and various team leadersmay have to create new metrics that factor in the degree to which augmen- tation reorients an individuals role and affects her productivity. Keep in mind that metrics and roles may need to evolve over time. The beauty and challenge of cognitive workers is they are constantly working and developing an ever more nuanced approach to tasks. In terms of productivity, this is tremendous. But in the context of augmentation, what happens to the human role when the augmenting technol- ogy evolves and grows? How will metrics accurately gauge human or machine performance when tasks and capabilities are no longer static? Likewise, how will they measure augmented performance (hu- mans and machines working in concert to achieve individual tasks)? Leading by example Just as the no-collar trend may disrupt IT, fi- nance, and customer service, so too could it disrupt HR organizations, their talent models, and the way they work. Some HR organizations are already play- ing leading roles in enterprise digital transforma- tion. Likewise, many are developing new approach- es for recruiting digital talent, and are deploying apps and a variety of digital tools to engage, train, and support employees. But in terms of process and tools, the opportunities that AI, cognitive, and ro- botics offer make HRs digitization efforts to date seem quaint. In the near future, HR will likely begin redesigning its own processes around virtual agents, bots, and other tools that can answer questions, execute transactions, and provide training, among many other tasks traditionally performed by human workers. What about using cognitive tools to manage me- chanical workers? Another intriguing possibility in the no-collar workforce of the future. 29 Skeptics corner The word automation is a loaded term these days. To some, it inspires hopeful thoughts of turbocharged efficiency and bottom-line savings. To others, it conjures images of pink slips. With your indulgence, we would like to correct a few common misconceptions about this evocative word and the no-collar workforce trend with which it is associated. Misconception: Theres a long history of workers being replaced by automation. Isnt reducing labor costs the entire point of automating? Reality: You are assuming that AI, cognitive technologies, and robots can do everything human workers can do, only more cheaply and quickly. Not true, by a long shot. At present, technology cannot duplicate many uniquely human workplace strengths such as empathy, persuasion, and verbal comprehension. As the no-collar trend picks up steam, companies will likely begin redesigning jobs around unique human capabilities, while looking for opportunities to augment these capabilities with technology. Misconception: Robotics and cognitive technologies fall under ITs domain. Whats HR got to do with this? Reality: Yes, IT will play a lead role in the deployment and maintenance of these technologies. But in an augmented workforce, the traditional boundary between humans and machine disappears. The two types of workers work symbiotically to achieve desired goals. Integrating people and technology becomes an interdisciplinary task, with HR taking the lead in redesigning jobs and training the augmented workforce. Misconception: I can understand why some workers should develop their tech fluency. But all workers? That seems like a waste of time and resources. Reality: The strongest argument for all workers becoming more tech fluentand for their employers to create learning environments to help them on this journeyis this: In the absence of a shared understanding of enterprise technologies and their possibilities, companies cannot nurture the collective imagination necessary to move toward a new strategic and operational future. Becoming conversant in technology can help workers of all backgrounds understand not only the realities of today but the possibilities of tomorrow. Tech Trends 2018: The symphonic enterprise 30 NASAs space-age workforce One of NASAs newest employees works at the Stennis Space Center. Fully credentialed, he oper- ates out of Building 1111, has an email account, and handles mainly transactional administrative tasks. His name is George Washington, and hes a bot. Rather than viewing bots as a replacement for people, I see them as a way to simplify work, says Mark Glorioso, executive director of NASA Shared Services Center (NSSC). We are building bots that will make our people more effective, so as we grow, we are able to do more without adding staff. George is one of a small team of bots that NASA has developed to take on rote, repetitive bookkeep- ing and organizational tasks so human workers may focus on higher-level, strategic activities. Con- ceived two years ago as part of NSSCs drive to op- timize budgetary resources, the bots-as-a-service program started to take shape in May 2017 when George went to work. Soon, Thomas Jefferson and other bots joined him. Gloriosos team chose to start small so they could measure the return on investment, as well as help ensure the bots would not inadvertently add to ITs workload. They identified opportunities to integrate bots by creating journey maps and break- ing up processes into analytical pieceslooking for tasks that could be automated. Georges responsi- bilities include cutting and pasting job candidates suitability reports from emails and incorporating the information into applications for the HR team. The other bots tasks include distributing funds for the CFOs office and automating purchase requests for the CIOs team. Tasks that took hours for a hu- man to complete now take just minutes. NASA has started to deploy bots throughout the agency. A decentralized approach allows the NSSCs 10 centers to decide how they want to reposition their staff members, then lets them build their own bots according to the tasks they choose to automate. Each center runs its bots off a single bot community, so the initial investment is shared. Because each task may require robots with different skills, cen- ters can choose software vendors that specialize in specific areas, such as finance. Gloriosos team en- sures that all bots across the 10 centers meet NASA standards, then pushes them into production and manages them. This allows NSSC to scale the bots program as needed. Rather than investing in infra- structure, the center invests in one bot at a time. The buy-in of the human workforce has been a priority for NSSC from the start. Gloriosos team demonstrated the bots for the business leads of the centers major units, then let the leads present the technology to their own teams. They also instituted Lunch and Learn sessions to educate employees LESSO N S FRO M TH E FRO N T LIN ES LESSO N S FRO M TH E FRO N T LIN ES No-collar workforce 31 on the benefits of bots and demonstrate how they work. Staff quickly embraced the bot program as a way to automate repetitive, time-consuming tasks and actively suggested transactions that could be augmented with worker bots. Although credentialed like human workers, the bots have performance reviews skewed to different metrics. For example, Gloriosos team is consider- ing turning over password resets to the bots. A bot should be able to handle many more password re- sets than a human employee, so a higher level of turnaround will be expected of them. However, the quality of the user experience will be the ultimate test. If users find it difficult to communicate with the bots, the experiment wont be considered a suc- cess. Glorioso says there will always be a need for humans on his teamtheir expertise is needed to approve budgetary requests, bring in new business, and assist the bots when there are unusual rules ex- ceptions. As the program grows, Glorioso sees po- tential job creation in the areas of bot-building and bot-performance management: Id like to think ul- timately we will hire people who can bot-ify their own transactions. For now, we build the bots and show everyone how they can help. We are giving them a reason to build their own bot.8 Exelon Utilities powers up the bots Exelon provides power generation, energy sales, transmission, and delivery in 48 states, Washington, DC, and Canada. The company champions compe- tition as a way to meet economic and environmen- tal policy objectives, so driving efficiencies is key to achieving its overall mission. These efficiencies include optimizing its workforce to fuel innovative thinking. After seeing success with its Strategic Sup- plier Programin which Exelon outsourced trans- actional work to free up IT employees for creative and analytical taskscompany leadership has be- gun exploring opportunities to augment its human workforce with bots. Innovation isnt a group in an ivory towerin- novation is everyones job, says Mark Browning, Exelon Utilities VP of IT and chief information of- ficer. Its an expectation that we all innovate across the organization to reinvent ourselves as a utility. The only way to get there is to let go of transactional work and migrate resources to value-added work that helps the business achieve even greater perfor- mance and higher levels of service for our custom- ers.9 Exelons CEO has charged leadership through- out the enterprise with exploring the potential of robotic process automation to drive efficiencies and cost savings. The organization recently completed a multi-month assessment to identify areas of op- portunity for deploying bots, and the IT organiza- tion is facilitating an initiative to build out pilots. A number of departmentsIT, finance, supply chain, human resources, legal, risk, and communications are evaluating their processes to recommend pos- sible use cases that could prove out the capabilities and benefits. With work time-sliced across several different individuals, a key part of the roadmap is not just identifying what tasks are ripe for automa- tion but determining how to adjust job definitions, how employees are organized, and how to navigate through the cultural implications. We were able to outsource transactional IT work, reduce costs, and redeploy employees to higher-val- ue work, and we believe we can do that again as we shift to a robotic model, Browning says. We want LE SS O N S FR O M T H E FR O N T LI N ES Tech Trends 2018: The symphonic enterprise 32 No-collar workforce LESSO N S FRO M TH E FRO N T LIN ES LESSO N S FRO M TH E FRO N T LIN ES to use RPA to offer employees the opportunity to do more challenging, satisfying work that directly con- tributes to the organizations success. As Exelon builds a business case showing con- crete return on investment, leaders are grappling with how the bots fit into its organizational struc- ture. Its not just a technology issuethis affects our people and our mission. Browning sees a future in which RPA has ma- tured within the organization, enabling his team to build out capabilities that leverage Exelons invest- ments in big data, machine learning, next-genera- tion ERP, the Internet of Things, and other tech- nologiesintersecting to create a closed-loop cycle that could have an impact on business outcomes, he says. We believe its a core competency we want to own and mature. We need to do this right, because RPA is as much about technology challenges and as it is about change management and cultural shifts. 33 The Center for Cyber Safety and Education has predicted that there will be 1.8 million unfilled cy- bersecurity positions by 2022.10 An augmented workforceone in which automation can carry out rote tasks to free up human workers for higher-level activitiescould help fill that demand. However, corporations should consider how this no-collar workforce could change the dynamic of their exist- ing operations. CULTURAL This new way of working already is affecting how the workforce interacts and engages. Its not un- common for employees to communicate with their teammates solely via email, social collaboration ap- plications, or instant message, with unclear impacts on creative collaboration. This can be further com- plicated when teammates are bots, a development that could stymie knowledge sharing. For example, a cyber professionals job includes collaborating with peers to build knowledge of attack mechanisms and to develop creative solutions. When automation replaces those functions, there may be less opportu- nity for interactive collaboration, which could affect the teams effectiveness. However, with effective training of people and ongoing training and calibra- tion of the machines, the two working together can help effectively execute a broader cyber strategy. Additionally, teams augmented with robotic process automation could experience friction de- rived from the dynamic of mission-based humans versus rules-based bots. When humans perform a cybersecurity-related task, they can apply a sense of mission as well as judgment in executing their task, make exceptions when necessary, and change course quickly to react to immediate threats. But bots often possess limited situational awareness and may be unable to make decisions regarding ex- ceptions. It is critical to automate tasks only after evaluating which functions may require a humans judgment and capacity for decision-making. CYBER Bots can help mitigate cyber risk by automating control activities to facilitate reliability, consistency, and effectiveness. RPA capabilities can enable cyber automation, such as processing vast threat intelli- gence sources. But bots themselves could be targets in an attack, exposing sensitive employee and customer data that could damage a companys reputation. Protecting bot workers, IoT devices, applications, and net- workswhether on-premises or in far-flung virtual officesbecomes paramount. Controls should be built in from the start, and then continuously moni- tored, tested, and adapted to new challenges as they emerge. Because this entails more than equipment decisions, comprising policy and personnel strate- gies as well, business and IT should work together closely to define cyber workplace guidelines to miti- gate risk. LEGAL AND REGULATORY As we automate tasks and augment workers, new regulatory and compliance issues may emerge. Privacy issues, for example, could be a concern, particularly for global organizations subject to the European Unions General Data Protection Regu- lation. Workplace bots collecting and processing data through sensors, devices, cameras, and even microphones could inadvertently collect work- ers personal data, which may violate privacy laws in some countries. Additionally, bots performing tasks in highly regulated industries, such as finance, could prove liabilities if a network outage or equip- ment failure results in a breakdown of automated oversight functions. Finally, labor laws could evolve around as-yet-unanticipated issues as human work- ers increasingly collaborate with their robot coun- terparts. Despite this uncharted territory, the no-collar workforce can help enhance cybersecurity planning and response and could improve overall risk man- agement. Automation of functions such as threat intelligence, security application monitoring, and privilege management may result in greater consis- tency, reliability, and coverage. RI SK IM PL IC AT IO N S Tech Trends 2018: The symphonic enterprise 34 No-collar workforce G LO BAL IM PACT Robotic process automation is changing the way we work around the world. Findings from a survey of Deloitte leaders across 10 regions show that au- tomation is affecting most regions, to some degree, across a variety of industries. Cognitive computing and artificial intelligence are not as widespread, but the no-collar workforce is a trend that global orga- nizations likely will need to address if they want to stay competitive. In Latin America, robotic process automation is of interest to mining and resource companies that require big data for critical decision-making. In Central Europe, robotics and cognitive automation will likely affect the large number of shared service centers and business process outsourcing provid- ers located in the region. Likewise, the talent pool likely will shift from supporting simple processes to delivering solutions that require skills such as criti- cal thinking. This is true for Northern Europe, as well, which expects new roles to emerge as global, around-the-clock, man-and-machine workforces develop; part of this change could involve a more prominent role for IT organizations. Australias in- creasing prioritization of customer and employee experiences, coupled with lower barriers to entry for cloud technologies, is fueling the adoption of augmenting and enabling technologies. In Africa, the no-collar workforce presents com- plex challenges within developing markets with high unemployment rates. Highly regulated labor environments could present obstacles, although the regions technology readiness and availability of cloud platforms could make it possible for organiza- tions to gear up for this much-needed transforma- tion. Most respondents see RPA being widespread within a year or two, with artificial intelligence and cognitive computing taking a bit longerfrom two to five years. All regions expect that some degree of upskilling will be necessary to make the shift. Deloitte Insights | Deloitte.com/insights Figure 2. Global impact Relevance Significant High Medium Low None Timeliness Now 1 year 12 years 25 years 5+ years Readiness Significant High Medium Low None N. America N. Europe C. Europe Israel Asia S. America S. Europe S. Africa Middle East Australasia Global impact measures Source: Deloitte analysis. 35 Where do you start? Building a no-collar workforce requires deliber- ate planning. Machines and humans can work well together if you anticipate the challenges and put in place the resources and governance to make all elements of the hybrid workforce successful. The following initial steps can provide a framework for deconstructing existing roles into underlying jobs, determining which are uniquely human and which can be redesigned for augmentation.  Assess your needs: Is the no-collar trend a viable option for your company? To answer this question, identify all the areas in your organi- zation where mission-critical activities that do not contain uniquely human work elements oc- cur. Are there opportunities to augment human performance in these areas? If so, are the oppor- tunities compelling? In some companies, aug- mentation opportunities are potentially trans- formative; in others, not so much. Remember: Let needs, not technology, drive your strategy.  Understand how work currently gets done: For each task within a given process, identify who is performing the task, the skills re- quired to complete the task, and the technologies enabling not only this specific task but adjacent or dependent tasks within the larger process. This informational baseline will help you chal- lenge your own assumptions about existing pro- cesses, and then explore different talent options and technologies that can be used in concert to improve overall process efficiency. It may also spark fresh ideas about the impact that automa- tion will have on your organizational structure.  Categorize skills and tasks: Define the dif- ference between skills that only humans have, such as ethical or creative thinking, and nones- sential tasks that machines can perform. Under- standing that difference can eventually help you redesign jobs, identify opportunities for aug- mentation, and develop automation strategies.  Investigate tools and tactics: What cogni- tive technologies and advanced robotics solu- tions are currently used in your industry? What new advances appear on the horizon? The speed of technological innovation is bringing disrup- tive tools online faster than ever. In this environ- ment, IT, HR, and business leaders should stay up to speed on advances in intelligent automa- tion, and try to identify how emerging capabili- ties and concepts could impact productivity and job design at their companies.  Easy does it or full steam ahead? Different smart technologies require different approaches. Are you sufficiently ambitious to explore oppor- tunities for brute force automation initiatives involving bots? Or does your ambition (and per- haps your budget) align more closely with less disruptive deployments of cognitive technolo- gies or AI? Which approach better supports your organizations overall mission and strategic pri- orities? Bottom line Advances in artificial intelligence, cognitive technologies, and robotics are upending time-honored assumptions about jobs, careers, the role of technology in the workplace, and the way work gets done. The no-collar trend offers companies the opportunity to reimagine an entirely new organizational model in which humans and machines become co-workers, complementing and enhancing the others efforts in a unified digital workforce. Tech Trends 2018: The symphonic enterprise 36 No-collar workforce ANTHONY ABBATIELLO Anthony Abbatiello is a principal with Deloitte Consulting LLP and serves as the digital leader for the Human Capital practice. He advises global clients on building high-performance digital businesses that drive growth and transformation through leadership development, human resources, and talent management. Abbatiello is a regular talent blogger on Huffington Post and a global eminence leader on topics such as the digital organization, leadership development, and global talent management. TIM BOEHM Tim Boehm is a principal with Deloitte Consulting LLP and leads Deloittes Application Management Services for Energy & Resources, including IT advisory and application development, and maintenance and portfolio management services. He also leads Deloittes AMS automation program, using the latest technology to drive exponential improvement in the IT function. JEFF SCHWARTZ Jeff Schwartz is a Human Capital principal with Deloitte Consulting LLP and leads the US future of work research and consulting services. Previously, he led the Human Capital global delivery centers and served as an adviser to the Consulting practice in India. Schwartz is a founder of and a US managing partner for the US Israel Innovation Collaboration. Risk implications SHARON CHAND Sharon Chand is a principal with Deloittes Cyber Risk Services practice and helps critical infrastructure providers be secure, vigilant and resilient. She is a CISSP with more than 20 years of experience helping global clients manage their cyber risks. Chand focuses on policy and risk governance implementation, cyber threat monitoring, vulnerability management, identity and access management, and data protection within the energy industry. AUTHORS 37 1. Vanessa McGrady, New study: Artificial intelligence is coming for your jobs, millennials, Forbes, June 9, 2017. 2. Alanna Petroff, US workers face higher risk of being replaced by robots: Heres why, CNN Tech, March 24, 2017. 3. Jeff Schwartz, Laurence Collins, Heather Stockton, Darryl Wagner, and Brett Walsh, The future of work: The aug- mented workforce, Deloitte University Press, February 28, 2017. 4. Angus Knowles-Cutler and Harvey Lewis, Talent for survival: Essential skills for humans working in the machine age, Deloitte UK, 2016. 5. Schwartz et al., The future of work: The augmented workforce. 6. Daniel Newman, What technology can teach us about employees of the future, Forbes, November 29, 2016. 7. David Schatsky and Jeff Schwartz, Machines as talent: Collaboration, not competition, Deloitte University Press, February 27, 2015. 8. Interview with Mark Glorioso, executive director of NASA Shared Services Center, September 18, 2017. 9. Interview with Mark Browning, vice president of IT and chief information officer, Exelon Utilities, November 14, 2017. 10. Center for Cyber Safety and Education, Global cybersecurity workforce shortage to reach 1.8 million as threats loom larger and stakes rise higher, June 7, 2017. ENDNOTES Tech Trends 2018: The symphonic enterprise 38 No-collar workforce 39 Enterprise data sovereignty If you love your data, set it free WE have entered a new age of digital en-lightenmentone driven by ever-grow-ing volumes of data and the valuable customer, strategic, and operational insights that information contains. In this new age, not only is there more data than ever beforeit is being gener- ated by a wider variety of sources, making it more revealing. As Deloittes 2017 Tech Trends report explored, insight-rich data from transactional sys- tems, industrial machinery, social media, IoT sen- sorsand from nontraditional sources such as im- ages, audio, video, and the deep webincreasingly informs decision-making and helps chart new paths to the future.1 To those already on the path to digital enlight- enment, it is becoming increasingly clear that to realize its full potential, data should be freefree not in a monetary sense but, rather, in terms of ac- cessibility and ubiquity. At a time when traditional boundaries separating organizational domains are coming down, it becomes more important than ever to expose data widely so that analysts can use it to create value. Yet even when data is free, we have to make sense of it. Traditionally, making sense of data meant imposing upon it top-down, canonical defi- nitions and hierarchies of access rights and creat- ing layer upon layer of governance protocols. This As every organization recognizes data as a key asset, there is an increas- ing demand to free itto make information accessible, understandable, and actionable across business units, departments, and geographies. This requires modern approaches to data architecture and data governance that take advantage of machine learning, natural language processing, and auto- mation to dynamically understand relationships, guide storage, and manage rights. Those same capabilities are needed to navigate changing global regula- tory and legal requirements around data privacy and protection. Enterprise data sovereignty 41 Dewey Decimal System-esque approach has been, in essence, just a formalized way to try to control chaos using brute force. We expect that, in the next 18 to 24 months, more companies will begin modernizing their ap- proaches to data management, working to strike the right balance between control and accessibility. As part of the growing trend toward enterprise data sovereignty, these companies will develop deliber- ate techniques for managing, monetizing, and un- locking the value of an increasingly vital enterprise asset. Their efforts will focus on solving data challeng- es in three domains: management and architecture, global regulatory compliance, and data ownership. The challenges that many organizations encounter in each of these areas are varied and persistent. For example:  How can we expose data across organizational boundaries and functional domains while still managing it deliberately and effectively?  How can we automate laborious and often man- ual data classification and stewardship tasks?  How can we, as a global company, comply with regulatory and privacy requirements that differ dramatically by nation?  Who in the enterprise is ultimately responsible for all this data? Does the CIO own it? The COO? Anybody at all? The enterprise data sovereignty trend offers a roadmap that can help companies answer these and other questions as they evolve into insight- driven organizations. Without a doubt, this transi- tion will require long-term investments in data in- tegration, cataloging, security, lineage, augmented stewardship, and other areas. But through these investments, companies can create a dynamic data management construct that is constantly evolving, learning, and growing. Data, then and now IT departments developed traditional data man- agement techniques when data volumes were still relatively small. In this simpler time, structured business data typically lived in tables or basic sys- tems. Even then, strategists, CIOs, and other decision- makers struggled to get their armsand heads around it. Many companies took one of two basic approaches for dealing with data: Laissez-faire. Decision-makers accepted that data management was messy and difficult, so rather than face its challenges deliberately, they built one- off systems to address specific needs. Data ware- houses, operational data stores, reports, and ad-hoc visualization ruled the day, requiring behind-the- scenes heroics to rationalize master data, cleanse dirty data, and reconcile discrepancies. Brute force. Recognizing datas greater poten- tial, some companies triedwith mixed success to get their arms around the data they possessed by creating a citadel in which data was treated as scripture. All processes were strict and regimented, which worked when all data was structured and uni- form but became difficult to sustain when different types of data entered the system. To maintain data consistency and quality, companies relied heavily on mandates, complex technologies, and manual procedures. Fast-forward two decades. Both of these ap- proaches have proven inadequate in the age of big data, real-time reporting, and automation, espe- cially as data continues to grow in both volume and strategic importance. Moreover, this phenomenon is encompassing all industries and geographies. Consider the automobile, which has in recent years become less a machine than a sensor-laden, data- spewing computer on wheels. Recently, Toyota, Ericsson, and several other companies announced that they will jointly develop new data management Tech Trends 2018: The symphonic enterprise 42 Enterprise data sovereignty architectures to accommodate an expected explo- sion of automotive-generated data. It is estimated that the data volume between vehicles and the cloud will reach 10 exabytes per month around 2025, ap- proximately 10,000 times larger than the present volume, the consortium reported.2 To be clear: 10XB is 10 billion gigabytesfrom cars alone, every month. IDC offers a macro view, predicting that by 2025, the world will create and replicate 163 zettabytes of data annually (a ZB is 1 trillion gigabytes), repre- senting a 10-fold increase over the annual amount of data generated just nine years earlier.3 With this data tsunami approachingor already here, depending on whom you askforward-think- ing companies can launch their enterprise data COGNITIVE DATA STEWARD Deloitte Insights | Deloitte.com/insightsSource: Deloitte analysis. Traditional Advanced Figure 1. The new data management architecture Traditional data management provides basic but critical information, built on manual intervention and regimented storage and processes. As part of an advanced data management architecture, a cognitive data steward and dynamic data fabric can help an enterprise gain insights on a deeper level and transform decision-making. DATA SOURCES DATA ACQUISITION DYNAMIC DATA FABRIC SEMANTIC LAYER ENTERPRISE INTELLIGENCE The dynamic data fabric creates a data dictionary that maintains metadata. It then identifies linkages in the data using semantic matching algorithms. The solution uncovers and visualizes multidimensional relationships among data. Data volume, variety, and complexity For processes such as entity resolution, an algorithm sorts data into clusters based on a set threshold for matches. A human data steward reviews and manually accepts or rejects clusters, training the algorithm with these actions. The algorithm improves itself and uses the same process to automate additional tasks like governance and oversight. 43 sovereignty journeys by answering the following foundational questions about advanced data man- agement and architecture, global regulatory compli- ance, and ownership: What will advanced data management and architecture look like in my company? When we speak of data management in the context of enterprise data sovereignty, we are talking about much more than how and where data is stored. We are also describing:  Sourcing and provisioning of authoritative data (for example, batch, real-time, structured, un- structured, and IoT-generated), plus reconcilia- tion and synchronization of these sources  Metadata management and lineage  Master data management and unique identifiers  Information access and delivery (for example, analytics and upstream/downstream consum- ing applications)  Security, privacy, and encryption  Archiving and retention Using traditional data management tools and techniques, these complex tasks often require man- ual intervention. Moving to the cloud or adopting a federated system can add additional layers of com- plexity. As companies explore ways to deploy new tools and redesign their data management architectures, they should think less about organizing data into specific structures, instead focusing on deploy- ing tools within new architectures to automate the decision-making processes in sourcing, storing, and governance. Though architectures vary by need and capability, most advanced data management archi- tectures include the following components:  Ingestion and signal processing hub: Sourcing and ingestion solutions for structured and unstructured public, social, private, and de- vice data sources; can include natural language processing and text analytics capabilities.  Dynamic data fabric: Solutions that dynami- cally build a data dictionary across the enter- prise while maintaining metadata and linkages. Using data discovery solutions, ontologies, and visualization tools, a dynamic data fabric ex- plores and uncovers multidimensional relation- ships among data. It also depicts these relation- ships using interactive technologies and spatial, temporal, and social network displays.  Data integrity and compliance engine: Ca- pabilities to enhance data quality and fill data gaps to ensure quality and integrity while main- taining regulatory compliance.  Cognitive data steward: Cognitive technolo- gies that help users understand new compliance requirements, and augment human data stew- ardship by defining data quality and compli- ance rules. Cognitive data stewardsdeployed in tandem with machine intelligence, bots, and other technologiescan automate many tra- ditionally manual governance, oversight, and accountability tasks.  Enterprise intelligence layer: Machine learning and advanced analytics solutions that il- luminate deeper data insights, which can lead to more confident decision-making and real-time action. Among other tasks, the enterprise intelli- gence layer dynamically builds master data, cat- alogs, lineage, and security profiles, identifying changes in usage, consumption, and compliance. Who should own data in my organiza- tion? Currently, many organizations employ a data steward who focuses primarily on data quality and uniformity. While this individual may not own data in the enterprise, she is the closest thing the company has to a data authority figure. With data increasingly a vital business asset, some organiza- tions are moving beyond simple data management and hiring chief data officers (CDOs) to focus on il- luminating and curating the insights the data can yield. Increasingly, CDOs develop data game plans for optimizing collection and aggregation on a glob- al scale; this includes leveraging both structured and unstructured data from external sources. Fi- nally, a CDOs data game plan addresses geographic and legal considerations about storage. Tech Trends 2018: The symphonic enterprise 44 Enterprise data sovereignty How do global companies meet regulato- ry requirements that vary widely by nation? Data hosted on cloud services and other Internet- based platforms is subject to the jurisdiction of the countries where the data is hosted or stored. As straightforward as this may sound, global regula- tion of data remains a persistently thorny issue for business. Several key questions must be addressed: Who has ownership rights to data? Who is permit- ted to access data stored in another country? Can a host country lay claim to access the data of a third country that might not be on the same continent as the host nation? There are surprisingly few easy an- swers. On May 25, 2018, the European Union will, de- pending on whom you talk to, either bring welcome clarity to such issues or add yet another layer of regulatory complexity to data management regimes worldwide. On this day, a body of data privacy and usage laws known as the General Data Protection Regulation (GDPR) goes into effect,4 aiming to pre- vent companies from collecting, processing, or us- ing consumer data without first obtaining consent from the individual to whom the data pertains. And it doesnt matter whether the data is stored on serv- ers located outside of the EUif the data pertains to an EU citizen, GDPR rules apply. Failure to abide by GDPR rules can lead to staggering fines: up to 4 percent of company revenues or a maximum of $22 million.5 Meanwhile, Australia, China, and many other countries also enforce their respective regulations, and aggressively pursue noncompliant organiza- tions. A recent report by Ovum, an independent an- alyst and consultancy firm in London, has observed that while the cost of regulatory compliance might be substantial, noncompliance will likely be even more expensive.6 Currently, global companies have several tech- nology-based options to aid in meeting the letter of jurisdictional laws. For example, a sophisticated rules engine deployed directly into cloud servers can dynamically apply myriad rules to data to de- termine which stakeholders in specific jurisdictions are allowed access to what data. Or companies can segregate data into logical cloud instances by legal jurisdiction and limit cloud access to those data stores to users in each locale. Finally, as any good CDO understands, draconi- an regulation of a particular jurisdiction may freeze datawith any luck, only temporarily. However, in- sights gleaned from those data assets are not subject to jurisdictional regulations and can be transferred freely throughout global organizations. With this in mind, shifting the focus from data to insights can help global organizations capitalize on data while remaining in compliance with local law. 45 Skeptics corner As a discipline, data management is not newnor are half-baked claims to have reinvented it. Because we understand that some may greet news of an emerging data trend with a degree of hard- earned skepticism, we will try in the following paragraphs to address concerns, correct common misunderstandings, and set the record straight on enterprise data sovereignty and its possibilities. Misconception: Weve already tried using master data solutions to turn lead into gold. What you are describing sounds like another fools errand. Reality: Its different this time . . . seriously. Heres why: Many of the master data solutions available during the last 20 years were federated systems with a master data set and separate working sets for storing various data typesfor example, customer, product, or financial data. The process of reconciling the master and working sets was manual and never-ending. Moreover, all data management rules had to be written prior to deployment, which had the net effect of straitjacketing the entire system from day one. The enterprise data sovereignty trend offers something different. Federated models and manual processes give way to automation and an advanced data management toolkit that includes natural language processing and dynamic data discovery and ontologies, plus advanced machine learning and cognitive capabilities. The system requires less up-front rule-making and can teach itself to manage complexity and maintain regulatory compliance consistently across internal and external ecosystems. Misconception: Even with automation, you still have frontline people inputting dirty data. Reality: True, workers inputting and manipulating system data have historically introduced more complexity (and dirty data) than the systems ever did. Moreover, rewarding and penalizing these workers did little to address the issue. In an advanced management system, automation, machine learning, and relational capabilities can help improve data quality by organizing data uniformly and consistently, providing a context for it, and making specific data sets accessible broadlybut only to those who need it. Moreover, when designing their data architectures, companies should consider moving data quality, metadata management, and lineage capabilities away from system centers and relocate them to the edges, where they can correct a human error before it enters enterprise data flows. Misconception: Freeing data will only lead to problems. Reality: Suggesting that data should be freely accessible does not mean all data should be accessible to everyone across the enterprise at all times. Doing so would overwhelm most people. Perhaps worse, sharing R&D or other sensitive data broadly could tempt some to engage in nefarious acts. But by using metadata, dynamic ontologies and taxonomies, and other relational capabilities, the system can have sufficient context to map data content to enterprise functions and processes. Using this map, the systemnot usersdetermines who gets access to which data sets, and why. Tech Trends 2018: The symphonic enterprise 46 LESSO N S FRO M TH E FRO N T LIN ES LESSO N S FRO M TH E FRO N T LIN ES LESSO N S FRO M TH E FRO N T LIN ES Data drives competitiveness in Asian markets In response to increased competition across the Asian market, in 2012 one global manufacturer be- gan looking for ways to amplify its business model and operations. How could it grow the top line, re- duce costs, and develop entirely new ways to drive revenue? Leaders found an answer in ever-growing volumes of data and the valuable customer, strate- gic, and operational insights contained therein. By developing new approaches for managing and lever- aging data, the company would be able to develop the insights it needed to achieve its strategic and operational goals. Step one involved building a new digital foun- dation that, once complete, would drive repeatable, reliable data collection and usage, while remaining compliant with data regulations across borders. The project also involved integrating new data sources, constructing a more robust customer mas- ter data system with a single view of the customer, and enhancing the protection of data both in stor- age and in transit across Europe and Asia. In addi- tion to its far-reaching technical components, the project plan called for transforming the companys my data culture into one that encourages data sharing across the organization. Since its completion, the digital foundation has enabled greater visibility into trends across func- tions and geographies, which has subsequently made it easier to identify improvement areas both internally and externally. For example, in 2016 the company launched a series of pilots to increase effi- ciencies and improve customer service. The first fo- cused on aggregating data from a variety of internal operations and transactions across geographies such as call centers, customer service departments, and dealer visitsand identifying early-warning in- dicators of potential quality issues. Shortly thereafter, the company launched a sec- ond pilot in which it placed hundreds of sensors in the field to obtain real-time performance data. It has used these insights to optimize operations, alert customers proactively of potential quality issues, empower customer-facing employees with more in- depth product knowledge, and identify inefficien- cies in the supply chain. Though leaders intend to continue exploring new data management approaches and applying new tactics, their ultimate goal remains consistent: harness data to become more competitive not only within the existing landscape but against newcom- ers as well. Enterprise data sovereignty 47 LE SS O N S FR O M T H E FR O N T LI N ES Making dollars and sense of data Data is rapidly becoming the hard currency of the digital economy. To manage this currency more efficientlyand to mine it more extensively for valuable insightsleading financial services orga- nizations are modernizing their approaches to data architecture and governance. Today, many financial services firms have large stores of potentially valuable historical data resid- ing in disparate legacy systems. Much of this data is organized in siloes for use by specific groups. For example, sales might own customer data while fi- nance would own transactional data. In an effort to make more data accessible to everyone across the enterprise, companies are breaking down tradition- al information silos. One payment services provider established a big data platform with cognitive and machine learning to improve its data discovery and real-time research capabilities. Likewise, a global insurance firm created a 360-degree view of the customer by connecting customer data across busi- ness units and then deploying predictive models to help drive process improvements. This approach also supported the creation of new capabilities in marketing, sales, risk management, fraud detection, underwriting, claims, and other lines of business. Meanwhile, a financial services firm implemented a metadata management repository, critical data lineage capabilities, and an enterprise data identi- fication and tracking system that, together, make it possible to identify and track data across the global enterprise using cognitive capabilities versus tradi- tional methods. As data moves from one system to another, accountability for that data shifts to whom- ever will be using it, automatically reorienting ac- countability to the data itself. Some firms are also working to advance their data governance strategies. Increasingly strict regu- latory oversight has made data quality management a priority at the executive and board levels. More than ever, financial services firms require complete, timely, accurate, and granular data to support regu- latory reporting disclosures. To this end, they are exploring ways to automate traditionally manual governance, oversight, and accountability tasks. For example, one investment management company es- tablished a governance system in which responsibil- ities for the global enterprise are held by a commu- nity of data stewards who operate within a defined set of policies and procedures. These stewards han- dle day-to-day data management and governance issues. In parallel, the company implemented an enterprise data identification and tracking system that extends governance workflow across all sys- tems, which helps the data stewards maintain com- pliance with jurisdictional data privacy and security regulations. Tech Trends 2018: The symphonic enterprise 48 Enterprise data sovereignty Bill Ruh, chief digital officer of GE and CEO of GE Digital GENERAL ELECTRIC Data was the impetus for GEs digital journey. Were more than just the equipment we sellwe also help our customers run and operate their businesses more efficiently. Almost a decade ago, we started adding more sensors to our machines to better understand their performance, then realized our customers were analyzing that same data in new and different ways. We know the machines inside and out, and we are in the best position to help our customers get every bit of value out of that data and, ultimately, our machines. We knew we needed to do things differentlyto evolve our business. So we launched GE Digital, with the goal of mapping the new digital industrial world by integrating our machinery, software, IT, security, fulfillment, and product management capabilities. We viewed this move through a business lens rather than a technology one, focusing on how to help our customers improve productivity, achieve better outcomes, even create new revenue opportunities. There was no roadmap to follow, but as we started, we quickly realized it would require deep domain knowledge of our equipment to understand both the physics and the analytics of the mined data. It also meant acquiring new capabilitiessuch as cloud, mobile, and data scienceto put in place an infrastructure and to scale it. Many big companies lack speed but do have scale, so moving into new areas requires leveraging existing assets and then building speed. Big companies tend to operate well in the vertical, with each business unit able to operate semi-independently. But the value of digital is in the horizontal, in the ability to integrate and leverage data across the enterprise: Being digital is the only way to move forward, and that has to be driven from the top of the organization. At the same time, you want toand need toenable those verticals to move fast. In the beginning, we didnt pretend that we knew what belonged in the vertical and what belonged in the horizontal; instead, we recognized the inherent conflict while committing to iterate and evolve our thinking. But we did get comfortable with the idea of reusing, interchanging, and reinforcing a culture of collaboration in order to optimize our existing assets. We focused first on bringing new capabilities to GEs services business, which allowed us to collect data, expand our knowledge, and determine what talent and skillsets we needed. We started in 2011 and focused internally the first two years, so we could develop a speed muscle. In 2013, we pivoted to adapt the offerings for our customers. Packaging together the data, analytics, and domain knowledge has immense value, not only in the ability to pull out cost but in the customers realization of the benefit to their operations. For example, GEs IT group built FieldVision on the Predix platform. Initially aimed at our Power services group, FieldVision became a blueprint for an automation layer for any services team. Now we provide the service to power plants to automate controlled outages, which saved one customer $200 million in one year. Most organizations utilize spreadsheet- or paper-based operations, so FieldVision is truly an outcome-focused solution for data. It allows organizations to put data in the hands of the operator to yield greater efficiencies. Theres no inherent value in the data itself. The value is in the belief system of what the data represents, and the potential impact if it can be unlocked. Everyone has been talking about the importance of data for decades, but the complexity and cost around ERP has created a skepticism around it. Companies dont want to get three years into their data sovereignty journey and realize the business isnt seeing any value from it. You need to think about the transformation you will make, the outcome you will deliver, and the change you will bring. The value of data is sitting out there for everybody to take, but to optimize it, organizations need to be willing to change their operating procedures, and their people need to be willing to change how they work. My take 49 As the enterprises most valuable asset, data is increasingly at risk for misuse, misplacement, and mishandling. This is due in part to increased band- width and computing power, as well as the sheer volume of data available, growing rapidly due to advanced mining capabilities, increased storage, cloud computing, the Internet of Things, and cogni- tive tools. Additionally, these technologies have ex- tended datas reach beyond the enterprise to third parties whose practices and protocols are beyond its direct control. These circumstances call for a new approach to data security and governance. Data governancethe process of ensuring the quality of data throughout its life cycleisnt in- tended to lock away information. In fact, data can play a key role in developing a more robust risk strategy. For example, applying analytics to nontra- ditional data sources can help build predictive risk models to better target potential threats (by loca- tion, population, period of time, and other factors). Similar data could assist in assessing the security protocols of new vendors and partners with whom you share a network. With such deep data troves, an organization can lose track of its data life cycle. The value of business intelligence has led to a school of thought that if some data is good, more is better, and all the data is best. Accessible, fast-growing data stores can in- troduce a litany of cyber risk scenarios if the enter- prise fails to adopt and adhere to leading practices around its creation/collection, storage, use, shar- ing, and disposal. Such scenarios have given rise to consumer-centric regulations such as the European General Data Protection Regulation (GDPR) and Chinas Cybersecurity Law, both of which are caus- ing some global enterprises to rethink their data management strategies. After years of collecting as much data as possible, organizations are beginning to realize that in some instances data may be more of a liability than an asset. For decades, many organizations spent their time, money, and resources on defensessuch as network, application, and infrastructure securi- tydesigned to keep cyber adversaries out of their networks. But because no organization can be im- mune to a breach, a more effective approach may be focusing on the data itself. While organizations should continue to implement and maintain tradi- tional security measures, which act as a deterrent to cyber threats, they should also consider the fol- lowing steps: Inventory, classify, and maintain sensi- tive data assets. The first step to protecting data is knowing what you have and where it is. Maintaining a current inventory of data can enable an organiza- tion to proceed with data protection in a methodical manner. Additionally, when you identify your most valuable assetsthe data with the highest threat vectorsyou can shore up your defenses around them. Finally, an accurate inventory facilitates com- pliance with regulatory requirements such as the GDPRs provisions for data portability and an indi- viduals right to be forgotten; once data has prolif- erated throughout an organization, locating all of it quickly for transfer or deletion could be a daunting task without an inventory. To expedite such tasks, organizations should develop and enforce rigorous governance processes that include oversight for data exchanged with third parties. Implement data-layer preventative and detective capabilities. It is important to imple- ment capabilities such as data classification, data loss prevention, rights management, encryption, tokenization, database activity monitoring, and data access governance. These types of capabilities enable preventative and detective capabilities at the last line of defense: the data layer itself. Reduce the value of sensitive data. One way to reduce the value of sensitive data is to encrypt, to- kenize, or obfuscate the data to render it difficult to use when compromised. A second way is to destroy it when it is no longer necessary. Decades-old data rarely generates revenue, but it can be costly to a companys reputation when compromised. Focusing risk strategy on the data layer itself may be one of the most effective ways to secure growing data troves and protect its value to your organization. RI SK IM PL IC AT IO N S Tech Trends 2018: The symphonic enterprise 50 Enterprise data sovereignty G LO BAL IM PACT The diverse, nascent-stage, and dynamic na- ture of global data privacy, residency, and usage regulations are a major driver of the enterprise data sovereignty trend. Across regions, there is ac- knowledgment of its profound impact, even while investments tend to focus on tactical responses to existing or looming government policies. From the 2018 deadlines for the European Unions GDPR to recent Australian privacy laws, some believe that these country-specific responses are necessary to navigate the void created by industry regulations that often lag behind technology advances. In light of these complex laws, however, many organiza- tions are realizing they dont knowmuch less have control overwhat data exists within the enterprise, where it sits, and how it is being used across busi- ness units and geographies, or by third parties. The range of adoption timelines may reflect the global lack of technical skills and reference use cases within specific country and industry intersections. Region- and country-specific challenges play a role in these varying timelines. In Northern Europe, for example, historical context related to civil liberties, privacy, and nation-state data collection may make the topic of data sovereignty particularly sensitive and highly politicized. Across the Americas, Eu- rope, and Asia Pacific, active discussions are under way between the government and private sectors to shape regulation. In all corners of the worldin- cluding South Africa, Italy, Brazil, and Chinapub- lic providers are racing to build national clouds in advance of evolving privacy laws. Region-specific timeframes and barriers reflect these consider- ations, indicating either the expected window for investments and policies to mature or a cautious buffer due to the complexities involved. Deloitte Insights | Deloitte.com/insights Figure 2. Global impact Relevance Significant High Medium Low None Timeliness Now 1 year 12 years 25 years 5+ years Readiness Significant High Medium Low None N. America N. Europe C. Europe Israel Asia S. America S. Europe S. Africa Middle East Australasia Global impact measures Source: Deloitte analysis. 51 Where do you start? For companies looking to boost data manage- ment capabilities, the holy grail is creating the ar- chitecture and processes required to handle growing volumes of data in an agile, efficient fashion. Yet for many organizations, the distance between current capabilities and that goal may seem daunting. The following steps can help you lay the groundwork for the journey ahead:  Pay data debt. CIOs think a lot about technical debtthe quick fixes, workarounds, and delayed upgrades that bedevil legacy systems and un- dermine efficiency. Many companies face com- parable challenges with data debt. Consider the amount of money you are spending on one-off data repositoriesor the cost, in terms of both time and efficiency, of creating reports manually. A first step in transforming your data manage- ment systems is assessing (broadly) just how much data sprawl you have. How many interfac- es and feeds connect disparate repositories and systems? With an inventory of systems and data, you can try to quantify how much manual effort is expended daily/monthly/yearly to keep the sprawl intact and functioning. This information will help you better understand your current data capacity, efficiency (or lack thereof), and costs, and provide a baseline for further analysis.  Start upstream. Data scientists use technolo- gies such as text and predictive analytics and machine learning to analyze largely unstruc- tured data. This process typically begins at the end of the information supply chainthe point at which users tap into data that has been ag- gregated. By deploying these and other tech- nologies at the beginning of the information supply chainwhere an organization initially ingests raw datacompanies can start the pro- cess of linking, merging and routing data, and cleansing bad data before data scientists and us- ers begin working with it. This approach helps impose some structure by creating linkages within raw data early on, laying the groundwork for greater storage and management efficiencies. Also, when you can improve data quality at the point of entry by correlating it and performing relationship analysis to provide more context, data scientists will likely end up spending less time organizing data and more time performing advanced analysis.  Use metadata, and lots of it. Adding metada- ta to raw data at the point of ingestion can help enhance data context, particularly in unstruc- tured data such as random documents, news- feeds, and social media. Greater context, in turn, can help organizations group and process the- matically similar information more efficiently, as well as enable increased process automation.  Create a cognitive data steward. Raw data is anything but uniform. Any raw data set is like- ly rife with misspellings, duplicate records, and inaccuracies. Typically, data stewards manually examine problematic data to resolve issues and answer questions that may arise during analysis. Increasingly, we see data stewards use advanced cognitive computing technologies to assist in this kind of reviewtheres only so much a hu- man can do to resolve these issues. The ability to automate this process can free up data stewards to focus on more valuable tasks.  Help users explore data more effectively. Navigating and exploring data can be challeng- ing, even for experienced users. Providing a natural language interface and cognitive com- puting tools to help guide users as they under- take predictive modeling and advanced searches can turn laymen into data scientistsand help companies extract more value from their data management investments. Tech Trends 2018: The symphonic enterprise 52 Enterprise data sovereignty Bottom line As data grows exponentially in both volume and strategic importance, enterprise data sovereignty offers companies a blueprint for transforming themselves into data-driven organizations. Achieving this goal may require long-term investments in data integration, cataloging, security, lineage, and other areas. But with focus and careful planning, such investments can generate ongoing ROI in the form of a dynamic data management construct that is constantly evolving, learning, and growing. 53 NITIN MITTAL Nitin Mittal is a principal with Deloitte Consulting LLP and serves as the US Analytics and Information Management practice leader. He specializes in advising clients on how to best navigate their analytics journey as well as how they can become insight-driven organizations. SANDEEP KUMAR SHARMA, PH.D. Sandeep Sharma is the deputy chief technology officer and a managing director in Deloitte Consulting LLPs Analytics and Information Management practice. He has more than 18 years of global experience delivering complex business intelligence, analytics, and data science programs for clients. Sharma works in a variety of industries, including financial services, health care, consumer products, telecommunications, energy, and the public sector. ASHISH VERMA Ashish Verma is a managing director with Deloitte Consulting LLP and leads the big data and Internet of Things analytics services. He has more than 18 years of management consulting experience with multiple Fortune 100 clients and specializes in solving complex business problems related to realizing the value of information assets within an enterprise. Risk implications DAN FRANK Dan Frank is a principal with Deloitte and Touche LLP and leads the US privacy and data protection service offering. He has more than 20 years of experience in cybersecurity and excels at privacy and data protection program development and remediation as well as rapidly responding to regulatory enforcement actions both in the United States and internationally. AUTHORS Tech Trends 2018: The symphonic enterprise 54 Enterprise data sovereignty 1. Tracie Kambies, Paul Roma, Nitin Mittal, and Sandeep Kumar Sharma, Dark analytics: Illuminating opportunities hidden within unstructured data, Deloitte University Press, February 7, 2017. 2. Toyota Global Newsroom, Industry leaders to form consortium for network and computing infrastructure of automotive big data, August 10, 2017. 3. David Reinsel, John Gantz, and John Rydning, Data age 2025: The evolution of data to life-critical, IDC White Paper, April 2017. 4. European Union, GDPR portal, accessed October 13, 2017. 5. Jessica Davies, Common GDPR myths, debunked, Digiday, September 7, 2017. 6. Alan Rodger, Data privacy laws: Cutting the red tape, Ovum, 2016. ENDNOTES 55 The new core Unleashing the digital potential in heart of the business operations FOR many in the business and tech worlds, the word digital conjures up thoughts of market-ing, e-commerce, and omnichannel experi- ences that increasingly capture business mindshare (and investment). This is hardly surprising given that improving digital engagement with customers, patients, citizens, and business partners is now a defining mandate across industries and sectors. Though savvy organizations are approaching the digital mandate from a number of angles, one issue remains consistently important: the interconnect- edness of front- and back-office systems. CIOs rec- ognize that any effort to transform the front office wont get far unless new digital systems have deep hooks into the core. These critical hooks make pric- ing, product availability, logistics, quality, financials, and other heart of the business information resid- ing in the core available to sales and customer ser- vice operations. Creating connective tissue between enterprise functions and the core represents progress, but in terms of opportunity, it only scratches the surface. Much of the attention paid to cloud, cognitive, and other digital disruptors today centers on the way they manifest in the marketplace: Individually and collectively, these technologies support new customer experiences, product innovation, and rewired industry ecosystems. Often overlooked, however, is their disruptive potential in core back- and mid-office systems and in opera- tions, where digital technologies are poised to fundamentally change the way work gets done. This transformation is beginning with finance and supply chain, two corporate and agency pillars ready to embrace all things digital. From there, next-generation transaction and financial systems, blockchain, machine intelligence, automation, and the Internet of Things (IoT) are redefin- ing what is possible in these mission-critical functions. The new core 57 Here in the midst of the digital revolution, the cores full potential remains largely untapped. Why? Be- cause thus far, few organizations have extended the digital mandate beyond customer-facing functions to the middle and back offices. Expect this to change over the course of the next 18 to 24 months as CIOs, CFOs, and supply chain leaders begin developing new digital capabilities in their core systems. Were not talking about deploy- ing point solutions or shiny digital add-ons. Rather, Deloitte Insights | Deloitte.com/insightsSource: Deloitte analysis. Figure 1. The new digital core: Finance and supply chain in action Make-to-use repair and enhancement parts DIGITAL CORE On-site part replacement to reduce downtime Monitoring of equipment, labor, and off-site facilities using sensors and drones AR-enhanced production and remote maintenance Enhanced live customer support and predictive aftermarket maintenance Blockchain-based transactions to improve security and accuracy Automatic replenishment driven by POS and sensors Predictive routing and driverless vehicles for delivery Digital-enabled collaboration, simulation, and rapid prototyping Data-driven design, enabling ultra-delayed differentiation Cognitive system to detect anomalies in transaction data and mitigate issues RPA-powered procure-to-pay and order-to-cash Scenario analysis powered by predictive analytics, machine learning, and sensors to forecast demand and optimize pricing Tech Trends 2018: The symphonic enterprise 58 this is about constructing a new core in which auto- mation, analytics, real-time analysis and reporting, and interconnections are baked into systems and processes, fundamentally changing how work gets done. In many ways, the new core trend mirrors digitization efforts already under way in other en- terprise functions, such as HR, sales, and marketing. Though their tactics and milestones certainly differ, all of these groups share a vision of enterprise func- tions as symbiotic building blocks in a larger ecosys- tem, working in concert to reshape business. Digital dj vu Efforts to digitize core business processes are hardly new. Over the last two decades, companies have invested in ERP implementations, large-scale custom systems, business process outsourcing, and other ghosts of innovations past. Some of these in- vestments delivered tangible benefitsfor example, standardized workflows and automated tasks. How- ever, others created unintended side effects: unin- tuitive employee user experiences, rigid and overly prescriptive operating procedures, limited data visi- bility, and in some cases, stagnation because needed changes were too costly or difficult to implement.1 After completing a few of these initiatives and the occasional one-off deployment of the latest digi- tal tool, some companies began to feel core system fatigue, a situation exacerbated by the compound- ing complexity that eventually appears in aging mis- sion-critical solutions. Meanwhile, CXOs and line-of-business leaders struggled to reconcile two seemingly contradictory realities: They recognized the shadow that tech- nologys rapid advancement was casting over their operations. At the same time, they were becoming ever more skeptical about one-off technology de- ployments. The new core flips these dimensions on their heads. As this trend gains momentum in the com- ing months, expect to see CXOs target core busi- ness areas such as finance and supply networks for meaningful change. Rather than focusing on dis- crete tasks or individual tools, they will be broadly exploring how digital technologies can support global ecosystems, platform economies, complex operational networks, and new ways of working in the future. Thats not to say the individual technologies are unimportant. They can be essential enablers for achieving an end vision. For example, blockchains distributed ledger offers a means for exchanging as- sets in an open, secure protocol, which has interest- ing implications for trade finance, supply chain vali- dation processes, and other areas. Yet blockchain alone is only one component in a dynamic, inter- connected new core stack. As companies begin their new core journeys, it will be critical to understand how digital innovations can work in concert with existing capabilities to drive business value. Making it real New core principles can be applied to all heart- of-the-business functions and processes. But to make the trend real, we are focusing on two areas with long histories of technology-enabled transfor- mation: finance and supply chain. The new core 59 The heart of the business meets the future For finance organizations, the digital revolution presents both significant opportunities and nag- ging challenges. For example, exploding volumes of structured and unstructured data contain insights that could potentially transform business and op- erating models. By harnessing digital technolo- gies and enhancing existing analytics capabilities, financea traditional purveyor of analysiscould become the go-to source across the enterprise for strategic advice. This opportunity becomes even more promising as boundaries between enterprise domains disappear, function-specific data sets con- solidate, and individual systems give way to unified digital networks. At present, however, many finance organizations struggle with data and have neither the technologies nor skillsets needed to turn this opportunity into reality.2 Or consider smart technologiesa collection of cognitive tools that could drive greater efficiencies throughout the finance organization by automating an array of manual tasks. In a recent Deloitte survey of CFOs, only 42 percent of respondents indicated that they and their teams were aware of such tech- nologies.3 Recently, this logjam of opportunities and chal- lenges has shown signs of breaking up. Increasingly, forward-thinking CFOs and CIOs are charting fi- nances course toward a digital future built around interconnected and automated systems, unified data sets, and real-time analysis and reporting. Though new core finance organizations differ by company and industry, many will likely share the following characteristics that together can help finance work more efficiently and better serve the business:4  Agile and efficient. In the digital finance mod- el, new product integrations and upgrades can be fast and effective. Public, private, or hybrid clouds offer a full stack of flexible, scalable as- a-service functionality without the large startup costs or technical debt associated with IT archi- tecture and code maintenance.  Faster, cheaper, better. Automation offers finance organizations opportunities to increase efficiencies and lower overall operating costs. Robotic process automation (RPA), for example, uses software programs to perform repetitive tasks and automate processes, such as procure- to-pay and order-to-cash. These processes often involve numerous manual activities, including data entry and reports.  Information accessibility. Planners and analysts can see developing trends and cir- cumstances that directly impact decision-mak- ing. Predictive algorithms feeding visualization technologies translate the kinds of information and insights that have traditionally been the do- main of data scientists into understandable vi- sual metrics that workers across the enterprise can leverage. Over time, CFO and COO data and insights may converge, enabling more seamless oversight, planning, and decision-making.  Automated insights in real time. The term cognitive computing describes an array of tech- nologies including machine learning, natural language processing, speech recognition, com- puter vision, and artificial intelligence. Taken together, these tools simulate human cognitive skills, grinding through mountains of data to au- tomate insights and reporting in real time.  Detailed insights and forecasts. Analytics has long been part of the finance arsenal, but new techniques are helping businesspeople tackle the crunchy questions with more insight- ful answers. It can also help them illuminate connections and trends buried within data findings that can make forecasting more de- tailed, more accurate, and more efficient as well. Such opportunities are fueling ongoing invest- ments in analytics tools. In a recent Deloitte sur- vey of CFOs, roughly 45 percent of respondents said they had invested in finance and accounting analytics, with 52 percent indicating they plan to invest more in the future.5  Super-sized data management capacity. To manage digital information effectively, fi- D IG IT AL F IN AN CE Tech Trends 2018: The symphonic enterprise 60 The new core nance organizations will likely need a techni- cal architecture that can handle massive data sets, without sacrificing availability, timeli- ness, or the quality of books and records. This is what in-memory technology provides. Its key applications include transaction process- ing, event processing, distributed caching, and scenario modeling.  Digital trust. As discussed in previous editions of Tech Trends,6 in the digital economy, finan- cial and legal transactions that involve third- party intermediaries such as a bank or credit agency may be replaced by person-to-person transactions that do not require traditional trust mechanisms. Instead, parties to a transac- tion will create digital identities that verify their trustworthiness and store these identities in a blockchain where others can access but not alter them. Similarly, digital identities will be essen- tial trust elements in blockchain-based digital contracts. Though currently not binding in a le- gal sense, smart contracts represent a next step in the progression of blockchain from a financial transaction protocol to an all-purpose utility. Even with digital technologies maturing and use cases emerging in other enterprise domains, new core digital finance initiatives are still relatively rare. Data discipline remains a challenge in many com- panies. Likewise, historically, decision-makers have not viewed finance organizations as particularly rich targets for achievable savings. Yet there are a few pioneering companies that are developing digi- tal finance capabilities in a concerted way. Others are experimenting with specific tools, such as RPA. Though these experiments may take place within the context of a larger roadmap, they may not rep- resent a holistic embrace of the new core trend. But in the end, these early efforts can give pioneers a competitive advantage as the trend picks up steam. D IG ITAL FIN AN CE 61 The new core At Pfizer, a healthy dose of digital helps finance stay ahead Pfizer Inc. is one of the largest global pharma organizations in the world, with operations in more than 180 countries. With an operation of that size and scale, the finance function is not a back-office consideration but, rather, a vital part of the overall operation. Given its importance, Pfizers finance organization has always sought to be at the forefront of embracing technology as an enabler to help drive the business. The journey began several years ago, when the overall enterprise began migrating to a centralized ERP platform. The move to a common global ERP helped to standardize processes and enabled a significant move to global shared services and centers of excellence; it also allowed finance business partners to focus on driving analytics and business insights with the broader enterprise. Now that 95 percent of Pfizers revenue is running on its ERP platform, taking advantage of emerging digital technologies was the natural next step in its journey. We dont view digital in and of itself as unique or different for us, says Paul DeBartolo, Pfizers VP of finance portfolio management and optimization. We have always been mindful of maintaining our finance expense-to-revenue ratio, while at the same time evolving our compliance posture and improving service levels. Centralization, standardization, and optimization of the function play a central role in achieving that. Now, were harnessing the next generation of digital technologies and tools to continue down that path.7 While the view of digital was not different, the approach for evaluating and deploying it was. According to DeBartolo, it was important for Pfizers finance leadership to understand which digital technologies were ready now and which tools were still emerging and might have an impact in the future. As a result, finance leaders decided to take a rapid rolling model, which allowed the function to quickly pilot digital tools and understand their functionality and relevance before rolling them out. In this model, the companys combined finance and business technology team began exploring and implementing tools differently and more rapidly than ever before. The team started with pilots in several of the more mature solutions, RPA, predictive analytics and data visualization. They piloted the technology in four processes that could quickly demonstrate measurable ROIwholesaler chargebacks (order-to-cash), accounts payable, management reporting, and intercompany reconciliationsand could help leadership understand the value of the tools and how best to deploy them. In certain pilots, the RPA automated between 30 and 80 percent of the in-scope tasks, including running reports, populating spreadsheets, uploading data to the server, and sending emails. As a result of the pilots, leaders have signed on, putting active programs in place to significantly deploy RPA and predictive analytics more broadly, with an attractive, accelerated payback. Moreover, some of the savings generated by the RPA pilot will be used to fund future digital finance pilots. Taking this rapid rolling approach was important for us. The key to moving fast was to initially look at automating existing processes rather than redesigning and automating them concurrently, DeBartolo says. We operate in a heavily regulated industry, so we were very deliberate about maintaining compliance as we made changes and added capabilities. Feedback from the early pilots and implementations will help us to streamline and simplify processes over time in light of the new technology landscape. From the lessons learned in the first two pilot areas, Pfizer has created a roadmap to pilot other tools, including blockchain, natural language generation, and cognitive computing. Collectively, the capabilities represent the opportunity to further improve how finance supports the business. For example, by Digital finance in action 62 developing predictive models for commercial forecasting, finance can provide additional insights on revenue, patient populations, and proactive risk detection, rather than focusing on manual efforts to calculate and assemble the information for assessment. Finance leaders do recognize that the move to digital solutions will necessitate a shift in colleagues mind- set, since new efficiencies could change how Pfizer executes finance processes. In certain areas, we are looking to move to as touchless a process as we can, but just because theres more digital automation involved in a process doesnt mean we dont need a culture of accountability, DeBartolo says. The shift to digital is as much about our people as it is about the technology. We want our people to own it, understand it, manage it, embrace it, and think about whats possible. Finally, DeBartolo is optimistic about the future because of how leaders and colleagues at all levels continue to embrace change. Our digital initiative was embraced at the most senior level in our organization, he says. Our business leadership understands the potential of this, and the finance and business technology leaders are willing to own it and sponsor it. Thats been the key differentiator. Given the speed of advancement, we may have to change ourselves again. Having leadership who are willing to take that journey makes all the difference to our organization. 63 Moving from linear to dynamic The digital revolution is driving profound change in every core function, but perhaps none more so than in the supply chain. Traditionally, organizations have structured their supply chains to support a linear progression of planning, sourcing, manufacturing, and deliver- ing goods. For each of these functions and their de- pendencies, supply chains enabled large numbers of transactions involving the exchange of time, money, data, or physical materials for some other unit of value. With the rapid digitization of the enterprise, this time-honored model is now giving way to an interconnected, open system of supply operations in which data flows through and around the nodes of the supply chain, dynamically and in real time. This interconnectedness is transforming staid, se- quential supply chains into efficient and predictive digital supply networks (DSNs) with the following characteristics:8  Always-on agility and transparency. Se- curely and in real time, DSNs integrate tra- ditional datasets with data from sensors and location technologies. This provides visibility into all aspects of the supply network, making it possible to dynamically track material flows, synchronize schedules, balance supply with demand, and drive efficiencies. It also enables rapid, no-latency responses to changing network conditions and unforeseen disruptions.  Connected community. DSNs allow multiple stakeholderssuppliers, partners, customers, products, and assets, among othersto com- municate and share data and information di- rectly, rather than through a gatekeeper. Being connected in this way allows for greater data synchronicity, ensuring that stakeholders are all working with the same data when making deci- sions. It also makes it possible for machines to make some operating decisions.  Intelligent optimization. By connecting humans, machines, and analytics (both data- driven and predictive), DSNs create a closed loop of learning, which supports on-the-spot human-machine decision-making. Whats more, through analytics, DSNs put data to work solv- ing challenges in targeted areas such as com- modity volatility, demand forecasting, and sup- plier-specific issues.  Holistic decision-making. When all supply chain processes become more transparent, the net result can be greater visibility, performance optimization, goal setting, and fact-based deci- sion-making. This enables complex decisions to be made more quickly and with an understand- ing of the trade-offs involved, thus avoiding sub- optimization. A centralized data hub operating within the DSN stack makes big-picture transparency possible. In traditional, linear supply chains, datasets are often siloed by function: customer engagement, sales and service customer operations, core operations and manufacturing, and supply chain and partnership. In this model, each dataset remains separate from the others, which can lead to missed opportuni- ties, as organizations cannot see where these func- tional areas intersect or align. An integrated DSN hub serves as a digital foundation that enables the free flow of information across information clusters. This hub, or digital stack, provides a single location to access near-real-time DSN data from multiple sourcesproducts, customers, suppliers, and af- termarket supportthereby encapsulating multiple perspectives. It also includes multiple layers that synchronize and integrate the data.9 DSNs emergence is part of the broader digital revolution advancing across industries and markets. Increasingly, digital technologies are blurring the line between the physical and digital worlds. Com- panies can now gather vast datasets from physical assets and facilities in real time, perform advanced analytics on them to generate new insights, and use those insights to make better decisions, develop strategies, and create efficiencies.10 64 D IG IT AL S U PP LY N ET W O RK S Tech Trends 2018: The symphonic enterprise 64 D IG ITAL SU PPLY N ETW O RKS Likewise, companies are already using these insights to reimagine the way they design, manu- facture, and deliver products to customers, with tremendous implications for the supply chain. In retail, for example, omnichannel customer experi- ences rely first and foremost on inventory visibility. When purchasing an item online, a customer wants to know if the item is available and, if not, when it will be. For some retailers, answering this question quickly and accurately is not always easy. In tradi- tional supply chains, information travels linearly, with each function dependent on the one before it. Inefficiencies in one step can result in a cascade of similar inefficiencies in subsequent stages. In some companies, supply chain stakeholders have little if any visibility into other processes, which limits their ability to react or adjust their activities. With the DSN model, all steps are interconnected, creat- ing a unified digital network that gives supply chain managers a real-time view of all process steps, from design to manufacture to delivery. The new core 65 Skeptics corner Back-office and operational functions are no strangers to the digital revolution. In fact, countless finance and supply organizations deploy some digital tools and are likely exploring other digital opportunities. But because the new core trend involves transformation on a much larger and fundamental scale, it might be useful to correct a few misconceptions that digital dabblers may have about the journey ahead. Misconception: Im better off waiting for my ERP vendor to offer cognitive tools specifically designed for the finance and supply chain modules Im running. Reality: The cognitive market is already showing signs of consolidating. Big enterprise software and cloud vendors are selecting cognitive tools and incorporating them into their products. In the future, small companies currently driving much of the innovation in the cognitive space likely will either be swallowed up or find a niche trajectory to follow independently. You cant afford to wait for the market to sort itself out. Your competition is already kicking the tires on existing products and laying the groundwork for a digital future. Misconception: I have a robust finance system that allows me to see all numbers and processes in gory detail. Whats more, theres very little latency. Why would I want to automate? Reality: We would venture a guess that many of the dedicated finance team members who think they are performing analysis are, in reality, trying to protect the predictability of earnings forecasts. CFOs can unburden these underused workers by using machine learning tools to automate the planning and forecasting processes. This can free finance talent to focus on generating real business insights. There is a bigger automation picture to consider. Chances are other enterprise groups are already exploring automation opportunities. Though domain-specific automation initiatives can drive discrete efficiencies, in the near future, companies may be able to maximize automations impact by applying it consistently across HR, supply chain, finance, and other enterprise domains. Automationwith RPA, cognitive, and other dedicated toolsrepresents the future. Misconception: Staff members in my finance organization are top-notch. They should have no problem with new digital systems and processes. Reality: No doubt your workers are top-notch. But remember: The skills needed to operate finance and supply chains in a digital world are very different from traditional accounting and logistics skills. Some staff members will make the transition to more digital roles; others may not. As you think about your talent model, how will you help current employees upskill? Likewise, how will you recruit in-demand digital veterans who can pick and choose from any number of job offers? As you embrace the new core trend, dont underestimate the importance of recruiting the right talentevery hire you make is an opportunity to prepare for a digital future. Tech Trends 2018: The symphonic enterprise 66 The new core RISK IM PLICATIO N S As we automate, digitize, and integrate functions in areas such as supply chain and finance, attack surfaces expand and new risk considerations arise. However, digitizing the core can enable greater transparency, real-time communication, and faster response times, facilitating increasingly sophisti- cated risk management tactics that can protect an organizations operations and assets. SUPPLY CHAIN RISKS While digitizing legacy supply chains can stream- line processes and improve transparency, it also can create huge data stores with multiple points of vul- nerability.  The risks around data encryption and confiden- tiality are still a concern: It is critical to pro- tect data, both at rest and in transit, as well as in memory.  The use of open APIs can increase your net- works vulnerabilities; management of API- specific identities, access, data encryption, con- fidentiality, and security logging and monitoring controls are essential.  The risks of a traditional supply chaincounter- feiting, malicious modifications, threats to intel- lectual propertystill apply in a digital supply network, while the digital footprint also requires securing the flow of intellectual property. In terms of data stewardship, organizations should thoroughly inventory the data moving through their supply chains. Determine who will monitor and manage data at each point, as well as who owns detection and response if there is a breach. Identify the core privacy and security requirements that need to be fulfilled, and who will own the track- ing and auditing for these at each node. Finally, put in place validation, review, and update mechanisms once the digital supply chain is operational. FINANCE RISKS In recent years, technology advances and en- terprise cost pressures have rapidly incentivized finance functions to streamline and automate with cognitive solutions. However, these opportunities also introduce new dimensions of data risk. Or- ganizations can manage this risk by establishing end-to-end governance, comprehensive review pro- cedures, and ongoing monitoring and surveillance techniques from the very beginning. Some critical steps include the following:  Monitor and surveil bots and cognitive systems. An organization needs to verify a bot is acting as designed and intended. For instance, if a system with only read access were able to gain write ac- cess, it could change data in the general ledger.  Carefully vet third-party capabilities and contin- uously monitor black box solutions. Third-party solutions can impose risksfrom an initial ven- dor proof of concept to adhering to ongoing re- quirements. Further, black box solutions can pose significant infrastructure risk once given access to systems, processes, or data.  Customize approaches to validation and testing. Traditional periodic, point-in-time compliance testing and oversight may no longer be sufficient for cognitive technologies.  Escalate the importance of preventive and au- tomated controls. Before cognitive solutions go live, they should undergo rigorous review boards, pre-authorization clearances, and impact analyses. Business process automation in both the digi- tized supply chain and finance functionsinclud- ing robotics, cognitive engines, natural language processing, and blockchain-related technologies offers opportunities for a more robust risk man- agement strategy. It can reduce the propensity for human error and make tracking, monitoring, de- tecting, and responding faster, more consistent, and smarter. While risks are inherent in the imple- mentation of any new technology, the modern core is helping enable more efficient, thorough, and in- telligent risk strategies to protect two of the most critical areas in any organizationsupply chain and finance. 67 G LO BA L IM PA CT Around the globe, organizations increasingly recognize the value that the new core trend can offer. According to findings from a recent survey of Deloitte leaders across 10 regions, the new core is gaining traction as an effective means for fram- ing broader digital transformation agendas. These agendas often include, among others, core ERP up- grades, and deployments of disruptive technologies, such as cognitive, robotics, and IoT. Survey responses suggest that new core time- lines vary greatly among regions. For example, countries with industries that adopted large-scale ERP or custom system deployments early onthe United Kingdom, the United States, Canada, and Germany, for exampleare becoming the new core pioneers. Countries with industries that embraced large-scale ERP later are at a different stage transi- tioning from acknowledge need to formal efforts to develop actionable plansfor example, financial services in Brazil, Mexico, Asia Pacific, and the Mid- dle East. Other factors also account for regional variations in adoption timelines. In Latin America and South Africa, for example, companies are more likely to focus on customer-facing transformation activities. Survey respondents report that companies in these regions are linking digital capabilities to ERP and other back- and mid-office systems. However, few have launched large-scale transformation projects. Across the globe, there are consistent readiness challenges. Survey respondents report significant concerns over the potential impact that new core ini- tiatives could have on company culture, talent, and organizational structures. The cost and complexity of maintaining existing systems also contribute to lack of readiness. Finally, many technology leaders worldwide struggle to develop an architectural vi- sion to guide various facets of core modernization. Deloitte Insights | Deloitte.com/insights Figure 2. Global impact Relevance Significant High Medium Low None Timeliness Now 1 year 12 years 25 years 5+ years Readiness Significant High Medium Low None N. America N. Europe C. Europe Israel Asia S. America S. Europe S. Africa Middle East Australasia Global impact measures Source: Deloitte analysis. Tech Trends 2018: The symphonic enterprise 68 The new core Where do you start? Just as looking beyond individual domains boundaries unlocks the underlying technologies full potential, the new core gets even more interest- ing when the lines between core functions start to blur. The same digital backbone needed for an auto- mated financial close could allow dynamic sched- uling of outbound delivery to prioritize order flow. IoT-empowered quality control metrics from the supply chain or embedded in products could allow dynamic, real-time visibility into actual selling, gen- eral, and administrative expensesand trigger pric- ing and promotions based on fluctuating product availability or performance issues of a customers previous purchases. Creating a new core is neither a marathon nor a sprintrather, its a series of sprints toward an overall destination. As you begin exploring digital possibilities, the following initial steps can help you get off to a good start.  Learn from others. If you havent already, create a small cross-functional team to help you understand the trends possibilities. Also, chances are, some of your peers in other parts of the company are already leading digital ini- tiatives. Dont reinvent the wheelthere is a lot you can learn from their experiences. Talk to your colleagues. Find out how transformation has reshaped their talent and operating models, and learn from successes theyve hadand from their failures.  Make a plan. Map out a transformation plan for your function, focusing first on applications that have proven to be clear winners in other finance or supply chain organizations. This can serve as a master blueprint, but remember to ex- ecute it one step at a time. Things are changing fast in the digital world. Try to avoid making big bets until you know you are ready and you fully understand the potential risks.  Dont just imagine tomorrowget there from today. Before committing to bold visions of digital grandeur, consider the hardest part of the equation: Where do your people, organiza- tional structure, processes, and technology fit in this brave new world? Many established assets can serve as building blocks for the new core. But make sure any modernization needs are well understood before provisioning budget and locking down milestones. Dont limit the reality check to your legacy, either. For emerging and new technologies, you will likely have to move beyond the rhetoric of whats real today, the path to enterprise scale and controls, and the pace of advancement. Build confidence in the when to invest, not just the where and the what.  Start cleaning up your use case data. Data is the lifeblood of the digital coreand a poten- tial source of trouble in any new core initiative. In many companies, the data needed for use cas- es is siloed and rife with misspellings, duplicate records, and inaccuracies. Consider creating a cognitive data steward to automate the tedious process of examining problematic data and re- solving issues. Also, be more proactive in the way you manage use case data. Adding metadata can enhance data context. Greater context, in turn, can help organizations group and process the- matically similar information more efficiently, as well as enable increased process automation. Bottom line Most boardrooms lack the appetite to fund (or the patience to weather) expansive transformation agendas. This is especially true when the agendas in question focus on back-office institutional processes. Be that as it may, digitals disruptive march across the enterprise continues apace. Fueled by digital innovation, the new core trend presents a host of potentially valuable opportunities to redefine heart-of-the-business work and establish a better foundation for customer-facing innovation and growth initiatives. 69 BILL BRIGGS Bill Briggs is a principal with Deloitte Consulting LLP and is the global and US chief technology officer. He has spent more than 19 years with Deloitte, delivering complex transformation programs for clients in a variety of industriesincluding financial services, health care, consumer products, telecommunications, energy, and public sector. Briggs is a strategist with deep implementation experience, helping clients anticipate the impact that new and emerging technologies may have on their business in the futureand getting there from the realities of today. STEVEN EHRENHALT Steven Ehrenhalt is a principal with Deloitte Consulting LLP and a leader of the US and Global Finance Transformation practice. He has more than 27 years of experience providing consulting services to finance organizations. Ehrenhalts areas of focus include finance transformation, finance cost reduction, performance management, planning, budgeting and forecasting, organizational design, finance service delivery models, and talent management. DOUG GISH Doug Gish leads Deloitte Consulting LLPs Supply Chain and Manufacturing Operations service line and serves as the lead consulting principal for a large, global equipment manufacturer. He has more than 26 years of industry and consulting experience in supply chain and production operations management. NIDAL HADDAD Nidal Haddad is a principal with Deloitte Consulting LLP, where he is a member of the management committee and serves as Deloitte Digitals chief of markets. He is also the lead consulting principal for a group of high-tech and communications clients. Haddad acts as an adviser across a number of multi-industry programs and has more than 26 years of marketing, sales, and service experience. AUTHORS Tech Trends 2018: The symphonic enterprise 70 The new core ADAM MUSSOMELI Adam Mussomeli is a principal with Deloitte Consulting LLP and specializes in supply chain strategy. He is a founder of Deloitte Consulting LLPs digital supply networks capability and is responsible for its contingent fee portfolio in the consumer and industrial products industry. Mussomeli has more than 20 years of experience delivering global, end-to-end supply chain transformations for consumer and industrial products companies. ANTON SHER Anton Sher is a principal with Deloitte Consulting LLP and a leader of the Digital Finance Strategy and Transformation practice. He has more than 17 years of consulting experience, working closely with CFOs and senior finance leaders of clients to drive enterprise value and optimize the finance function. Shers client service is global and focuses on strategy, operating model, and digital technologies, primarily in the healthcare and life sciences sectors. Risk implications VIVEK KATYAL Vivek (Vic) Katyal is the Global and US Risk Analytics leader with Deloitte and Touche LLP. He also serves as the leader for operations for cyber risk services and managed risk services and represents risk in the Deloitte Analytics integrated market offering. In his role, Katyal primarily serves clients in the cyber risk domain but also has an extensive background in the financial services industry. ARUN PERINKOLAM Arun Perinkolam is a principal with Deloitte and Touche LLPs Cyber Risk Services practice and a leader within the Deloitte US technology, media, and telecommunications sector. He has more than 16 years of experience in developing large-scale digital and cyber risk transformational initiatives for global technology and consumer business companies. 71 1. Deloitte, Reinventing the ERP engine, 2013. 2. Deloitte, CFO Signals, 3rd quarter 2017. 3. Ibid. 4. Steven Ehrenhalt, Crunch time: Finance in a digital world, Deloitte, 2016. 5. Deloitte, CFO Signals, 3rd quarter 2017. 6. Eric Piscini, Joe Guastella, Alex Rozman, and Tom Nassim, Blockchain: Democratized trust, Deloitte University Press, February 24, 2016; Eric Piscini, Gys Hyman, and Wendy Henry, Blockchain: Trust economy, Deloitte Univer- sity Press, February 7, 2017. 7. Interview with Paul DeBartolo, vice president of finance portfolio management and optimization, Pfizer, Novem- ber 11, 2017. 8. Adam Mussomeli, Doug Gish, and Stephen Laaper, The rise of the digital supply network, Deloitte Insights, Decem- ber 1, 2016. 9. Ibid. 10. Brenna Sniderman, Monika Mahto, and Mark Cotteleer, Industry 4.0 and manufacturing ecosystems: Exploring the world of connected enterprises, Deloitte University Press, February 22, 2016. ENDNOTES Tech Trends 2018: The symphonic enterprise 72 The new core 73 Digital reality The focus shifts from technology to opportunity OVER the next decade, advances in digital realityan amalgamation of augmented reality (AR), virtual reality (VR), mixed re- ality, 360, and immersive technologieswill lead to more natural and intuitive ways for technology to better our lives. Indeed, our means of interfac- ing with digital information will likely no longer be screens and hardware but gestures, emotions, and gazes. This represents a leap forward comparable to historic transitions from client-server to the web, and web to mobile. And it may already be under way. International Data Corp. (IDC) projects that total spending on AR/VR products and services will soar from $9.1 billion in 2017 to nearly $160 billion in 2021, representing a compound annual growth rate of 113.2 percent.1 What accounts for such explosive growth? In- creasingly, companies are shifting their focus from experimenting with shiny object AR and VR de- vices to building mission-critical applications in the enterprise. Consumer-oriented investments in The augmented reality and virtual reality revolution has reached a tipping point. Driven by a historic transformation in the way we interact with tech- nology and data, market leaders are shifting their focus from proofs of con- cept and niche offerings to strategies anchored in innovative use cases and prototypes designed for industrialization. They are laying the groundwork for broader deployment by tackling issues such as integration experiences with the core, cloud deployment, connectivity, cognitive, analytics, and access. Some have even begun developing new design patterns and nurturing non- traditional skillsets, heralding a new era of engagement. These early adopters recognize a shift in the AR/VR winds: The time to embrace digital reality is now. Digital reality 75 gaming and entertainment continue, but increas- ingly the real action is happening in the workplace. IDC estimates that industry AR/VR use cases that will attract the largest investments in 2017 are on- site assembly and safety ($339 million), retail show- casing ($250 million), and process manufacturing training ($248 million).2 During the next 18 to 24 months, the digital re- ality trend will likely gain momentum as more com- panies pilot use cases and accelerate into produc- tion. Some early adopters are now in their second or third iteration of product or service design. Others have taken use cases all the way to industrializa- tion. For example, BMW has incorporated virtual reality into its automobile design process,3 while Air France has deployed immersive entertainment sys- tems on some flights that allow passengers wearing VR headsets to watch movies in 3D.4 This trend may accelerate as three promising de- sign breakthroughs are integrated into digital real- ity systems:  Transparent interfaces: A blend of voice, body, and object positioning capabilities will make it possible for users to interact with data, software applications, and their surrounding en- vironments. Though such functionality will de- velop further in the coming years, it can already make interfaces seem much more natural.  Ubiquitous access: Much like we enjoy with mobile devices today, in the near future AR/VR will likely provide an always on connection to the Internet or to enterprise networks. But unlike having to reach into our pockets for our phones, we may soon wear AR/VR gear for hours at a stretch. Advances in design and the underlying technology are giving rise to a new generation of comfortable, self-contained digital devices free of tethering wires or bulky battery packs.  Adaptive levels of engagement: You are at- tending a virtual meeting with colleagues and a loud 3D advertisement launches in your field of vision, disrupting your concentration and inter- rupting the meeting. For the same practical rea- sons that we must be able to mute the ringers on our smartphones and block pop-ups when surf- ing the Internet, with AR/VR having the ability to control data feeds appearing in our virtual environments will be crucial. In the near future, A guide to digital reality terms and acronyms Augmented reality (AR): Overlays digitally created content into the users real-world environment. Features include transparent optics and a viewable environment in which users are aware of their surroundings and themselves. Virtual reality (VR): Creates a fully rendered digital environment that replaces the users real- world environment. Features body- and motion-tracking capabilities. Mixed reality (MR): Seamlessly blends the users real-world environment and digitally created content in a way that allows both environments to coexist and interact. Utilizes advanced sensors for spatial awareness and gesture recognition. Immersive: A deeply engaging, multisensory, digital experience, which can be delivered using VR, AR, 360 video, mixed reality, and other technologies. Formats vary. Digital reality (DR): An umbrella term for augmented reality, virtual reality, mixed reality, 360, and immersive technologies. Tech Trends 2018: The symphonic enterprise 76 contextual traffic cop capabilities may be able to tailor data feeds to user preferences, location, or activities. Development of these game-changing capa- bilities may not happen overnight. Designing user experiences for immersive environments is a fun- damentally different process than creating experi- ences for flat screens. Indeed, it utilizes entirely new languages and patterns. Some design techniques will have to be invented by a new generation of pro- grammers whose skills fit more naturally in Holly- wood than in a traditional IT department. Already, we are seeing CIOs enlist film and videogame design veterans with computer-generated image (CGI) ex- pertise to help design VR experiences.5 Meanwhile, the major Hollywood studios are ramping up their own VR content development programs.6 As with any development initiative, there are real IT ecosystem issues to consider, including core integration, cloud deployment, connectivity, and ac- cess. Whats more, digital realitys component parts are still evolving, as are standards and governance strategies. Yet even with these headwinds, digital reality initiatives march steadily forward. Welcome to the Metaverse.7 Its time to get to work. Five big digital reality opportunities In previous editions of Tech Trends, we ex- amined AR/VR technologies and early use cases through a future-perfect lens, recognizing that broader adoption and commercialization would not happen overnight.8 Well, the future has arrived. The digital reality trend shifts the focus away from technology and firmly toward their development and deployment. As you explore digital realitys po- tential for your organization, consider the following opportunity areas:  Connect: Cooperation without co-location. Digital reality already makes it possible for workers to engage, share information with, and support colleagues in other locations. Some may think of this as glorified video telephony, but it is much more than that. For example, engineers sitting in a regional office will be able to see what field workers see as they repair and maintain re- mote equipment, helping to guide their actions. Scientists separated by oceans will convene in a virtual sandbox where they can perform col- laborative research. Videoconferencing and live chatsoften frustrating experiences hobbled by broken connections and unflattering camera an- glesbecome immersive interactions that serve up replicated facial expressions, gesticulations, and holograms in real time. Teams will be able to work together on shared digital assets such as virtual whiteboards or digital models that can be manipulated in real time.  Know: Digital reality can offer knowledge workersa broad term that basically applies to anyone using a computeraccess to the specific information at the exact moment they need it to do their jobs. This is more than a souped-up document-sharing toolit can actually present information in a visual context. For example, wearing DR glasses, construction engineers can see a detailed description of a projects electrical and plumbing parts, and also how the individual parts will fit into a wall. Imagine leveraging this same flexibility in any initial conceptualization phase, such as architecture and interior design, consumer product R&D, or supply chain and lo- gistics mapping. Immersive analytics can further enhance virtual collaboration by helping users explore data in multiple axes and dimensions. For example, by applying immersive analytics to historical data on urban cellphone tower place- ment, engineers immersed in a virtual environ- ment might be able to move cellphone towers around a map to gauge the potential impact that Digital reality 77 Short term Medium term Long term Sources: Deloitte analysis; *International Data Corp., Worldwide Semiannual Augmented and Virtual Reality Spending Guide, October 28, 2017; spending line is representative. Relative market interest Three phases of the digital reality market 0 $160B 120 80 40 Increasing battery life Total spending on AR/VR products and services* $160B2017 actual: $9.1B 2021 projected: Figure 1. Digital reality in the marketplace As technology develops, we move even closer to our data with the disintermediation of hardware and interfaces. Six specific developments are paving the way for the mass adoption of digital reality. Deloitte Insights | Deloitte.com/insights Increasing mobile bandwidth Increasing app ecosystem compatibility Decreasing data latency Decreasing price point of devices Decreasing social inertia Handheld AR/MR Extensive development of consumer use cases. Looking for the killer app. HMD for AR/MR Enterprise use cases well understood with significant hardware in market. HMD for AR/MR/VR AR/MR/VR become one with ubiquitous usage. Consumer and enterprise use cases. HMD for AR/MR Prototyping phase. HMD for VR In use for specific immersive use cases. Consolidation of providers. HMD for VR Device price point dropping. Beginning development of use cases. AR = Augmented reality; VR = Virtual reality; MR = Mixed reality; HMD = Head-mounted display. Tech Trends 2018: The symphonic enterprise 78 each placement could have on nearby residents quality of life.  Learn: Some pioneering companies are using digital reality to immerse trainees in lifelike situations that would be too expensive or logisti- cally impossible to recreate on the ground. For example, UPS now provides VR driving tests that allow new drivers to prove themselves in a virtual environment before taking the wheel of a five-ton delivery van.9 In its training simula- tion, KFC places employees in a virtual escape room where they must successfully complete a five-step chicken preparation process before they are released.10  Explore: Consumer-focused use cases are pro- liferating across the retail, travel-hospitality- leisure, and real estate sectors as vendors use digital reality to bring potential customers closer to the products, services, and experiences on of- fer. For example, Este Lauder has launched an AR virtual makeup mirror on its web and mo- bile sites that adjusts for light, skin texture, and shine so that users can virtually try on product shades using their photo or live video.11 Mean- while, guided virtual visits are poised to trans- form the real estate industry and the way agents work on a daily basis; they may never have to show up for an open house again.12  Play: Use cases and full deployments of DR technologies in gaming, storytelling, and live events are varied and numerousand will likely become more so in the coming years. IDC proj- ects that the investment in AR/VR gaming use cases alone will reach $9.5 billion by 2021.13 What does this mean for IT? Many questions about the impact that digital reality technologies could have on IT ecosystems remain unanswered. However, we are far enough along in the immersive journey to know that CIOs should start thinking now about their companys DR strategies and the computing power required to support them fully. Storage. The amount of data required to ren- der DR experiences is staggeringly largeand will grow even larger as technologies evolve and new functionality emerges. Consider this: Providing 360 views in VR requires storing each video view- point so that users can turn their heads while the video continues to run behind them. Translated, this means that designers need 10 to 20 times the storage capacity that they would need to play a standard HD video file.14 Cloud can likely meet in- creased storage requirements in a cost-efficient way, but it is not the only option. Perhaps digital reality could also be a forcing function to modernize your approach to data management, governance, and ar- chitecture (see Tech Trends 2018: Enterprise data sovereignty for more details). Core integration. Headgear manufacturers are designing APIs that tie core technologies and business processes into DR experiences. Imagine, for instance, being able to present customer, facility, or product content in a virtual environment. Like- wise, imagine being able to use this content in trans- actions initiated in digital reality. In the near future, deep hooks into ERP/CRM/CMS systems will be a critical component of DR system design. Analytics. What is the intent behind a gaze? It is currently possible to track the gaze of an individ- ual wearing an augmented reality headset and then, to discern user intent, analyze the data this track- ing generates. Eventually it may be possible to use tracking analysis to drive advertising. For example, when an individual gazes at the refrigerator, a pop- up discount to a neighborhood restaurant could appear in that persons field of vision. But what if it were possible to track an individuals gaze for 12 hours at a time? The amount of storage needed to support tracking on this scale would be immense. Whats more, analyzing this volume of data in real time would require immersive analytics capabilities far more powerful than those many companies cur- rently deploy. Digital reality 79 Bandwidth and networking. At present, few network operators can deliver the bandwidth speeds that AR/VR streaming and 360 experiences require. For example, the kind of low-resolution ex- perience available with many VR displays requires at least 25Mbit/s for streaming; for HD resolutions, the requirement jumps to roughly 80Mbit/s.15 Re- cent research finds that only 7.1 percent of global connect speeds are above 25Mbit/s.16 Though na- scent efforts to develop the intelligent traffic man- agement solutions, compression algorithms, and low-latency/high-throughput capabilities needed for AR/VR are under way, in the short term, band- width and networking could slow progress in digital reality initiatives. Skeptics corner Okay, so the VR goggles you got for your birthday make you feel seasick. Dont let green gills color your opinion of digital reality technologies and the possibilities they offer your company. Please allow us to set the record straight on the future that lies ahead. Misconception: Digital reality in manufacturing? Field operations? Give me a break. Right now, VR headsets must be tethered to a computer during operation. Reality: Fair enough. Currently, VR mobility is largely limited by cord length. The good news is that tetherless products are emerging, with battery technology evolving at a fast clip. Moreover, inside- out tracking technology is poised to increase VR mobility. Some higher-end headsets use external cameras and sensors to track a VR users position within a room. Since mobile VR systems dont typically offer positional tracking capabilities inside-out tracking places sensors that read depth and perception cues on the headset itself, which allows users to escape the confines of sensor- and camera-filled rooms.17 Misconception: Youve got to be kidding: $850 for VR glasses? Reality: In late summer 2017, prices for major-label VR gear took a welcome nosedive.18 VR kits are running anywhere between $200 and $600, last time we checked. At these prices, the threshold for achieving positive ROI with existing VR capabilities becomes considerably lower. As expanded capabilities emerge, new experiences and designs could boost ROI further. Misconception: We havent even figured out how to get the most from smartphones and tablets. Before we get lost in science fiction, lets finish the job with todays technology. Reality: Its not an either/or scenario. Just as mobile has not replaced desktop and web applications, digital reality isnt likely to replace mobile. However, it can help us to tackle some problems in ways that traditional technologies do not. If the use cases discussed in this chapter resonate with you, it might be worth launching a few digital reality bets in parallel with your ongoing smartphone and tablet deployments. This might give you an early-adopter advantage when the DR trend heats up in the months to come. Tech Trends 2018: The symphonic enterprise 80 LESSO N S FRO M TH E FRO N T LIN ES At Google, the revolution will be virtualized Google is no stranger to digital reality: Over the last few years, it has launched Cardboard, Tango, Daydream, and most recently, ARCore. Like many companies operating in the space, it is studying pos- sible use cases, testing ideas, and designing road- maps. But while some firms aim to make a quick impact with a one-shot device, Google is preparing to launch a series of developmental chess moves over the next three to five years that it believes will deliver a powerful virtual experience. These deliber- ate initiatives are driven by the companys belief in AR/VRs long-term potential. AR/VR works as a platform not because of portability or personalization but because of its in- creased intuitiveness, says Steven Kan, Googles head of AR/VR global strategy. The primitives of computer science are input and output. On the out- put front, display technology has been improving for years, but the claims of immersion from bigger screens and higher resolution havent fundamen- tally changed whats possible. On the input side, we have gone from punch cards to keyboards to touch- ing and swiping. Now were able to reach out and touch something. Put those together, and you have the next computing platform. What could be more intuitive than manipulating real or virtual objects that arent being viewed on a device but appear right in front of you? Googles AR/VR strategy team is looking to build a full-stack platformhardware, operating system, and end-user applications. Each layer of the stack has its own trajectory: Hardware, software, and components will have 18-month to three-year development cycles; displays can take five years to develop; and applications can be built in just weeks, months, or quarters. Kans team maps out each journey to extrapolate where they will converge, a process he likens to playing a game of chess. To date, most of Googles forays into digital re- ality have targeted the consumer market, but Kan sees the enterprise market playing a key part in the technologys future. There are use cases delivering hard ROI with todays technologies to spur business and government investment, even though the tim- ing and trajectory of broader mass adoption remain uncertain. Google has identified four enterprise sce- narios that show promise:  Help me learn. Google validated the tech- nologys power to educate with Google Expedi- tions, putting Cardboard headsets in schools to facilitate virtual field trips.19 Now the company is looking at potential uses in corporate training and even as a replacement for how-to manuals on job sites. Digital reality 81 LE SS O N S FR O M T H E FR O N T LI N ES  Help me create. In architecture and in- dustrial design, the technology could enable real-time, collaborative discussion among pro- fessionals involved with a project. They could walk through a real-size model of the proposed product or building from their disparate remote locations, which could improve the quality and cycle time of the design process and drive down project costs.  Help me operate. In the field, engineers could access the service history of specific equip- ment or written guidance for performing triage and repairs. They would review this information in a hands-free, heads-up manner that main- tains their autonomy and supports worker safe- ty. If needed, they could also connect via their headsets to remote specialists who could virtu- ally demonstrate repair techniques.  Help me sell. One of the leading use cases for AR/VR is salesmost notably for demonstrating products, allowing interaction with digital prod- uct catalogs, and allowing buyers to get familiar with equipment prior to closing a deal. Developers are still working on some of the el- ements needed to expand beyond these use cases, Kan notes. For example, it is still difficult to access 3D models and digital assets: CAD programs were not built with AR and VR in mind, which can lead to rendering problems. Likewise, existing policy management, device management, and enterprise controls for access and entitlements also present challenges. The initial round of devices were not designed with manageability in mind, though we are able to address this retroactively, much like enterprises did in the early days of smartphones and tablets, Kan says. That said, competition for already-scarce design and development talent has become fierce as the entertainment and gaming in- dustries ramp up digital reality initiatives. Even at this early stage, Kan is optimistic about digital realitys enterprise potential. We see evi- dence of positive ROI for these use casesfor ex- ample, R&D design times are being shortened by up to 20 percent. The potential for positive ROI is the bedrock of my faith in AR/VRs enterprise pos- sibilities, he says, adding, As long as that potential exists, well figure out how to bring the other puzzle piece together. The investments Google has made over the last three years in ARCore, Tango, and Cardboard, among others, have already enhanced the enter- prise ecosystem. When adoption of this technology eventually accelerates, we are confident Google will be able to continue adding value to the ecosystem, Kan says. People underestimate how big of an im- pact this shift will have once it happens.20 Facebooks virtual thumbs- up to the enterprise Facebook has set a goal of reaching 1 billion users through virtual reality with Oculus, the VR headset and platform maker it acquired in 2014. Although Facebook is primarily a consumer-focused platform, in the past couple of years it has seen large-scale enterprises adopt its Oculus technology, including the Oculus Rift headset, to assist in training, sales, marketing, and collaboration. Our virtual reality products originally were tar- geted at consumers, but by addressing the social aspect and presence, VR can remove barriers that transcend distance and time in ways that can ben- efit the enterprise, says Ash Jhaveri, VP of business development at Facebook and Oculus. We found people using Oculus headsets to create experiences we wouldnt have imagined ourselves. They were doing things within their organizations such as find- ing efficiencies, reducing costs, and improving sales and operations, all with virtual reality. Our new Oculus for Business program is a direct response to this growing interest from business-to-business customers. Well be able to better serve demand with a dedicated focus and interest in evolving VR in the workplace.21 Companies across industries have found rich and varied applications for VR technology: Tech Trends 2018: The symphonic enterprise 82 Digital reality LESSO N S FRO M TH E FRO N T LIN ES LESSO N S FRO M TH E FRO N T LIN ES  A multinational consumer goods corporation uses the technology as a merchandising aid, mocking up shelves with complementary prod- ucts to assist multiple product-line owners in collaborative marketing efforts, as well as to present suggested display ideas to retailers.  Automaker Audi has outfitted showrooms with virtual models to educate customers on its vehi- cles inner workings as well as help them choose, and preview, thousands of model configurations and interior and exterior colors and fittings.  Cisco is experimenting with new collaboration tools by integrating its existing Cisco Spark product with VR technology. Remote teams can be present in the same room collaborating by writing on and pinning to either a virtual white- board or a connected whiteboard device that is on-premises. The resulting diagrams and con- tent can be printed for reference.  Across industries, several organizations have be- gun to experiment with data visualization pro- grams that allow users to immerse themselves in data with a 360-degree view, as well as with 3D versions of autoCAD that would allow designers to collaborate over a 3D rendering of a building, car, or engine.  Childrens Hospital Los Angeles is training resi- dents in emergency care by simulating a realistic ER scenario in which they need to resuscitate an infant. Students try to diagnose and save the child by navigating emergency-room equipment and medications in a small space with a hysteri- cal parent watching their every move. Oculus is also adding core features to its prod- ucts to support the enterprise. One upcoming new feature is virtual desktop, which unlocks the PC to turn a users desktop screen into a 720-degree com- mand center that provides better access to infor- mation to do her job. There are still challenges to address before it becomes ubiquitous, such as the costly price point for screens and panels, render- ing clarity, tweaking optics for prolonged use, and developing interfaces that dont require constant movement of limbs to be effective, but Jhaveri is convinced there will be demand for a virtually im- mersive workspace. As great as we think phones and tablets are, theres just something magical about unbounded screen space, he says. Truly immersive VR expe- riences trigger emotional responses, which is im- portant for consumer and enterprise adoption. Ul- timately, those responses will help you tell stories better, translate relationships, and help grow your business. Driving the enterprises digital reality Unity Technologies is a leading game develop- ment platform, known for its Unity creation engine, which reaches more than 2 billion devices world- wide.22 With many of the initial forays into virtual and augmented realities being videogames, its probably unsurprising that Unity created a develop- ment platform for 2D, 3D, VR, and AR experiences. However, Unitys leadership team is also turning its attention to the enterprise, where the automotive, architecture, aerospace, and creative fields, among others, are looking to digital reality to create rich user experiences for customers and employees. Immersive technology is the next computing platform, after mobile, says Tony Parisi, Unitys global head of AR/VR strategy. It will just be a part of daily life, like the mobile phone is today, although form factors and costs will have to evolve before well see mass consumer adoption. We believe most of the interesting activity will be in the enterprise over the next few years.23 Unity is working with industries far beyond gaming looking to derive value from digital real- ity tools. For example, the auto industry has taken an interest in using digital reality for tasks as var- ied as designing vehicles, training operators and service technicians, performing simulations for autonomous vehicle training, and creating compel- ling marketing and sales experiences. Unity is ex- 83 tending its platform by adding tools that can assist in automobile design. While automakers have used CAD software for years, most continue to use physi- cal prototypes made of claywhich can be a costly and time-consuming proposition. But with 3D en- vironments and digital reality, auto designers can take simple physical mockups and augment them with design geometry, paint and material finishes, and even interactive capabilities in digital prototype equivalents. This can reduce the time to iterate, pro- vide a more realistic experience, enable new ways to collaborate, be cost-effective, and ultimately im- prove product quality. Of course, there are challenges ahead in creating digital reality solutions for the enterprisedata in- tegration, enterprise licensing, the logistics of soft- ware deployment, and producing product lifecycle management tools to move 3D data around an or- ganization. However, companies are forging ahead, and Unitys teams continue to evolve its digital real- ity platform to support their clients use cases, in- cluding home furniture shopping, equipment-fail- ure diagnosis applications for both industrial and office equipment, and training, merchandising, and store planning for retail. The next two to three years will be all about un- derstanding and mastering the medium, with new classes of content creators who can master real- time 3D, Parisi says. We can provide platforms, and we will see independents and production stu- dios creating digital reality content to deploy over them. There are tremendous opportunities across many industries. LE SS O N S FR O M T H E FR O N T LI N ES Tech Trends 2018: The symphonic enterprise 84 Digital reality Judith McKenna, executive vice president and chief operating officer WALMART US How people live, work, and shop is changing rapidlyand so is Walmart. By combining technology and innovation with a commitment to training, skill development, and lifelong learning, we are reinventing our store experience and empowering our people to deliver for customers, grow in their jobs, and have the opportunity for advancement and success. Our journey began by reviewing how work was getting done in our stores with an eye toward simplification. The result was a complete rewrite of nearly every process used to manage our day-to-day business. We also saw an opportunity to equip our people with mobile technology and a suite of custom- built apps that provide real-time data on everything from sales to availability to customer satisfaction, helping our associates know where they can make the biggest difference. Today, thanks to data and technology, our people are able to manage their stores directly from a tablet on the sales floor. At the same time, we set out to reinvent our training programs to support the new way of working and skill development our people would need for their future. Our existing online and job-shadowing training programs were replaced with a hands-on classroom experience called Walmart Academy, which will have trained approximately 220,000 associates in 200 sites across the country by the end of the year. When you do something at that scale, you need to think about how you will teach as well as what you will teach. From the start, we wanted to enhance the training experience with technology. In the academies, the coursework doesnt require printed or written materialsjust tablets, screens, and facilitators. We designed the curriculum to be 25 percent in the classroom and 75 percent on the sales floor, so our people could gain hands-on experience using technology in real-life scenarios. But not every situation can be easily created on the sales floorlike a spill or the holiday rush. So we began looking for new ways to bring those experiences to life. Around that time, one of our associates saw football players at the University of Arkansas training with virtual reality. While we were exploring ways we might use VR, we hadnt yet considered it as a way to teach. We started with one VR headset in one Walmart Academy, with a single-use case: We placed an associate in a virtual store environment and asked her to look for potential problems such as litter on the floor, a spill, or a sign hanging incorrectly. The other trainees observed, in real time, the associates interaction with the environment on screens in the classroom. The trainees were fully engaged in the experience, able to clearly visualize the surroundings and the corresponding behaviors. It worked so well that were now expanding VR-based training and a wide variety of use cases to all 200 academy locations. Looking at engagement and recall of the material, the power of virtual reality as a training tool became clear. Im not sure VR will ever be a 100 percent replacement for real-life sales floor situations, though there is value in being able to experience situations that are difficult to recreate, and using cutting-edge technology makes the experience fun and engaging for our associates. There is undoubtedly a lasting impact on our associates overall experience when they learn from this technology. More than a how-to manual that spells out routine actions and responses, the immersive experience helps build confidence and prepare our people to run great stores. My take 85 Technology is reshaping the future of retail, and in order to compete, we must always lean into innovation and try new things. Some will work; some will not. We test, learn, and move on. At one time, in-store Wi-Fi was a noveltynow its a table stake. In the same way, we werent sure whether VR training would work or if it was just an intriguing idea. Now we know VR is a powerful and effective way to empower our associates and teach them new skills. Combined with our academy training program and handheld technology, it will help drive the transformation of what it means to work (and shop) at Walmart. 86 With digital reality changing how people interact with data, the environment, and each other, the cy- ber risk implications of technology systems become even more complex. While no organization is im- mune to a cyber breach, organizations are expected to secure virtual as well as physical worlds, at a time when the technology is being deployed in critical situations, such as surgical procedures or military training. Rather than viewing these issues as ob- stacles, meeting them head-on early in the develop- ment process can help mitigate cyber risks, enable faster deployment and innovation, and minimize brand and reputational risks. The risks associated with digital reality are var- ied, becoming more nuanced and serious as appli- cations are ported onto DR platforms. They can in- clude physical harm, property damage, public safety, and operational disruption. Organizations should view risk management as an expected standard of care, taking into account customer well-being, con- tractual obligations, and stakeholder expectations. Start with the fundamentals: Issues such as identity and authentication in the virtual world will differ from logging into a laptop with a user name and password. Embedding risk management into the organizational constructthroughout the concep- tual, delivery, and run phases of developmentis a crucial step in digital transformation. One aspect to consider is protecting user iden- tity and data. Users upload and generate their own content, then interact with other users. The chal- lenge is protecting that data without sacrificing a rich user experience. This requires a thorough in- ventory of the data you are extracting and how you are accessing, using, and storing it. The same data privacy and security controls that you implement throughout the rest of your organization should be in place for DR applications. Additionally, deter- mine your internal and customer-facing privacy and data protection policies (including jurisdictions) for DR activities, and communicate those within the or- ganization and to customers. Another dimension is third-party access to your platform and network. If you use third parties or open-source software to build your platform, you should mitigate the risk of exposing code or sensi- tive data due to poor or malicious design. Build in security from the start of development, and extend it throughout your technology ecosystem. With to- days pressure around speed to market and first- mover advantage, developers may not consider risk implications until after the fact. Understand the components that enable your DR experience; review the policies and processes of your develop- ers, third-party vendors, and partners; and promote resilience and have them follow your organizations security protocols. VR equipment can also pose risks. With users re- lying on VR headsets and the content served to guide their actions and responses, it is critical to maintain the integrity of the data, device, and infrastructure to minimize physical harm, disorientation, and ac- tion triggered by erroneous information. Your tech- nology stack should be monitored and managed on a real-time basis, and assess devices and interfaces to identify points of vulnerability. Enterprise secu- rity protocolsincluding third-party oversight pro- tocolsshould be extended or adapted to the DR platform. Thus far, there are few standards regu- lating VR experiences, and regulations likely will continue to lag behind technological development. However, it is essential to integrate robust controls into the product or platform. Customers expect it, as do regulators and shareholders. Virtual reality can play an important role in planning for and responding to both physical and cyber threats. It can simulate disasters for response training without putting employees or the organiza- tions infrastructure in harms way. Also, it makes an effective threat-modeling tool for physical and logical threats. In the very near future, VR could al- low security professionals to visualize the paths that an adversary might take through a network, build- ing, city block, or industrial facility. It could also provide penetration testers with three-dimensional virtual threat models of applications, software, and solution blueprints. Digital reality RISK IM PLICATIO N S 87 Theres a global excitement around digital real- itys potential to transform many industries. How- ever, the expected timeframe for adoption is a bit further out than most of the other trends, based on findings from a survey of Deloitte leaders across 10 regions. The opportunities to drive organizational efficiency, make dangerous occupations safer, and augment worker skillsets through virtual and aug- mented realities are being explored in Africa, Aus- tralia, and Latin America, in particular. In Africa and Latin America, mining companies and other high-risk industries are beginning to ex- periment with the technology to help mitigate safety risks.24 However, the high costs of initial investment will likely stave off widespread adoption of the tech- nology in those regions for another two to five years. Australia is already deploying digital reality in the entertainment and retail sectors,25 while real estate, financial services, and education are explor- ing opportunities as well.26 Leading organizations in the region are integrating multidimensional layers of experience architecture across strategic, digi- tal, and spatial initiatives and are measuring these against key performance indicators. On the Euro- pean front, organizations are piloting the technol- ogy in a variety of contexts, including infrastruc- ture maintenance and retail, but the main barrier to widespread adoption is the low adoption rate of ultra-broadband networks. Australia is already seeing widespread impact from digital reality while other regions are moving toward large-scale adoption in approximately one to five years. In addition to cost concerns, Deloitte leaders cite the dramatic cultural shift required to work in virtual worldsspecifically in Africa and the Middle Eastand a need to reskill the workforce, particularly in Southern Europe and Latin America, as barriers to widespread deployment. Deloitte Insights | Deloitte.com/insights Figure 2. Global impact Relevance Significant High Medium Low None Timeliness Now 1 year 12 years 25 years 5+ years Readiness Significant High Medium Low None N. America N. Europe C. Europe Israel Asia S. America S. Europe S. Africa Middle East Australasia Global impact measures Source: Deloitte analysis. G LO BA L IM PA CT Tech Trends 2018: The symphonic enterprise 88 Where do you start? Few companies have fully commercialized their digital reality deployments. Many are just begin- ning their journeys by learning more about these solutions and surveying the growing AR/VR mar- ket. Because DR components are still being tested in enterprise environments, diving headfirst into an ambitious AR/VR initiative could be risky. Consider, instead, taking the following preliminary steps to lay the foundation for larger projects to come:  Learn more about the technology: Tradi- tional IT skillsets offer little practical value to those working with AR, VR, 360, and immer- sive technologies. Take this opportunity to up- skill. Formal training or even a few hours spent with one of many development kits on the mar- ket can help you develop the skills and vocabu- lary youll need to kick devices tires and under- stand their value potential.  Speak a new language: Designing for digi- tal reality requires embracing new patterns and perspectives along with a wholly different design vocabulary. It also requires new enabling tools and services to bring the experiences to life and make them work in the real world. High-defi- nition 3D image capture and mapping equip- ment are emerging, thus accelerating developers abilities to recreate real-world physical environ- ments with new AR/VR tools. Gaming engines are finding new purchase in the enterprise, with Unreal, Unity, and others being used to create simulations and virtual environments for AR and VR interaction.  Take a look around you: Across industries, companies and government agencies are devel- oping use cases, piloting DR technologies, and in some cases moving toward production deploy- ments. As you explore your organizations pos- sibilities, look first within your own sector. What are your competitors doing in this space? Like- wise, what business goals are companies in adja- cent sectors pursuing with their DR initiatives? Finally, your supplier, vendors, and business partners may be willing not only to discuss their own efforts but to provide their perspectives on potential use cases and opportunities that you can pursue jointly.  Dont hold out for perfection: The pace of innovation in the DR space is accelerating and will continue to do so for the foreseeable future. The consumer market is driving much of this innovation, but increasingly insights emerging from enterprise use cases, PoCs, and production deployments are influencing designs and driving the development of new capabilities. The per- fect digital reality system does not existyet. But that should not keep you from exploring DR opportunities and developing use cases of your own. Remember: The shelf life of any given de- vice needs to be only long enough to support its original purpose. The technology will evolve, as will your deployment strategies. Its time to get started. Bottom line As more DR use cases accelerate into full production, the idea that immersive technologies could become the next big platform seems less like science fiction and more like a reasonable vision of the future. To be sure, challenges remain on digital realitys path to full commercialization. But these challenges do little to diminish its long-term disruptive potential. Digital reality is poised to transform the way we interact with data and experience the world around us. Are you ready? Digital reality 89 ALLAN COOK Allan Cook is the global and US technology, media, and telecommunications sector leader for Deloittes Operations Transformation practice, with more than 25 years of industry experience. He works with a wide variety of organizations to build their innovation strategies, corporate visions, and business plans. Cooks client work has focused on strategy, scenario planning, business transformation, innovation, and digital reality. RYAN JONES Ryan Jones is a principal with Deloitte Consulting LLP and leads Deloittes Augmented, Virtual and Mixed Reality practice. He has over 20 years of experience helping technology companies with strategic business and technology transformations, including the development and execution of new go-to-market strategies, business and operating models, customer and partner channel ecosystems, Agile, and digital. Risk implications ASH RAGHAVAN Ash Raghavan is a principal with Deloitte and Touche LLP and leads Deloitte Advisorys Center for Intelligent Automation and Analytics practice. He brings more than 15 years of experience in information technology to his work with numerous Fortune 100 clients and CIOs. For the past decade, Raghavan has focused in the fields of cyber risk and risk management consulting, primarily in the financial services industry. IRFAN SAIF Irfan Saif is an advisory principal with Deloitte and Touche LLP and has over 20 years of IT consulting experience, specializing in cybersecurity and risk management. He serves as the US technology industry leader for Deloittes Advisory business and is a member of Deloittes CIO Program and its Cyber Risk practice leadership teams. AUTHORS Tech Trends 2018: The symphonic enterprise 90 1. International Data Corp., Worldwide Semiannual Augmented and Virtual Reality Spending Guide, October 28, 2017. 2. Ibid. 3. Aaron Mamiit, Why and how BMW will use HTC Vive VR in vehicle development process, Tech Times, April 9, 2016. 4. Woodrow Bellamy III, Nine companies using virtual and augmented reality in aviation, Aviation Today, August 24, 2017. 5. Kevin J. Ryan, This startup recruited a Hollywood designer to create the coolest cybersecurity software youve ever seen, Inc. 6. Matt Pressberg and Matt Donnelly, Hollywoods virtual reality push: How all 6 major studios stack up, Wrap, July 24, 2017. 7. Neal Stephenson, Snow Crash (New York: Bantam Spectra, 1992). 8. Nelson Kunkel and Steve Soechtig, Mixed reality: Experiences get more intuitive, immersive, and empowering, De- loitte University Press, February 7, 2017. 9. Matt McFarland, UPS is training drivers with virtual reality, CNN, August 15, 2017. 10. Whitney Filloon, KFCs new employee training game is a virtual reality nightmare, Eater, August 23, 2017. 11. Sarah Tseggay, Estee Lauders latest project uses AR to find your perfect lipstick, Next Reality, July 18, 2017. 12. Azad Abassi, How virtual reality could revolutionize the real estate industry, Forbes, March 28, 2017. 13. International Data Corp., Worldwide Semiannual Augmented and Virtual Reality Spending Guide. 14. Andy Mills, Virtual reality drives data center demand for storage, Enmotus Blog, February 8, 2017. 15. Teresa Mastrangelo, Virtual reality check: Are our networks ready for VR?, Technically Speaking, June 29, 2016. 16. Akami, Q1 2017 State of the Internet/Connectivity Report, May 31, 2017. 17. Adi Robertson, Self-tracking headsets are 2017s big VR trendbut they might leave your head spinning, Verge, January 12, 2017. 18. Charlie Fink, Behind those high-end VR price cuts, Forbes, August 21, 2017. 19. Marcus Shingles, Bill Briggs, and Jerry ODwyer, Social impact of exponential technologies, Deloitte University Press, February 24, 2016. 20. Interview with Steven Kan, head of global strategy, AR and VR, Google, September 27, 2017. 21. Interview with Ash Jhaveri, vice president of business development at Facebook and Oculus, October 30, 2017. 22. Unity, Company facts, accessed November 14, 2017. 23. Interview with Tony Parisi, global head of AR/VR strategy, Unity Technologies, October 23, 2017. ENDNOTES Digital reality 91 24. Mining Magazine, Virtual blast training facility for South Africa, July 20, 2017; Ilan Solomons, Virtual reality tech- nologies gaining traction in South African mining sector, Engineering News, November 13, 2015; Carly Leonida, Immersive virtuality enters mining, Mining Magazine, March 30, 2017; John Bayliss, Cool operators, Volvo Con- struction Equipment, September 29, 2017. 25. David White and Robbie Robertson, Immersive technology no longer in the future, its here now for retailers, Deloitte, May 3, 2017; Zoey Chong, Dive Australias Great Barrier Reef with Netflix and Google, CNET, October 25, 2017. 26. Silvia Liu, How virtual reality is transforming the real estate industry, PropertyMe, April 26, 2017; Paul Petrone, Australias biggest bank is brilliantly using virtual reality to recruit, LinkedIn, March 9, 2016; Asha McLean, Com- monwealth Bank using VR to educate children, ZDNet, October 9, 2016. Tech Trends 2018: The symphonic enterprise 92 Digital reality 93 Blockchain to blockchains Broad adoption and integration enter the realm of the possible AMID the media frenzy surrounding bitcoin a few years back, prescient technologists and business leaders recognized that the real story was not the scandals swirling around Silk Road or Mt. Gox but, rather, bitcoins technology endoskeleton, blockchain. They saw tremendous disruptive potential in this open, shared ledger platform. For example, public and private sector organizations might use it to share information se- lectively and securely with others, exchange assets, and proffer digital contracts.1 Individuals could use blockchain to manage their financial, medical, and legal recordsa scenario in which blockchain might eventually replace banks, credit agencies, and other traditional intermediaries as the gatekeeper of trust and reputation.2 Though at the time few use cases for such op- portunities were ready for prime time, the notion that blockchain had significant potential not just for business but in society as a whole began to gain traction. Today, blockchain is garnering headlines once again, this time for the vast ecosystem of cross- Blockchain technologies are on a clear path toward broad adoption, with proofs of concept shifting toward production and leading organizations explor- ing multiple concurrent use cases of increasing scope, scale, and complexity. Moreover, initial coin offerings and smart contracts are finding more applica- tions and creating more diversity throughout the blockchain ecosystem. Now is the time for organizations to begin standardizing on the technology, talent, and platforms that will drive future blockchain initiatives. Likewise, they can begin identifying business consortia to join. Beyond these immediate steps, they should also look to the horizon for the next big blockchain opportunity: coordinating, integrating, and orchestrating multiple blockchains working together across a value chain. Blockchain to blockchains 95 industry use cases emerging around it. Blockchain is now finding applications in every region and sec- tor. For example:  Europes largest shipping port, Rotterdam, has launched a research lab to explore the technol- ogys applications in logistics.3  Utilities in North America and Europe are using blockchain to trade energy futures and manage billing at electric vehicle charging stations.4  Blockchain is disrupting social media by giving users an opportunity to own and control their images and content.5  Blockchain consortiumsincluding the Enter- prise Ethereum Alliance, Hyperledger Project, R3, and B3iare developing an array of enter- prise blockchain solutions. This list is growing steadily as adopters take use cases and PoCs closer to production and industry segments experiment with different approaches for increasing blockchains scalability and scope. In- deed, the path to broad blockchain adoption looks strikingly well paved. Gartner Inc. projects that blockchains business value-add will grow to $176 billion by 2025.6 Yet there are several issues that warrant atten- tion. With the proliferation of platforms and proto- cols in the marketplace today, no single solution has emerged as the clear winner; consequently, no tech- nical or process standards are yet in place. Likewise, operational siloes keep some companies from either developing clear business plans around blockchain or collaborating with ecosystem partners for mass adoption. In the latest blockchain trend that will unfold over the next 18 to 24 months, expect to see more organizations push beyond these obstacles and turn initial use cases and PoCs into fully deployed pro- duction solutions. Though the tactics they use to achieve this goal may differ by sector and unique need, many will likely embrace three approaches that, together, comprise the latest blockchain trend:  Focus blockchain development resources on use cases with a clear path to commercialization  Push for standardization in technology, business processes, and talent skillsets  Work to integrate and coordinate multiple blockchains within a value chain Because we are only now coming to the end of a hot blockchain hype cycle, many people assume that enterprise blockchain adoption is further along than it actually is. In reality, it will take time and dedication to get to large-scale adoption. But when it does arrive, it will be anchored in the strategies, unique skillsets, and pioneering use cases currently emerging in areas such as trade, finance, cross-bor- der payments, and reinsurance. As these sectors lead in the coming months, blockchains future will follow. Treading the path to commercialization Regardless of industry bias, blockchain use cases that feature a clear path to commercialization often stand a better chance of reaching production. Why? Because in the minds of stakeholders and decision- makers, the words potential ROI can magically transform a nebulous tech concept into a scalable business opportunity. By focusing available resources exclusively on those use cases and PoCs offering a path to com- mercialization, CIOs are offering clear incentives for stakeholders and partners, driving ROI in indi- vidual blockchain solutions, and potentially creat- ing additional revenue or cost savings opportunities. In a way, they are also formalizing and legitimizing blockchain development strategies, both prerequi- sites for further refining project goals, setting time- lines, and recruiting specialized talent. By answering the following questions, CIOs can assess the commercial potential of their blockchain use cases: Tech Trends 2018: The symphonic enterprise 96  How does this use case enable our organizations strategic objectives over the next five years?  What does my implementation roadmap look like? Moreover, how can I design that roadmap to take use cases into full production and maxi- mize their ROI?  What specialized skillsets will I need to drive this commercialization strategy? Where can I find talent who can bring technical insight and commercialization experience to initiatives?  Is IT prepared to work across the enterprise (and externally with consortium partners) to build PoCs that deliver business value? One final point to keep in mind: Blockchain use cases do not necessarily need to be industry-specific or broadly scoped to have commercial potential. In the coming months, as the trend toward mass adoption progresses, expect to see more use cases emerge that focus on enterprise-specific applica- tions that meet unique value chain issues across organizations. If these use cases offer potential rev- enue opportunities down the roadthink licensing, for exampleall the better. Next stop, standardization As blockchain use cases grow in scope, scale, and complexity, the need for standardized technologies, platforms, and skillsets becomes more pressing each day. Consider standardizations potential ben- efitsnone of which companies developing block- chain capabilities currently enjoy:  Enterprises would be able to share blockchain solutions more easily, and collaborate on their ongoing development.  Standardized technologies can evolve over time. The inefficiency of rip-and-replace with every it- eration could become a thing of the past.  Enterprises would be able to use accepted stan- dards to validate their PoCs. Likewise, they could extend those standards across the organi- zation as production blockchains scale.  IT talent could develop deep knowledge in one or two prominent blockchain protocols rather than developing basic knowhow in multiple pro- tocols or platforms. Unfortunately, there are currently no overarch- ing technical standards for blockchain, and it is unrealistic to think we will get them soon, if ever, across all use cases. For CIOs, this presents a press- ing question: Do you want to wait for standards to be defined by your competitors, or should you and your team work to define the standards yourselves? For financial services giant JP Morgan Chase, sitting on the sidelines while others in the finan- cial sector developed blockchain standards was not an option. In 2017, the firm launched Quorum, an open-source, enterprise-ready distributed ledger and smart contracts platform created specifically to meet the needs of the financial services industry. Quorums unique design remains a work in prog- ress: JP Morgan Chase invited technologists from around the world to collaborate to advance the state of the art for distributed ledger technology.7 Not all IT shops are in a position to emulate this strategy for influencing the development of block- chain standards. But there are steps that CIOs can take to promote standardization within their com- panies and industries rather than waiting passively for universal standards to emerge. For example, by plugging into external developer ecosystems, IT shops can begin influencing standardization discus- sions and exchanging best practices with like-mind- ed organizations. Internally, CIOs can empower their teams to make decisions that drive standards within company ecosystems. Finally, in many orga- nizations, data management and process standards already exist. Dont look to reinvent the wheel. Ap- ply these same standards to your blockchain solu- tion. Blockchain to blockchains 97 Integrating multiple blockchains in a value chain In the future, blockchain solutions from different companies or even industries will be able to com- municate and share digital assets with each other seamlessly. For organizations whose use cases turn on blockchain ecosystem diversity and scalability, the potential benefits of integration are clear: Hav- ing more partnerships within a blockchain ecosys- tem can drive greater value and boost blockchain ROI. Likewise, interoperability can make it possible to customize and enhance blockchain solutions without rendering them obsolete. Unfortunately, many of the technical challenges preventing blockchain integration persist. Different Deloitte Insights | Deloitte.com/insightsSource: Deloitte analysis. Figure 1. The blockchain implementation roadmap Expand MVE by creating or joining consortiums Develop operating models and governance Pilot blockchain solution in live production environment Design roll-out strategy and integrate with legacy systems Build and test the proof of concept iteratively Retrospective to confirm value and identify new challenges SCALE Select the blockchain technology stack Develop functional and technical architecture Industrialize technology stack and engage regulators if needed Institutionalize operating structure Define the minimum viable ecosystem (MVE), onboard team Consortia success factors Leadership Governance Membership Funding Phases in the agile workflow DesignDiscover Build Review Use case evaluation framework Viability: Expected return Feasibility: Ability to deliver Desirability: Alignment with business Learn where and when blockchain makes sense Inventory use cases address- ing business challenges Assess how well use cases leverage block- chain strengths Prioritize use cases based on framework and select 13 PROOF OF CONCEPT USE CASE Tech Trends 2018: The symphonic enterprise 98 protocolsfor example, Hyperledger Fabric and Ethereumcannot integrate easily. Think of them as completely different enterprise systems. To share information between these two systems, you would need to create an integration layer (laborious and painful) or standardize on a single protocol. Even if the technical challenges were solved, connecting two blockchains is much harder than connecting two networks. Why? Because with blockchain integration, you are connecting two val- ue networks that may not necessarily talk to each other. This means that when transferring digital as- sets from one blockchain to another, you must be able to transfer the first blockchains value set of all its past transactions as well. You must also be able to guarantee that the data packets point to the same places in both blockchains, which helps maintain data integrity and auditability. Right now, the Hyperledger Foundation and oth- ers are working to establish technical standards that define what constitutes a blockchain, and to develop the protocols required to exchange assets. These efforts will continue, and as they do, convergence of protocols will likely accelerate and standards emerge. Likewise, interoperable technologies will eventually mature, with new protocols that support communication between different technologies be- coming broadly available. Until then, organizations can enjoy some integration benefits by working within a consortium model in which all participants deploy the same solutions and protocols. (When integration challenges are solved, those already sharing common processes and standards within a consortium may enjoy the competitive advantage of momentum.) There are also bridge technologies available that make it possible to move digital assets between blockchains. Think of the process like this: You move digital assets from point A to point B in a car. At point B, you transfer the assets from the car to a train, which takes it to its final destination at point C. Its inelegant, but it can deliver the desired business outcome. Blockchain to blockchains 99 Skeptics corner Few technologies today are as misunderstood as blockchain. That a simple Internet search produces a cornucopia of articles with titles such as WTF Is Blockchain? or A Blockchain Explanation Even Your Parents Can Understand suggests that for many, the world of shared ledgers, protocols, and consortiums remains opaque. With this in mind, join us as we correct a few common misconceptions about blockchain and its enterprise potential: Misconception: Standards must be in place before my organization can adopt a production solution. Reality: Currently, there are no overarching technical standards for blockchain, and it is unrealistic to think we will get them soon, if ever, across all use cases. There are, however, some technical and business standards for specific uses, such as cross-border transactions and smart contracts. These use case-based standards are established, if not commonly accepted, which means you may not have to wait for universal standards to emerge before adopting a blockchain production solution. Misconception: I read about how quantum computing may completely invalidate blockchain as we know it. If thats true, why should I bother with blockchain? Reality: That is a possibility, but it may never happen. Quantum computing provides enormous computing power that could be used to crack current encryption schemes. On the flip side, quantum computing may be able to help cryptologists generate stronger encryption algorithms. Either way, blockchain technologies will continue to evolve in ways that accommodate quantums eventual impactfor better or worseon encryption. Misconception: Blockchain is free, isnt it? Reality: Not quite. While most blockchain codes are open-source and run on low-cost hardware and public clouds, the full integration of blockchains into existing environments will require both resources and expertise, which dont come cheap. Whats more, supporting new blockchain-based business platforms will not be free. Blockchain technologies, like the systems and tools that users need to interact with them, require IT maintenance and support. Finally, because they are still new, for some time blockchain platforms will likely run in parallel with current platforms, which may add short-term costs. So, no, blockchain is not free. That said, understanding its true cost requires identifying the net value you may be able to harvest from blockchain cost savings and revenue generation. Tech Trends 2018: The symphonic enterprise 100 LESSO N S FRO M TH E FRO N T LIN ES Linking the chains In October 2016, global insurance and asset management firm Allianz teamed up with several other insurance and reinsurance organizations to explore opportunities for using blockchain to pro- vide client services more efficiently, streamline rec- onciliations, and increase the auditability of trans- actions.8 Blockchain is a new technology that is a bit mind-bending, says Michael Eitelwein, head of group enterprise architecture at Allianz. It only makes sense if it is a shared concept, which is the motivating factor for peers in our industry to try and understand this together. Over the course of the following year, the joint effortthe Blockchain Insurance Industry Initia- tive (B3i)welcomed 23 new members from across the insurance sector and began market-testing a new blockchain reinsurance prototype.9 Test par- ticipants were granted access to a sandbox envi- ronment in which they could simulate creating and settling contracts. We took a straightforward, iter- ative, R&D approach, Eitelwein says. Our goal was to gauge how useful this prototype is in transacting contracts, and to understand its strengths and limi- tations before taking it to the next level of develop- ment.10 In addition to participating in B3i, Allianz is working internally to determine if the same basic mechanism can be deployed across its global op- erations to facilitate interaction among multiple entitiesa possibility that, while promising, pres- ents several technical challenges. For example, can a blockchain platform be embedded in the architec- ture of systems that already communicate with each other? How would policy administration system de- signs for blockchain differ from traditional designs? And is it even possible to scale existing prototypes sufficiently to meet global enterprise needs? A broader opportunity looms large above Alli- anzs blockchain initiatives as well as those under- way in other industries: integrating and orchestrat- ing multiple blockchains across a single value chain. Currently, multiple parties can transact digitally only when everyone adopts a single shared ledger technology and one set of standards within a con- sortiuma limitation that diminishes blockchains potential value across B2B and peer-to-peer trans- actions. Our view is that blockchain makes sense only if you have common standards for interacting digital- ly, like those developed for the Internet, Eitelwein says. This would be especially powerful in retail; you cant have 50 different blockchains for 50 dif- ferent customersit would never pay off. Eitelwein says that multi-chain integration is certainly a goal Blockchain to blockchains 101 of blockchain exploration, but the concept remains unknown territory. For now, the B3i use case is laying the ground- work for future collaboration and even standardiza- tion across the insurance sector. If by working to- gether we can eventually create common standards for blockchain processes, we will be able to remove a lot of inefficiency from digital business, Eitel- wein says. This could provide tremendous benefits to our customers, and for the digital economy as a whole. This is what we are aiming for.11 Blockchain beyond borders: Hong Kong Monetary Authority The Hong Kong Monetary Authority (HKMA) is the central banking authority responsible for main- taining the monetary and banking stability and international financial center status of Hong Kong. Given its scope of responsibilities in developing and operating the territorys financial market infrastruc- ture, it comes as no surprise that its leadership took an interest in exploring blockchains or distributed ledger technologys (DLT) potential for a variety of financial applications and transactions. After re- searching the value proposition of the technology alongside the Hong Kong Applied Science and Tech- nology Research Institute, the HKMA published a white paper in November 201612 that raised more than 20 governance, legal, regulatory, and opera- tional concerns that the financial industry should address when implementing blockchain or DLT. Leaders then decided to develop a proof of concept (PoC) to test the value proposition as well as to ad- dress those concerns. The proof of concept focused on trade finance for banks, buyers and sellers, and logistics companies. It leveraged DLT to create a platform for automat- ing labor-intensive processes via smart contracts, reducing the risk of fraudulent trade and duplicate financing, and improving the transparency and pro- ductivity of the industry as a whole. DLT provided immutable data integrity, enhanced reliability with built-in disaster recovery mechanisms, enabled near-real-time updates of data across the nodes, and acted as a repository for transactional data. The trade finance PoC ran on a private block- chain network for a 12-week period from December 2016 through March 2017, with five Hong Kong banks participating. In addition to trade finance, HKMA developed two other successful PoCs for mortgage applications and digital identification. When banks saw the prototypes, they were ex- cited and keen to commercialize the PoC as quickly as possible, says Shu-pui Li, HKMA executive di- rector of financial infrastructure. At the beginning of the PoC project, we all thought distributed ledger technology had potential, but we had a lot of ques- tions about whether it would work in a commercial environment. The prototypes success opens up many possibilities. With seven banks now participating in the trade finance blockchain, HKMA intends to launch a pro- duction pilot in the second half of 2018. It plans to have a full commercialized solution in production by 2019. Also, there are a number of other banks waiting in the queue to participate in this platform. Building on the success of its proofs of con- cept, HKMA is exploring interconnectivity between blockchains with Singapores government and Mon- etary Authority of Singapore (MAS), which could be the foundation of an international blockchain eco- system. HKMA announced its joint venture with Singapore in October 2017 and a formal cooperative agreement was signed in November between the HKMA and MAS. Both authorities plan to imple- ment the cross-border infrastructure (i.e. Global Trade Connectivity Network) at around the same time that it launches its domestic platform. Then, if other countries want to participate in the network, they would plug their local platform into the inte- grated distributed ledger technology infrastructure. LE SS O N S FR O M T H E FR O N T LI N ES Tech Trends 2018: The symphonic enterprise 102 LESSO N S FRO M TH E FRO N T LIN ES Since HKMA doesnt know how many countries might connect to the infrastructure or what technol- ogy they might use, Li says the authority is explor- ing how to address interoperability. We dont have a perfect solution to interoperability, but we have identified some considerations and have some sug- gestions. We intend to work through those issues over the next year. But so far, so good. Its encourag- ing to see so many banks working together to reach a consensus. In addition, a common standard for digitization of the documentations and trades is a critical success factor for this infrastructure.13 Blockchain to blockchains 103 Peter Miller, president and CEO THE INSTITUTES Over the last 108 years, The Institutes has supported the evolving professional development needs of the risk management and insurance community with educational, research, networking, and career resource solutions. Now, as the industry faces increasingly fast-moving, innovative, and data-driven challenges, insurers have varying levels of knowledge about the benefits of blockchain. The next step is for The Institutes to help educate them about and prepare them for this technology. People are starting to understand blockchains broader applications and how it can link various parties; its a distributed ledger and therefore, by definition, requires cooperation by participants. Like any century-old organization, weve adapted to our industrys changing needs and problems, and we see blockchains potential applications. For our industry, blockchain has the capacity to streamline payments, premiums, and claims; reduce fraud through a centralized record of claims; and improve acquisition of new policyholders by validating the accuracy of customer data. Weve formed The Institutes RiskBlock Alliance, the first nonprofit, enterprise-level blockchain consortium. It will bring together risk management and insurance industry experts and blockchain developers to research, develop, and test blockchain applications for industry-specific use cases. It is by design a platform thats agnostic of specific underlying technologies, developed in concert with other groups involved in the insurance industryfrom life to property and casualty, including our membership, issuers, reinsurers, brokers, and others. Rather than focusing on single blockchain use cases, we believe in the need to communicate to multiple blockchains and enable federated inter-blockchain communication to facilitate reuse of capabilities among 30 organizations from various industry segments. To start, we are tackling four use cases that technology has struggled to tame: proof of insurance, first notice of loss, subrogation, and parametric insurance. These cases all include multiple parties working together, using shared data and predefined contracts. They are ideal use cases because we can solve a business problem while demonstrating the capabilities of blockchain technology, which in turn will educate the industry on its potential. And while were excited about these initial focus areas, there are literally hundreds of equally compelling examples waiting to be explored. A big challenge to interoperability is getting organizations to work together. We want to enable secure blockchain interconnectivity across the industry, and we are developing a framework that would support this. Since all organizations are under constraints to optimize cost structure, we are looking at an API layer to enable shared data and operations. We envision the consortium controlling the end products, with the integration into back-end legacy systems depending on each vendor. To facilitate adoption, organizations need to advance along the learning curve and focus on the business problems that blockchain could solve. Finding great partners is essential, as is understanding why confidence in the technology is justified: Blockchain is building on a package of proven technologies including distributed computing, cryptographic encryption, and hashingand concerns about its capabilities shouldnt hold back potential agreements for its use, whether in insurance or other industries. My take 104 RISK IM PLICATIO N S Risk practitioners across industries are excited about blockchains potential to help organizations manage risks posed by current systems. However, organizations should understand that while block- chain may drive efficiency in business processes and mitigate certain existing risks, it poses new risks broadly classified under three categories: common risks, value transfer risks, and smart contract risks.14 COMMON RISKS Blockchain technology exposes institutions to similar risks associated with current business pro- cessessuch as strategic, regulatory, and supplier risksbut introduces nuances for which entities need to account. Organizations that adopt block- chain should evaluate both the participating entities and the underlying platform; the choice of the latter could pose limitations on the services or products delivered, both now and in the future. From an in- frastructure perspective, blockchain technology is part of the enterprises core, so it should integrate seamlessly with back-end legacy systems. Addi- tionally, firms may be exposed to third-party risks, as some of the technology might be sourced from external vendors. For example, the typical risks of cloud implementation apply here for cases in which cloud-based infrastructure is part of the underlying technology for blockchain. VALUE TRANSFER RISKS Because blockchain enables peer-to-peer trans- fer of value, the interacting parties should protect themselves against risks previously managed by central intermediaries. In the case of a blockchain framework, evaluate the choice of the protocol used to achieve consensus among participant nodes in the context of the framework, the use case, and net- work participant requirements. While the consen- sus protocol immutably seals a blockchain ledger, and no corruption of past transactions is possible, it remains susceptible to private key theft and the takeover of assets associated with public addresses. For example, if there is fraud on the value-transfer network, and a malicious actor takes over a non- compliant entity, then that actor can transfer and siphon value off of the network. SMART CONTRACT RISKS Smart contracts can encode complex business, financial, and legal arrangements on the blockchain, so there is risk associated with the one-to-one map- ping of these arrangements from the physical to the digital framework. Additionally, cyber risks increase as smart contracts rely on oracles (data from out- side entities) to trigger contract execution. Smart contracts apply consistently to all participant nodes across the network; they should be capable of ex- ception handling that adheres to business and legal arrangements and complies with regulations. Like other software code, smart contracts require robust testing and adequate controls to mitigate potential risks to blockchain-based business processes. For example, smart contracts allow for straight-through processing (contractual clauses may be made par- tially or fully self-executing, self-enforcing, or both) as they directly interact with other smart contracts. One corrupted smart contract could cause a chain reaction that paralyzes the network. The successful adoption of any new technol- ogy is dependent on the appropriate management of the associated risks. This is especially true when that technology is part of the organizations core infrastructure, as is the case with blockchain. Ad- ditionally, its important to understand the evolu- tion of regulatory guidance and its implications. For example, the Financial Industry Regulatory Author- ity has shared operational and regulatory consider- ations for developing use cases within capital mar- kets.15 Organizations should work to address these regulatory requirements in their blockchain-based business models and establish a robust risk-man- agement strategy, governance, and controls frame- work. Blockchain to blockchains 105 G LO BA L IM PA CT Blockchain technology and its derivatives are continuing to mature, but a number of enabling conditions need to be addressed for its mainstream potential to be realized around the world. Deloitte leaders across 10 global regions see varying levels of certainty around the anticipated impact that the technology could have on financial services, manu- facturing, supply chain, government, and other ap- plications. While there are pockets of innovation in places such as Asia Pacific, Northern Europe, and Africa, many countries in Europe and Latin America are taking it slow, awaiting more standardization and regulation. The general expected time frame for adoption is two to five years, with some notable exceptions. Most regions have seen an uptick in proof-of-concept and pilot activity, mostly by financial institutions work- ing with blockchain start-ups. A few countries in Africa and Northern Europe are exploring national digital currencies and blockchain-based online pay- ment platforms. In Asia Pacific, several countries are setting up blockchains to facilitate cross-border payments. The Middle East, while bullish on blockchains potentialDubai has announced its intention to be the first blockchain-powered government by 2020, for example16finds itself in the very early phases of adoption; widespread adoption is expected to take up to five years in the region. In most regions, the main barrier to adoption is public skepticism as well as concerns about regula- tion. However, as consortiums, governments, and organizations continue to develop use cases for smart contracts, and the public becomes more edu- cated on potential benefits, viable blockchain appli- cations should continue to evolve around the world. Deloitte Insights | Deloitte.com/insights Figure 2. Global impact Relevance Significant High Medium Low None Timeliness Now 1 year 12 years 25 years 5+ years Readiness Significant High Medium Low None N. America N. Europe C. Europe Israel Asia S. America S. Europe S. Africa Middle East Australasia Global impact measures Source: Deloitte analysis. Tech Trends 2018: The symphonic enterprise 106 Blockchain to blockchains Where do you start? Though some pioneering organizations may be preparing to take their blockchain use cases and PoCs into production, no doubt many are less far down the adoption path. To begin exploring block- chains commercialization potential in your organi- zation, consider taking the following foundational steps:  Determine if your company actually needs what blockchain offers. There is a common misconception in the marketplace that blockchain can solve any number of organiza- tional challenges. In reality, it can be a powerful tool for only certain use cases. As you chart a path toward commercialization, its important to understand the extent to which blockchain can support your strategic goals and drive real value.  Put your money on a winning horse. Exam- ine the blockchain uses cases you currently have in development. Chances are there are one or two designed to satisfy your curiosity and sense of adventure. Deep-six those. On the path to block- chain commercialization, focusing on use cases that have disruptive potential or those aligned tightly with strategic objectives can help build support among stakeholders and partners and demonstrate real commercialization potential.  Identify your minimum viable ecosystem. Who are the market players and business part- ners you need to make your commercialization strategy work? Some will be essential to the prod- uct development life cycle; others will play criti- cal roles in the transition from experimentation to commercialization. Together, these individu- als comprise your minimum viable ecosystem.  Become a stickler for consortium rules. Blockchain ecosystems typically involve mul- tiple parties in an industry working together in a consortium to support and leverage a blockchain platform. To work effectively, consortia need all participants to have clearly defined roles and responsibilities. Without detailed operating and governance models that address liability, partici- pant responsibilities, and the process for joining and leaving the consortium, it can become more difficultif not impossibleto make subsequent group decisions about technology, strategy, and ongoing operations.  Start thinking about talentnow. To maxi- mize returns on blockchain investments, organi- zations will likely need qualified, experienced IT talent who can manage blockchain functionality, implement updates, and support participants. Yet as interest in blockchain grows, organizations looking to implement blockchain solutions may find it increasingly challenging to recruit quali- fied IT professionals. In this tight labor market, some CIOs are relying on technology partners and third-party vendors that have a working knowledge of their clients internal ecosystems to manage blockchain platforms. While external support may help meet immediate talent needs and contribute to long-term blockchain success, internal blockchain talentindividuals who ac- crue valuable system knowledge over time and remain with an organization after external talent has moved on to the next projectcan be criti- cal for maintaining continuity and sustainability. CIOs should consider training and developing internal talent while, at the same time, leverag- ing external talent on an as-needed basis. Bottom line With the initial hype surrounding blockchain beginning to wane, more companies are developing solid use cases and exploring opportunities for blockchain commercialization. Indeed, a few early adopters are even pushing PoCs into full production. Though a lack of standardization in technology and skills may present short-term challenges, expect broader adoption of blockchain to advance steadily in the coming years as companies push beyond these obstacles and work toward integrating and coordinating multiple blockchains within a single value chain. 107 ERIC PISCINI Eric Piscini is a principal with Deloitte Consulting LLP and the global leader of Deloittes financial services blockchain consulting efforts. He also co-leads the global blockchain and cryptocurrency team, and leads Deloittes US digital transformation and innovation service line for financial services. Piscini primarily focuses on digital transformations, fin-tech, blockchain, and innovation as well as developing software assets to accelerate the delivery of projects and enable organizations to quickly benefit from new technologies. DARSHINI DALAL Darshini Dalal is a technology strategist with Deloitte Consulting LLPs Technology, Strategy and Transformation practice, and leads Deloittes US blockchain lab. She has extensive experience in implementing complex, large-scale technology transformations and focuses on creating immersive experiences to help clients understand both the applications and implications of blockchain technology across a variety of business issues. Risk implications DAVID MAPGAONKAR David Mapgaonkar is a principal with Deloitte and Touche LLPs cyber risk services and leads the US technology, media, and telecommunications industry for the Cyber Risk Services practice as well as the Privilege Access Management offering. He has more than 18 years of experience and has led dozens of cyber risk engagements for Fortune 500 clients ranging from strategy to technology implementation to managed services. PRAKASH SANTHANA Prakash Santhana is a managing director with Deloitte Transactions and Business Analytics LLP and leads the payments integrity work for financial services, retailers, and service providers. He also co-leads the Deloitte blockchain and cryptocurrency community. Santhana has more than 20 years of experience in mitigating fraud across payment types and channels and is currently working on a framework for big data and machine learning to detect cyber-criminal activities targeting financial institutions. AUTHORS Tech Trends 2018: The symphonic enterprise 108 1. Eric Piscini, Joe Guastella, Alex Rozman, and Tom Nassin, Blockchain: Democratized trust, Deloitte University Press, February 24, 2016. 2. Eric Piscini, Gys Hyman, and Wendy Henry, Blockchain: Trust economy, Deloitte University Press, February 7, 2017. 3. Port Technology, Rotterdam Port celebrates new blockchain lab, September 25, 2017. 4. James Basden and Michael Cottrell, How utilities are using blockchain to modernize the grid, Harvard Business Review, March 23, 2017. 5. Brian D. Evans, Blockchain is now aiming to disrupt social networks in a major way, Inc., August 14, 2017. 6. John-David Lovelock and David Furlonger, Three things CIOs need to know about blockchain business value forecast, Gartner Inc., August 2, 2017. 7. JP Morgan Chase, Quorum: Advancing blockchain technology, accessed September 27, 2017. 8. Allianz SE, B3i expands with new members joining its prototype market testing phase, October 2, 2017. 9. Allianz SE, Insurers and reinsurers launch blockchain initiative B3i, October 19, 2016. 10. Allianz SE, B3i launches working reinsurance prototype, September 10, 2017. 11. Interview with Michael Eitelwein, head of Group Enterprise Architecture, Allianz SE, September 29, 2017. 12. Hong Kong Monetary Authority, White Paper on Distributed Ledger Technology, November 2016. 13. Interview with Shu-pui Li, HKMA executive director of financial infrastructure, October 16, 2017. 14. Prakash Santhana and Abhishek Biswas, Blockchain risk management, Deloitte, 2017. 15. Financial Industry Regulatory Authority, Distributed ledger technology: Implications of blockchain for the securi- ties industry, January 2017. 16. Nikhil Lohade, Dubai aims to be a city built on blockchain, Wall Street Journal, April 24, 2017. ENDNOTES Blockchain to blockchains 109 API imperative From IT concern to business mandate LOOKING back across successive industrial rev-olutions, interoperability and modularity have consistently delivered competitive advantage. Eli Whitneys interchangeable rifle parts gave way to Henry Fords assembly lines, which ushered in the era of mass production. Sabre transformed the air- line industry by standardizing booking and ticket- ing processeswhich in turn drove unprecedented collaboration. Payment networks simplified global banking, with SWIFT and FIX becoming the back- bone of financial exchanges, which in turn made dramatic growth in trade and commerce possible. The same concept manifests in the digital era as platformssolutions whose value lies not only in their ability to solve immediate business problems but in their effectiveness as launching pads for fu- ture growth. Look no further than the core offerings of global digital giants, including Alibaba, Alphabet, Apple Inc., Amazon, Facebook, Microsoft, Tencent, and Baidu. These companies have become domi- nant in part by offering platforms that their custom- ers can use to extend services to entire ecosystems of end users, third parties, and othersplatforms For many years, application programming interfaces (APIs) have made it possi- ble for solutions and systems to talk to each other. But increasingly, companies value these often-overlooked technologies for another capability: They expose technology assets for reuse across and beyond the enterprise. Not only can reuse drive greater ROI in IT investmentsit can offer API consumers a set of building blocks for using existing data, transactions, and products in creative ways. As part of the growing API imperative trend, organizations have begun exploring new ways to expose, manage, and control APIs. As this trend gath- ers momentum in the coming months, expect further innovative approaches to emerge for contracting, pricing, servicing, and even marketing a venerable technology that has become a critical pillar of many digital ambitions. API imperative 111 designed around the principles of interoperability and modularity. In the world of information technology, applica- tion programming interfaces (APIs) are one of the key building blocks supporting interoperability and design modularity. APIs, an architectural technique as old as computer science, can help improve the way systems and solutions exchange information, invoke business logic, and execute transactions. In previous editions of Tech Trends, we have tracked the growth of API deployment and the increas- ingly critical role that APIs are playing in systems architecture, innovation, modernization, and in the burgeoning API economy.1 This growth continues apace: As of early 2017, the number of public APIs available surpassed 18,000, representing an in- crease of roughly 2,000 new APIs over the previous year.2 Across large enterprises globally, private APIs likely number in the millions. What accounts for such growth? Increasingly, APIs are becoming a strategic mandate. If every company is a technology company, then the idea that technology assets should be built for reuse seems intuitive. Reuse compounds return on tech- nology investments in ways that couldnt be imag- ined when IT departments were developing many legacy solutions. That said, reuse requires new capabilities to manage the exchange of what is essentially an en- capsulation of intellectual property. These new ca- pabilities also make it possible to support the flow of information and operations across organizational boundaries, and to manage the discovery, usage, and servicing of API assets. Collectively, the strate- gic intent of APIs and this underlying enabling re- sponse represent the API imperative trend. A fresh look Given that APIs have been around for many years, moving forward suggests that we separate the tenets of the API imperative trend from previ- ous incarnations and potential biases. Large, com- plex projects have always featured interfaces that exchange information between systems. A vast majority of these interfaces were, and continue to be, completely bespoke, engineered to meet specific project needs. As point-to-point interfaces prolifer- ated, complex interdependencies between systems begat the spaghetti diagrams that represent too many IT landscapes today. In brittle, custom-built interfaces, customer, order, product, and sales in- formation is often duplicated; making changes has required tryingoften unsuccessfullyto unwind a tangled mess. Meanwhile, each successive project introduces new interfaces and more complexity. APIs were an attempt to control the chaos by encapsulating logical business concepts like core data entities (think customer or product) or trans- actions (for example, place an order or get price) as services. APIs could be consumed in broad and expanding ways. Whats more, good API design also introduced controls to help manage their own life cycle, including:  Versioning. The ability to change without ren- dering older versions of the same API inoperable.  Standardization. A uniform way for APIs to be expressed and consumed, from COM and CORBA object brokers to web services to todays RESTful patterns.  API information control. A built-in means for enriching and handling the information em- bodied by the API. This information includes metadata, approaches to handling batches of records, and hooks for middleware platforms, message brokers, and service buses. It also de- fines how APIs communicate, route, and manip- ulate the information being exchanged. Today, many organizations have yet to fully em- brace API opportunities. We know anecdotally that while developing shared APIs inside IT is growing in popularity, traditional project-based, siloed inte- gration approaches remain the rule, not the excep- tion. Much of ITs budget and effort go into paying back technical debt and maintaining legacy assets that were not designed to gracefully expose data Tech Trends 2018: The symphonic enterprise 112 Enterprise systems API layers Figure 1. API logical architecture Devices Consumers Programs Opportunities Supports microservices built on the foundation Allows faster market pivots by isolating changes to upper layer Enables more open, self-serve APIs Reduces time, cost, and effort by building on pre-existing API libraries User experience Enable ecosystem management and rapid innovation Replaces traditional BPM with process orchestration Augments orchestration with AI, bots, and RPA driven by data and APIs Uses composition to create domain-specific APIs from system-level building blocks Domain-level Simplify, automate, and package digital processes Enables data virtualization by mapping to modern formats Manages master data governance and access Creates batch, real-time, and pub-sub patterns Isolates higher-level apps from changes in the underlying system System-level Standardize data and decentralize data access Deloitte Insights | Deloitte.com/insightsSource: Deloitte analysis. Mobile Customers EmployeesIoT devices Kiosks Developers Partners SaaS apps Mainframes Cloud apps FTP Databases Web services Applications Files and business logic. Remediating that existing legacy to be API-friendly is akin to open-heart surgery. At the same time, rebuilding a foundation with greenfield solutions can be challenging, adding new expectations of cost, time, and complexity to proj- ect plans. It also requires a different set of skills to architect and realize the vision. For many compa- nies, the prospect of disrupting established controls, budgeting models, processes, and talent models seems dauntingespecially if the so what is left as a tactical IT architecture decision. And this apprehension is hardly unfounded: The need for agility, scalability, and speed grows more pressing each month as innovation presents new opportunities, remakes markets, and fuels competi- tion. Over the next 18 to 24 months, expect many heretofore cautious companies to embrace the API imperativethe strategic deployment of application API imperative 113 programming interfaces to facilitate self-service publishing and consumption of services within and beyond the enterprise. The why to the what In embracing the API imperative, companies are making a strategic choice. They are committing to evolve their expectations of technology investments to include the creation of reusable assetsand com- mitting to build a lasting culture of reuse to inform future project planning. Preparing, both strategical- ly and culturally, to create and consume APIs is key to achieving business agility, unlocking new value in existing assets, and accelerating the process of delivering new ideas to the market. APIs can deliver a variety of operational and strategic benefits. For example, revitalizing a legacy system with modern APIs encapsulates intellectual property and data contained within that system, making this information reusable by new or young- er developers who might not know how to use it di- rectly (and probably would not want to). Likewise, building APIs onto monument systems makes it possible to extract more value from IT assets, while at the same time using valuable existing data to drive new innovations. Finally, incorporating APIs into new applications allows for easier consumption and reuse across new web, mobile, and IoT experi- ences, not to mention the option for exposing those APIs externally to enable new business models and partner ecosystems. APIs potential varies by industry and the de- ploying companys underlying strategy. In a recent in-depth study of API use in the financial services sector, Deloitte, in collaboration with the Associa- tion of Banks and the Monetary Authority in Sin- gapore, identified 5,636 system and business pro- cesses common to financial services firms, mapping them to a manageable collection of 411 APIs.3 Once created, these building blocks could allow for vastly accelerated development of new solutions and of- feringsfrom blockchain-driven trade finance to a virtual-reality retail branch experience. Support from the top As companies evolve their thinking away from project- to API-focused development, they will like- ly need to design management programs to address new ways of:  Aligning budgeting and sponsorship. Em- bed expectations for project and program priori- tization to address API concerns, while building out shared API-management capabilities.  Scoping to identify common reusable ser- vices. Understand which APIs are important and at what level of granularity they should be defined; determine appropriate functionality trade-offs of programmatic ambitions versus immediate project needs.  Balancing comprehensive enterprise planning with market need. In the spirit of rapid progress, avoid the urge to exhaustively map potential APIs or existing interface and service landscapes. Directionally identifying high-value data and business processes, and then mapping that list broadly to businesss top initiative priorities, can help prevent planning paralysis and keep your API projects moving.  Incenting reuse before building new. Measure and reward business and technol- ogy resources for taking advantage of existing APIs with internal and external assets. To this end, consider creating internal/external devel- oper forums to encourage broader discovery and collaboration.  Staffing new development initiatives to enable the API vision. While IT should lead the effort to create effective API management programs, it shouldnt be that functions sole re- sponsibility. Nor should IT be expected to build and deliver every API integration. Consider, in- stead, transforming an existing shared-services center of excellence (COE) that involves the Tech Trends 2018: The symphonic enterprise 114 lines of business. Shifting from a COE mentality that emphasizes centralized control of all shared services to a federated center for enablement (C4E) approachtying in stakeholders and de- velopment resources enterprise-widecan help organizations improve API program scalability and management effectiveness. Enterprise API management Deploying and scaling APIs requires capabilities that are different from those typically used in estab- lished integration and messaging layers. Whether APIs are being consumed internally to orchestrate a new business process or externally as parts of new products, managing APIs deliberately throughout their life cycle can help make them more discover- able, serviceable, and more easily monitored. As your ambitions evolve, explore how one or more of the following technology layers can help you manage APIs more strategically throughout their life cycle:  API portal: a means for developers to discover, collaborate, consume, and publish APIs. To sup- port the overall goal of self-service, these por- tals describe APIs in a way that represents their functionality, context (the business semantics of what they do, and how they do it), nonfunctional requirements (scalability, security, response times, volume limits, and resiliency dimen- sions of the service), versioning, and metrics tracking usage, feedback, and performance. For organizations without mature master data or architectural standards, the API portal can still offer visibility into existing APIs and provide contact information for individuals who can de- scribe features, functions, and technical details of services.  API gateway: a mechanism that allows con- sumers to become authenticated and to con- tract with API specifications and policies that are built into the API itself. Gateways make it possible to decouple the API proxythe node by which consumers logically interact with the servicefrom the underlying application for which the actual service is being implemented. The gateway layer may offer the means to load balance and throttle API usage.  API brokers: enrichment, transformation, and validation services to manipulate information coming to/from APIs, as well as tools to embody business rule engines, workflow, and business process orchestration on top of underlying APIs.  API management and monitoring: a cen- tralized and managed control level that provides monitoring, service level management, SDLC process integration, and role-based access man- agement across all three layers above. It includes the ability to instrument and measure API usage, and even capabilities to price and bill charge- back based on API consumptionto internal, or potentially external, parties. Tomorrow and beyond The API imperative trend is a strategic pillar of the reengineering technology trend discussed ear- lier in Tech Trends 2018. As with reengineering technology, the API imperative embodies a broader commitment not only to developing modern ar- chitecture but to enhancing technologys potential ROI. It offers a way to make broad digital ambitions actionable, introducing management systems and technical architecture to embody a commitment toward business agility, reuse of technology assets, and potentially new avenues for exposing and mon- etizing intellectual property. API imperative 115 Skeptics corner Even with digital platform use cases proliferating and excitement about reusability gaining traction, who can really blame veteran CIOs for harboring a few reservations about the API imperative trend? After all, in a media climate in which every new innovation is described as earth-shattering, it is sometimes difficult to separate fact from fiction. Lets set the record straight on a few common misconceptions about APIs and their potential: Misconception: APIs have been around for a long time. Theres nothing new here. Reality: Yes, IT organizations have deployed APIs in different ways for years. Even though a lack of standards and immature underlying technology limited their potential, the vision behind them was, and remains today, remarkably grounded. In the last generation of APIs, many mistakenly thought that service-oriented architecture initiatives powered via SOAP-based web services would deliver on APIs promise. The issue? The underlying protocols and supporting stacks were complex and offered limited reach. Repositories such as UDDP never reached maturity, and the lack of cloud platforms and services constrained broader scale. Today, however, developers are following Silicon Valleys lead by reimagining core systems as microservices, building APIs using modern RESTful architectures, and taking advantage of robust, off-the-shelf API management platforms. Increasingly, organizations are deploying a microservices approach for breaking down systems and rebuilding them as self-contained embodiments of business rules. Traditional approaches to wrap specific chunks of functionality within a more complex code base succeeded in exposing a transaction or data element as an interface or API. However, they didnt allow individual APIs to scale or evolve independent of the whole. Microservices look to break larger applications into small, modular, independently deployable services. This approach turns the rhetoric of SOA into a modernized application architecture and can magnify APIs impacts. REST stands for representational state transfer. APIs built according to REST architectural standards are stateless and offer a simpler alternative to some SOAP standards. For example, REST enables plain-text exchanges of data assets instead of using complex WSDL protocols. It also makes it possible to inherit security policies from an underlying transport mechanism. At a high level, these and other simplified approaches can deliver better performance and faster paths to develop, deploy, and triage. Finally, API management platforms have evolved to complement the core messaging, middleware, and service bus offerings from yesteryear. Vendors include new entrants and established players, including IBM, SAP, Oracle, Tibco, MuleSoft, Dell, Software AG, CA, Dell, and Apigee. Misconception: Project-based execution is cheaper and faster. I dont have time to design products. Reality: With urgent projects, or those dependent upon tactical integrations, you may not be able to invest much design time up front. But understand that you will have to duplicate your efforts, A to Z, when you begin the next project. By spending some time on understanding cross-project requirements and designing for reuse, your costsin both time and budgetbecome leveraged, and the value you create compounds over time. The goal is not to construct centralized, enterprise- wide controls and governorsrather, it is to create assets that can empower teams to drive accelerated time-to-value. Sure, there will be some stand-up cost. And the initial projects Tech Trends 2018: The symphonic enterprise 116 will involve scoping, designing, and building different types of assets. Consider subsidizing those investments so that business owners and project sponsors dont feel as though they are being taxed. Also, look for ways to reward teams for creating and consuming APIs. Misconception: I dont have the executive sponsorship I need to take on an API transformation. If I dont sell it up high and secure a budget, its not going to work. Reality: You dont have to take on a full-blown API transformation project immediately. Begin building a business case by completing a few small, low-cost projects that demonstrate the ROI around reuse of a common set of APIs. CIOs may be able to develop a proof point with as few as three APIs delivered across two or more projects (three is a manageable number to prove reuse ROI). Subsequent success with a few tightly scoped projects can then help lay the groundwork for business support and, eventually, executive sponsorship. API imperative 117 LE SS O N S FR O M T H E FR O N T LI N ES AT&Ts lean, mean API machine In the last decade, AT&T embarked upon a se- ries of mergers, uniting several large companies. They resulted in an IT organization having to man- age more than 6,000 applications, as well as distinct operating and software development life cycle pro- cesses, each of which worked well in its own right. With the ultimate goal of bringing all of these ap- plications and processes under the AT&T umbrella, the organization pursued a transformation effort to integrate the systems, remove duplicate costs, streamline global products and network care, and increase speedall while delivering an effortless customer experience. To enable this transforma- tion, the company defined a variety of big technol- ogy plays, with API platforms as the core, integral component. The first step was application rationalization, which leaders positioned as an enterprise-wide business initiative. In the last decade, the IT team reduced the number of applications from 6,000- plus to 2,500, with a goal of 1,500 by the year 2020. When the team started the rationalization process in 2007, they quickly recognized the need for a modern, platform-based architecture designed for reuse rather than purpose-built applications with point-to-point interfaces. The team spent the next couple of years putting a platform architecture in place, and then introduced an API layer in 2009 with a common data model across the wired and wireless business. We saw an opportunity to reduce the total cost of ownership by billions of dollars, as well as achieve huge savings for care centers as they were consoli- dated, says Sorabh Saxena, president of business operations (formerly, CIO of network and shared services) for AT&T. APIs also enable more agility and speed to market for product teams. The goal was to motivate both the corporate and technology teams to build a software-driven, platform-based company.4 AT&T made the API platform the focus of its so- lutions architecture team, which fields more than 3,000 business project requests each year and lays out a blueprint of how to architect each solution within the platform. Saxenas team implemented a federated development program so each busi- ness units unique needs would be taken into con- sideration on the API platform. As a $160 billion- plus company, some voiced concerns that business knowledge couldnt be centralized on one team. AT&T now has close to 200 federated development teams, aligned to the applications themselves. Fed- erated teams develop on the platform, combining the commonality of the platform with the teams Tech Trends 2018: The symphonic enterprise 118 LESSO N S FRO M TH E FRO N T LIN ES API imperative business knowledge. However, the platform teams are responsible for the environment, development standards, design and test assurance, deployment, and production support. In the beginning, they seeded the API platform by building APIs to serve specific business needs. Over time, the team shifted from building new APIs to reusing them. In 2017, they had approximately 4,000 instances of reuse, which Saxena values at hundreds of millions in savings over the years. Likewise, by September 2017, AT&T had 24 billion transactions per month on its API platformsfor internal, developer, and business-to-business ap- plicationscompared to 10 billion transactions per month in 2013. The number of APIs has grown more than threefold in that timeframe, and cycle time and quality have improved significantly. Though the API platform hasnt removed all instances of point-to- point application interfaces, the bias is to use APIs. But in the beginning, the IT team needed to en- courage buy-in across the organization for the API strategy. Saxena says teams were reluctant at first, expecting latency to result from a shared services model, so his team cultivated relationships with lo- cal champions in each area of the organization and tied their performance to the program. They also zoned in on potential detractors and proactively provided white-glove service before any issues bub- bled up, thereby increasing overall support. Additionally, the team instituted an exception process that was made painful on purpose. Saxe- na hosted a twice-weekly call in which departments presented a request to build an application outside the API platform, and he would personally approve or deny the exception. In the beginning, there was a 20 percent exception rate that eventually stabi- lized to 4 to 5 percent, as teams saw that the upfront investment would quickly pay back, with big divi- dends. They redirected business funding to build the APIs, which became the architecture standard. By sharing reuse benefits with the business, the API platform has succeeded in speeding up deployment while lowering costs. The next step in AT&Ts transformation is a mi- croservices journey. The team is taking monolithic applications with the highest spend, pain points, and total cost of ownership, and turning them and all the layersUI/UX, business logic, workflow, and data, for exampleinto microservices. At AT&T the microservices transformation has tangible busi- ness goals. Since change is the one constant, the goals are to increase the speed, reduce the cost, and reduce the risk of change to the enterprise suite of APIs. The right sizing of microservices versus previous monoliths helps componentize the distrib- uted business functions, which facilitates change. To ease the microservices transition, the team is de- ploying a hybrid architecture, putting in place an in- telligent routing function to direct services to either the monolith or microservices, and implementing data sharing. The API and microservices platform will deliver a true DevOps experience (forming an automated continuous integration/continuous delivery pipe- line) supporting velocity and scalability to enable speed, reduce cost, and improve quality. The plat- form will support several of AT&Ts strategic initia- tives: artificial intelligence, machine learning, cloud development, and automation, among others. We positioned the API journey as a business initiative, rather than a technology effort, Saxena says. We worked with product partners to educate them on how technology changes would streamline nationwide product launches, with single processes, training programs, and greater flexibility in arrang- ing the workforce. We built the necessary upswell and secured the support across teams. Now, when- ever we want to do something new with technology, we think business first. 119 The Coca-Cola Co.: APIs are the real thing Whats the secret to being an industry leader for 131 years? For the Coca-Cola Co., its adapting to the needs and desires of its customers, which entails everything from crowdsourcing new sweeteners to delivering summer shipments via drones. More importantly, it means embracing digital, a goal set by the organizations new CEO, James Quincy. The enterprise architecture team found itself well posi- tioned for the resulting IT modernization push, hav- ing already laid the foundation with an aggressive API strategy. All APIs are not created equal, says Michelle Routh, Coca-Cola chief enterprise architect. Its one thing to have an API, and another thing to have an API that operates well. Coca-Colas API journey began several years ago, when Routh was CIO for North America and she and her team put in place a modern market- ing technology platform. They moved all of their applications onto the public cloud and based their marketing technology platforms on software-as-a- service solutions. Rouths team then built an API conceptual layer across the marketing and technol- ogy stack, facilitating a move from a monolithic to a modern platform. Next, they decomposed and de- coupled the platform into a set of easily consumable microservices and made them available to the thou- sands of marketing agencies with which they work. The team leveraged Splunk software to monitor the APIs performance; this enabled them to shift from being reactive to proactive, as they could mon- itor performance levels and intervene before degra- dation or outages occurred. A friendly competition ensued between the teams and departments provid- ing APIs to build the best performer, resulting in even greater efficiencies over time. The marketing agencies could access the services quickly and eas- ily, and Coca-Cola scaled its investment with agil- ity and speed-to-market, resulting in best-in-class digital marketing. Now the enterprise architecture team is leverag- ing that experience as it works alongside the chief digital officer to transform Coca-Colas business and modernize its core to meet the demands of a digital enterprise. The organization is undergoing a sys- temwide assessment to gauge its readiness in five areas: data, digital talent, automation innovation, cloud, and cyber. The enterprise architecture team is developing reference architectures to align with each of those five capabilitiesmapping all the way to an outcome that builds a solution for a particular business problem. Routh realized that to become more digital, the company needs to do things at scale to drive growth: For us to provide a technol- ogy stack for a truly digital company, we need a set of easily consumable APIs to help the business go to market quickly. The modernization program first targeted leg- acy systems for Foodservice, one of Coca-Colas oldest businesses. The challenge was to convince long-established customerssome with contracts dating back a centurythat moving away from pa- per-based data delivery would make it easier to do business with the company. The ability to develop and publish standard APIs facilitated the process and elevated the organizations engagement with those customers. We want to be able to offer a series of services that people can call on, by domain, to start building their own experiences right away, says Bill May- nard, Coca-Cola global senior director of innovation and enterprise architecture. We dont debate the need for APIs. We just do it. Indeed, APIs have already become an integral part of the fabric of the new, digital Coca-Cola. When we look at the business case, we dont de- compose it into parts, Routh says. Migrating to the public cloud, embracing Agile methodology and DevOps, and building an API layer were all compo- nents of the overall initiative to move to a modern best-in-class technology stack. The collective of all three is enabling our growth and allowing us to achieve a digital Coca-Cola.5 LE SS O N S FR O M T H E FR O N T LI N ES Tech Trends 2018: The symphonic enterprise 120 API imperative State of Michigan optimizes resources through reuse The State of Michigans Department of Technol- ogy, Management and Budget (DTMB) provides administrative and technology services and infor- mation for departments and agencies in the state governments executive branch. When the Michi- gan Department of Health and Human Services (MDHHS) needed to exchange Medicaid-related information across agencies in support of legisla- tive changes mandated by the Affordable Care Act, DTMB implemented an enterprise service bus and established a reusable integration foundation. Later, the health and human services depart- ment embarked on a mission to reform how the agency engages with citizens, seeking to tailor ser- vice delivery to specific citizen needs via an Inte- grated Service Delivery program. In expanding ser- vices to help more families achieve self-sufficiency, the departmentoffering new cloud-based, citizen- facing programsneeded to scale technology to support the increased activity. DTMB decided to evolve its architecture to expand the enterprise ser- vice bus and add an API layer. An API layer would allow for reuse and scalability, as well as provide operational stability through service management, helping to prevent outages and performance degra- dation across the system by monitoring and limiting service consumers. Paired with our ongoing cloud initiatives, APIs were a sensible approach for a more effective ar- chitecture and reuse across all state agencies, says DTMB general manager Linda Pung. They can share APIs with each other to help drive down cost, as well as facilitate a quicker time to market.6 DTMB has taken a multi-phased approach in le- veraging APIs with existing IT assets such as back- end systems, data, enterprise shared services, and infrastructure. Data is the key driver to the entire strategy. We need to support sharing data in a standard- ized and simplified manner between cloud services and on-premises data sources, not only in the de- partment but across multiple agencies to enable better customer service and data security, says Judy Odett, DTMBs business relationship manager. Additionally, the solution must be scalable so it can continue to expand with additional datasets over time. The first step was to expand the enterprise ser- vice bus to enable the cloud-based portal to leverage existing state assets. This was followed by the de- ployment of an API management platform, building upon existing architecture and enabling reuse. The team chose a platform that allowed rate limiting and load balancing, as well as the ability to ingrain the states security policies. DTMB recently released its first pilot phase with bounded functionality, and the department plans to roll out the platform enter- prise-wide, with full functionality, in the near future. A service management solution will provide a portal for DTMB architects to review and analyze consoli- dated web services, a responsibility that each indi- vidual system owner currently handles. This will reduce the number of duplicate web services and facilitate reuse. Development time has decreased by leveraging existing enterprise shared services such as a mas- ter person index and address cleansing. It also has achieved centralized security by allowing citizens to verify their identities through third-party iden- tity management services and enabling secure data exchange through centralized gateway services. Fi- nally, MDHHS is anticipating a reduction in the number of customer inquiries by enabling citizens to access data through mobile applications support- ed by the APIs. Reaction to the pilot has been positive, and the faster time to market, improved operational stabil- ity, and data quality are already yielding benefits to the consumers. LESSO N S FRO M TH E FRO N T LIN ES 121 LE SS O N S FR O M T H E FR O N T LI N ES CIBC: Building the bank of the future In the new digital economy, consumer expecta- tions are rapidly evolving. They want frictionless transactions and rich digital experiences. Like many financial institutions, the Canadian Imperial Bank of Commerce (CIBC), a 150-year-old institution, is building new capabilities to help it meet customers increasingly sophisticated needs. This means inte- grating new functionality into its existing infrastruc- ture. However, technology integrationwhether it be extending an existing capability or introducing a new oneis often time-consuming and expensive. While CIBC has been on a service-oriented architec- ture journey for over a decade, it wants to further modernize its architecture to reduce the cost and effort of integration, while continuing to meet cus- tomer demands for an end-to-end experience. Building a platform for integration is not new to CIBC, which has thousands of highly reusable web services running across its platform. But the team recognized that the current SOA-based model is be- ing replaced by a next-gen architectureone based on REST-ful APIs combined with a micro-services architecture. CIBC evaluated different approaches for mod- ernizing its integration architecture, and decided to focus on cloud-native, open-source frameworks. The bank moved to a self-service publishing mod- el, where API consumers can access microservices without a traditional API gateway intermediary. This simplified, democratized model has alleviated the bottlenecks common to more traditional ap- proaches. From a technology standpoint, the combina- tion of APIs, the cloud, and open source frame- works such as Light4J are creating tremendous benefit, says Brad Fedosoff, CIBC vice president and head of enterprise architecture. We currently have APIs implemented across some of our produc- tion systems, and implementation has been faster and cheaper, with greater flexibility, than initially thought. For example, internally CIBC identified a new technology for its data services. Working with the API platform team, CIBC had a working version a week later. Traditionally, this request would have taken months to come to fruition. From a business perspective, CIBC has been able to innovate and of- fer new capabilities in rapid fashion. One example is its Global Money Transfer service that allows clients in Canada to send money to more than 50 countries for no fee. The IT team quickly integrated internal and external capabilities from third parties to sim- plify the money transfer and to provide a smooth experience for its customers. As it continues to evolve its customer experience, CIBC is turning its attention to payments and iden- tity as the next areas of opportunity to expand its API footprint. We envision an API/microservices-based ap- proach as the heart of the Global Open Banking movement, Fedosoff says. Financial services firms will look to open up capabilities, and as a result, will need to develop innovative features and effortless journeys for clients. APIs may be a smart way to do it.7 Tech Trends 2018: The symphonic enterprise 122 Werner Vogels, vice president and chief technology officer AMAZON.COM When Jeff Bezos started building Amazon, there was nothing else like it from a technology perspective. We were doing iterative development on a monolithic codebase that included everything from content to customer service apps to the logistics of shipping packages. Amazons mantra has always been delight customers, and that has been the driving force behind our evolutionary journey. With each stage of growth, we refine our approach. Around 2000, our engineers were building stateless applications maintained in back-end databases. These databases were shared resources, so employees could easily access the data they needed and not worry about where the data lived. As Amazon rapidly scaledadding product categories and expanding internationallythese shared resources became shared obstacles, compromising speed. So the engineers started thinking about a different kind of architecture, one in which each piece of code would own its own database and encapsulated business logic. We called them services, well before the popularity of service-oriented architecture. Dependencies were embodied in APIs, giving teams the freedom to make rapid changes to the underlying data model and logic as the business demanded. This allowed an evolutionary approach to engineering and let us carve out the monolith, piece by piece. Performance metrics began ramping up again. Then, around 2004, we realized that a few of the services had become as big as the monolith had been. Services were organized by dataorder, customer, productswhich had exploded as the business grew. For example, a single service maintained all of the code that operated on Amazons global customer base, even as that base expanded exponentially. Different capabilities needed different levels of service, but because they were grouped together, everything had to resort to the highest common needfor scalability, security, reliability, and more. We realized we needed to shift to a functional decomposition, creating what we now call microservices. We ended up with around 600 to 800 services. After enjoying several years of increased velocity, we observed productivity declining again. Engineers were spending more and more time on infrastructure: managing databases, data centers, network resources, and load balancing. We concluded that a number of capabilities were much better suited to be shared services, in which all of our engineers could reuse technology without having to carry the burden of solving for the underlying platform. This led to the build-out of the technical components that would become Amazon Web Services (AWS). Amazon is a unique company. It looks like a retailer on the outside, but we truly are a technology company. Senior management is not only supportive of technology initiativesthey are technologists themselves who take part in the architectural review. Technology is not a service group to the business the two are intertwined. We hire the best engineers and dont stand in their way: If they decide a solution is best, they are free to move forward with it. To move fast, we removed decision-making from a top-down perspectiveengineers are responsible for their teams, their roadmaps, and their own architecture and engineering; that includes oversight for reuse of APIs. Teams are encouraged to do some lightweight discovery to see whether anybody else has solved parts of the problems in front of them, but we allow some duplication to happen in exchange for the ability to move fast. My take 123123 Our experience with services and APIs has been crucial to building AWS, which turns everything whether its a data center, outbound service, network, or databaseinto a software component. If we hadnt experienced the process ourselves, we would have been unable to understand either the value it would have for our customers or the needs our customers would have to build, run, and evolve in such an environment. We realized this technology could help Internet-scale companies be successful, and it completely transformed the technology industry. Now, many of our AWS customers are transforming their worlds as well. Speed of execution and speed of innovation are crucial to Amazons business. The shift to APIs enabled agility, while giving us much better control over scaling, performance, and reliabilityas well as the cost profilefor each component. What we learned became, and remains, essential to scaling the business as we continue to innovate and grow. 124 API imperative RISK IM PLICATIO N S Historically, organizations secured their siloed and controlled environments by locking down de- vices, systems, and platforms in order to protect data that lived inside their own four walls. In todays computing environment, with the proliferation of loosely coupled systems, multi-vendor platforms, integrations across traditional enterprise boundar- ies, and open APIs, this strategy is likely no longer adequate. Todays API imperative is part of a broader move by the enterprise to open architecturesexposing data, services, and transactions in order to build new products and offerings and also to enable more efficient, newer business models. But this expansion of channels inherently increases the permeability of an organizations network, which can create new seams and a broader attack surface that can be ex- ploited as a result of new vulnerabilities. Cyber risk should be at the heart of an organi- zations technology integration and API strategy. Organizations should consider how to secure data traveling across and beyond enterprise boundar- iesmanaging API-specific identities, access, data encryption, confidentiality, and security logging and monitoring controls as data travels from one API to another. An API built with security in mind from the start can be a more solid cornerstone of every application it enables; done poorly, it can multiply application risks. In other words, build it in, dont bolt it on:  Verify that your API developers, both internal and third-party, employ strong identity authen- tication, authorization, and security-event log- ging and monitoring practices.  Build in second-level factors of authentication and in-memory, in-transit, and at-rest data en- cryption methods when high-risk data sets or environments are involved.  Evaluate and rigorously test the security of third-party APIs you leverage.  Clearly understand the exposure and technical security requirements of public versus private APIs, and apply enhanced security due diligence and monitoring considerations on your public API set.  Allocate enough time to conduct API unit and integration security testing exercises to detect and fix potential security vulnerabilities. Lack of credential validation, data type checking, data validation, improper error handling, insufficient memory overflow handling, and privilege escala- tion are just a few examples of issues on which hackers can capitalize. While APIs can introduce new risks to an eco- system, they can also help organizations facilitate standardized, dynamic protection against evolving threats. An open and API-forward architecture can be well suited to address and help standardize on the implementation of core security, monitoring, and resiliency requirements in computing environ- ments. Cyber risk capabilities made available to ap- plications, developers, partners, and third parties alike through a standardized API set can help ad- dress security policy mandates, minimum security and privacy guidelines, and compliance obligations. When common cyber risk APIs are implemented ef- fectively, organizations can update, upgrade or re- engineer services such as identity and access man- agement, data encryption, certificate management, and security logging and monitoring, and have this enhanced functionality be automatically pushed out across their enterprise, extraprise, or customer base. APIs can also improve an organizations resil- iency posture and enable rapid updates when new threats are identifiedwithin a matter of hours, not daysthereby helping to reduce costs, operational overhead, and overall time to detect and respond. Many security technology vendors are also moving to open API-based models, which could mean an increasingly integrated security ecosystem in which multi-vendor platforms integrate with one another to present a united front rather than layers of dis- jointed security solutions that could present expo- sures which hackers can exploit. As APIs become more common in organizations, the flexibility and scalability they provide can help improve an enterprises approach to being more se- cure, vigilant, and resilient against cyber-attacks. 125 G LO BA L IM PA CT Findings from a recent survey of Deloitte lead- ers across 10 regions suggest that several factors are driving the API imperative trend globally. First, with more organizations modernizing IT and re- engineering technology delivery models, APIs are becoming centerpieces of digital transformation agendas and complex business models. Likewise, as major software vendors upgrade their solutions to support APIs and microservices, they are providing building blocks for API adoption. Finally, start-ups embracing API-driven architectures and capability models are providing proof pointsand some com- petitive pressurein regional ecosystems. Survey respondents see API adoption progress- ing in several countries, with particular momentum in two industry sectors: financial services in the UK, US, Brazil, Canada, and across Asia Pacific; and me- dia and telecommunications in Germany, Ireland, Italy, and Latin America. Across global markets, public-sector API adoption lags somewhat, perhaps due to ongoing open government guidelines that mandate longer time frames for organizing and executing larger-scale API transformation initia- tives. And even though APIs are relatively new to the Middle East, a large number of businesses have already demonstrated how APIs can help organiza- tions become leaner. Survey respondents see API adoption accelerating throughout the region, espe- cially in Israel. Globally, companies are recognizing that API ambitions go hand-in-hand with broader core mod- ernization and data management efforts. Survey respondents in Denmark specifically called out an issue that appears to be universal: New systems are being built with APIs incorporated within, while legacy systems continue to impede information sharing. On the regulation front, a recent EU ruling makes providing transparency into all IT services that will be used in technology projects a condition for receiving government funding. The net result? Funding and procurement become forcing func- tions for the API imperative. Deloitte Insights | Deloitte.com/insights Figure 2. Global impact Relevance Significant High Medium Low None Timeliness Now 1 year 12 years 25 years 5+ years Readiness Significant High Medium Low None N. America N. Europe C. Europe Israel Asia S. America S. Europe S. Africa Middle East Australasia Global impact measures Source: Deloitte analysis. Tech Trends 2018: The symphonic enterprise 126 API imperative Where do you start? Viewed from the starting block, an API trans- formation effort may seem daunting, especially for CIOs whose IT environments include legacy sys- tems and extensive technical debt. While the follow- ing steps do not constitute a detailed strategy, they can help lay the groundwork for the journey ahead:  Embrace an open API arbitrage model. Dont waste your time (and everyone elses) try- ing to plot every aspect of your API imperative journey. Instead, let demand drive project scope, and let project teams and developers determine the value of APIs being created based on what they are actively consuming. That doesnt mean accepting a full-blown laissez-faire approach, especially as the culture of the API imperative takes root. Teams should have to justify deci- sions not to reuse. Moreover, you might have to make an example of teams that ignore reuse guidelines. That said, make every effort to keep the spirit of autonomy alive within teams, and let the best APIs win.  Base API information architecture design on enterprise domains. The basic API infor- mation architecture you develop will provide a blueprint for executing an API strategy, design- ing and deploying APIs to deliver the greatest value, and developing governance and enforce- ment protocols. But where to begin? To avoid the common trap of over-engineering API ar- chitecture, consider basing your design on exist- ing enterprise domainsfor example, sales and marketing, finance, or HRand then mapping APIs to the services that each domain can po- tentially expose. Approaching architecture de- sign this way can help avoid redundancies, and provide greater visibility into APIs effective- ness in driving value and supporting domain- specific strategies.  Build it and they wont come. Driving API consumption is arguably more important than creating APIs, a point often lost on organiza- tions as they embrace the API imperative trend. To build an organizational culture that empha- sizes API consumption, start by explaining the strategic importance of consumption to line-of- business leaders and their reports, and asking for their support. Likewise, create mechanisms for gauging API consumption and for reward- ing teams that embrace reuse principles. Finally, share success stories that describe how teams were able to orchestrate outcomes from existing services, or rapidly create new services by build- ing from existing APIs.  Determine where microservices can drive value. If you are beginning your API transformation journey, you probably have mul- tiple services that could be managed or delivered more effectively if they were broken down into microservices. Likewise, if you already have API architecture in place, you may be able to gain efficiencies and scalability by atomizing certain platforms into microservices. To determine whether this approach is right for your com- pany, ask yourself a few questions: Do you have a large, complex code base that is currently not reusable? Are large teams required to develop or support an application? Are regular production releases required to maintain or enhance appli- cation functionality? If you answered yes to any or all of the above, it may be time to begin tran- sitioning to microservices.  Define key performance indicators (KPIs) for all exposed services. Deploying an API makes a service reusable. But is that service be- ing reused enough to justify the maintenance required to continue exposing it? By developing KPIs for each service, you can determine how ef- fectively API platforms are supporting the goals 127 set forth in your API strategy. If the answer is not very effective, then KPIs may also be able to help you identify changes to make that can im- prove API impact.  Dont forget external partners. APIs should be built for consumers, partners, and internal lines of business. For external partners, includ- ing the developer community, it is important to develop and provide necessary support in terms of documentation, code samples, testing, and certification tools. Without it, collaboration and the innovation it drives rarely take off. Bottom line As pioneering organizations leading the API imperative trend have discovered, companies can make more money by sharing technology assets than by controlling them. Embracing this trend fully will require rethinking long-held approaches to development, integration, and governance. But clinging to the old ways is no longer an option. The transition from independent systems to API platforms is already well under way. Dont be the last to learn the virtues of sharing. Tech Trends 2018: The symphonic enterprise 128 API imperative LARRY CALABRO Larry Calabro is a principal with Deloitte Consulting LLP and leads Deloittes Cloud Engineering practice. He previously served as the banking and securities sector leader, and prior to his role in the financial services industry, he launched and led the Application Management Services practice. Calabro has more than 20 years of experience helping clients use technology and innovation to transform their business. CHRIS PURPURA Chris Purpura is a managing director with Deloitte Consulting LLP and has more than 24 years of experience in both private- and public-sector technology companies. He is a leader within the cloud engineering service line and serves as a capability leader for APIs and hybrid integration. Purpura specializes in building out new markets, products, and business models focused on the enterprise middleware segment. VISHVESHWARA VASA Vishveshwara Vasa is a managing director with Deloitte Digital and serves as chief digital and cloud architect, with more than 18 years of IT experience. More recently, he has focused on digital marketing, cloud native development, global e-commerce, enterprise portal, system integration, and custom application development. Risk implications ARUN PERINKOLAM Arun Perinkolam is a principal with Deloitte and Touche LLPs Cyber Risk Services practice and is a leader within the Deloitte US technology, media, and telecommunications sector. He has more than 16 years of experience in developing large-scale digital and cyber risk transformational initiatives for global technology and consumer business companies. AUTHORS 129 1. Deloitte Consulting LLP, Tech Trends 2015: API economy, 2015. 2. Wendell Santos, ProgrammableWeb API directory eclipses 17,000 as API economy continues to surge, Program- mableWeb, March 3, 2017. 3. ABS-MAS Financial World, Finance-as-a-Service: API PlayBook, November 17, 2016. 4. Interview with Sorabh Saxena, AT&T Inc. president of business operations (formerly CIO of network and shared services), October 20, 2017. 5. Interview with Michelle Routh, chief enterprise architect, and Bill Maynard, global senior director of innovation and enterprise architecture, Coca-Cola Co., August 9, 2017. 6. Interview with general manager Linda Pung, business relationship manager Judy Odett, and business relation- ship manager Kemal Tekinel, all of the state of Michigans Department of Technology, Management and Budget, October 30, 2017. 7. Interview with Brad Fedosoff, vice president and head of enterprise architecture, Canadian Imperial Bank of Commerce, on October 30, 2017. ENDNOTES Tech Trends 2018: The symphonic enterprise 130 API imperative 131 Exponential technology watch list Innovation opportunities on the horizon SCIENCE author Steven Johnson once observed that innovation doesnt come just from giv-ing people incentives; it comes from creating environments where their ideas can connect.1 In a business and technology climate where the ability to innovate has become critical to survival, many companies still struggle to create the disci- plined, innovation-nurturing environments that Johnson describes. The process of innovating is, by definition, a hopeful journey into new landscapes. Without a clear destination, some executives can become unsure and frustrated. Where should we focus our innovation efforts? How can we develop breakthrough innovations that will set our business up for success in the future while delivering for the quarter? How can we turn our haphazard, episodic innovation efforts into methodical, productive pro- cesses? With exponential technologies, the challenge be- comes more daunting. Unlike many of the emerging tools and systems examined in this reportwhich demonstrate clear potential for impacting business- Is quantum computing becoming powerful enough to render your data encryption technology at risk? If so, will it be possible to quantum proof your information and communications? When does that need to be done? Will artificial general intelligence actually emerge and tilt the man/machine equa- tion further toward machines? Will it put your own job at risk? What about your businessor even your industry? Does AI represent an equal amount of opportunity to innovate and thrive? In the face of these and other exponential forces, leading organizationsworking within ecosystems that include busi- ness partners, start-ups, and academicsare developing the disciplined inno- vation responses and capabilities they will need to sense, experiment with, incubate, and scale exponential opportunities. Exponential technology watch list 133 es in the next 18 to 24 monthsexponentials can ap- pear a bit smaller on the horizon. These are emerg- ing technology forces that we think could manifest in a horizon 3 to 5 timeframebetween 36 and 60 months. With some exponentials, the time horizon may extend far beyond five years before manifesting broadly in business and government. For example, artificial general intelligence (AGI) and quantum encryption, which we examine later in this chap- ter, fall into the 5+ category. Others could manifest more quickly; even AGI and quantum encryption are showing breadcrumbs of progress that may lead to breakthroughs in the nearer time horizon. As you begin exploring exponential forces, keep in mind that even though they may appear small on the ho- rizon, you should not assume you have three to five years to put a plan together and get started. Now is the time to begin constructing an exponentials in- novation environment in which, as Johnson says, ideas can connect. At present, many enterprises lack the structures, capabilities, and processes required to innovate ef- fectively in the face of exponential changea real- ity that carries some risk. Though exponential ini- tiatives may require leaps of faith and longer-term commitments, they can potentially deliver transfor- mative outcomes. For example, in our Tech Trends 2014 report, we collaborated with faculty at Singu- larity University, a leading research institution, to explore robotics and additive manufacturing. At that time, these emerging technologies were out- pacing Moores Law: Their performance relative to cost (and size) was more than doubling every 12 to 18 months. Just a few years later, we see these same technologies are disrupting industries, business models, and strategies. Researchers at Doblin, the innovation practice of Deloitte Digital, have studied how effective in- novators approach these challenges and risks. They found that companies with the strongest innova- tion track records clearly articulate their innova- tion ambitions and maintain a strategically relevant portfolio of initiatives across ambition levels. Some efforts will focus on core innovation that optimizes existing products for existing customers. Others are around adjacent innovation that can help expand existing markets or develop new products working from their existing asset base. Others still target transformational innovationthat is, deploying capital to develop solutions for markets that do not yet exist or for needs that customers may not even recognize that they have. Doblin researchers examined companies in the industrial, technology, and consumer goods sec- tors, and correlated the pattern of companies in- novation investments with their share price perfor- mance. (See figure 1.) A striking pattern emerged: Outperforming firms typically allocate about 70 percent of their innovation resources to core offer- ings, 20 percent to adjacent efforts, and 10 percent to transformational initiatives. In contrast, cumula- tive returns on innovation investments tend to fol- low an inverse ratio, with 70 percent coming from Figure 1. Manage a portfolio of innovation investments across ambitions Deloitte Insights | Deloitte.com/insights Source: Deloitte analysis. Existing Incremental New M ar ke t & c us to m er s Products & assets Ex is ti ng A dj ac en t N ew 70% 70% 10% 10% 20% 20%Core Adjacent Transformational Average balanced portfolio 35-year return from an average balanced portfolio Tech Trends 2018: The symphonic enterprise 134 the transformational initiatives, 20 percent from adjacent, and 10 percent from core.2 These findings suggest that most successful innovators have struck the ideal balance of core, adjacent, and transforma- tional initiatives across the enterprise, and have put in place the tools and capabilities to manage those various initiatives as parts of an integrated whole. To be clear, a 70-20-10 allocation of innovation investments is not a magic formula that works for all companiesit is an average allocation based on cross-industry and cross-geography analysis. The optimum balance will vary from company to com- pany.3 One might assume that innovations derived from exponential technologies will emerge only in the transformational zone. In fact, exponential in- novation can occur in all three ambition zones. Au- thor and professor Clayton Christensen observed that truly disruptive technologies are often de- ployed first to improve existing products and pro- cessesthat is, those in the core and nearby adja- cent zones. Only later do these technologies find net new whitespace applications.4 Pursuing the unknowable Innovation investments allocated to exploring exponentials might be broadly characterized as un- knowable. Whether targeted at core, adjacent, or transformational returns, exponential investments focus largely on possibilities and vision that work beyond todays habits of success. Even though an exponential technologys full potential may not be- come apparent for several years, relevant capabili- ties and applications are probably emerging today. If you wait three years before thinking seriously about them, your first non-accidental yield could be three to five years beyond that. Because exponential forces develop at an atypical, nonlinear pace, the longer you wait to begin exploring them, the further your company may fall behind. As you begin planning the exponentials innova- tion journey ahead, consider taking a lifecycle ap- proach that includes the following steps:  Sensing and research. As a first step, be- gin building hypotheses based on sensing and research. Identify an exponential force and hypothesize its impact on your products, your production methods, and your competitive en- vironment in early and mid-stage emergence. Then perform research around that hypothesis, using thresholds or trigger levels to increase or decrease activity and investment over time. It is important to note that sensing and research are not R&Dthey are preliminary steps in what will be a longer effort to determine an exponen- tial forces potential for your business.  Exploration and experimentation. At some point, your research reaches a threshold at which you can begin exploring the state of the possible. Look at how others in your industry are approaching or even exploiting these forces. At this point, show is better than tell. Try to col- lect 10 or more exemplars of what others are do- ing with exponentials. These can help you and your colleagues better understand exponential forces and their potential. Also examine how developing an ecosystem around each exponential force could help you engage external business partners, vendors, and suppliers as well as stakeholders in your own or- ganization. How could such an ecosystem enable exchanges of value among members? What kind of governance and processes would be needed to manage such an ecosystem? How could your en- terprise benefit from ecosystem success? As you and stakeholders across the enterprise gradually deepen your understanding of expo- nential forces, you can begin exploring state of the practical. Specifically, which elements of a given exponential force can potentially benefit the business? To develop a more in-depth un- derstanding of the state of the practical, examine an exponentials viability through the lens of a balanced breakthrough model: What about this opportunity is desirable from a customer per- spective? Is this opportunity viable from a busi- ness perspective? And importantly, do you have Exponential technology watch list 135 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 Deloitte Insights | Deloitte.com/insights Figure 2. Innovation centers in Fortune 100 companies Deloitte research reveals that 67 of the Fortune 100 companies have at least one innovation centera formal initiative that harnesses disruptive technologies and partnerships to improve operations, products, and customer experiences. Early on, a handful of forward-thinking organizations pioneered the innovation center model. In the decades since, more companies have created their own innovation centers, which evidences a steadily growing need to tackle innovation more methodically. Source: Publicly available information on all Fortune 100 companies; representative sample of partnerships. 19451929 1957 1966 1979 1980 1996 1997 1998 1999 2000 2001 2002 2003 Industry Consumer & industrial products Financial services Energy & resources Public sector Cross-industry Partnerships Academia & research Venture capital Government Companies & industry associations Technology, media, telecommunications Life sciences & health care Innovate 72 Technology 54 Solution 29 Lab 22 Business 21 Create 21 Industry 18 New 18 Drive 17 Health care 17 World 17 Research 16 Computer 15 Customer 15 Experience 15 Partner 15 Advance 14 Lead 14 Collaborate 13 Develop 13 Company 12 Health 12 Help 12 Improve 12 Build 11 Connect 11 Enable 11 People 11 Product 11 Work 11 Timeline Founding year of companys first innovation center Purpose The most frequent words in the companies mission statements Start-ups the critical capabilities and technology assets you will need to capitalize on this opportunity? To move beyond exploration and into ex- perimentation, try to prioritize use cases, de- velop basic business cases, and then build initial prototypes. If the business case yieldsperhaps with some use case pivotsthen you may have found a winning innovation.  Incubation and scaling. When the value proposition of the experiment meets the ex- pectations set forth in your business case, you may be tempted to put the innovation into full enterprise-wide production. Be cautious about moving too quickly. Even with a solid business case and encouraging experiments, at this stage your innovation is not proven out at scale. Some companies have established innovation centers that are separate from the core business and staffed with dedicated talent. These formal ini- tiatives typically have incubation and scaling expertise. They may also have the capacity to carry out the level of enhancement, testing, and hardening needed before putting your innova- tion into production.  Be programmatic. Taking any innovation but particularly one grounded in exponential forcesfrom sensing to production is not a two-step process, nor is it an accidental process. Tech Trends 2018: The symphonic enterprise 136 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 Deloitte Insights | Deloitte.com/insights Figure 2. Innovation centers in Fortune 100 companies Deloitte research reveals that 67 of the Fortune 100 companies have at least one innovation centera formal initiative that harnesses disruptive technologies and partnerships to improve operations, products, and customer experiences. Early on, a handful of forward-thinking organizations pioneered the innovation center model. In the decades since, more companies have created their own innovation centers, which evidences a steadily growing need to tackle innovation more methodically. Source: Publicly available information on all Fortune 100 companies; representative sample of partnerships. 19451929 1957 1966 1979 1980 1996 1997 1998 1999 2000 2001 2002 2003 Industry Consumer & industrial products Financial services Energy & resources Public sector Cross-industry Partnerships Academia & research Venture capital Government Companies & industry associations Technology, media, telecommunications Life sciences & health care Innovate 72 Technology 54 Solution 29 Lab 22 Business 21 Create 21 Industry 18 New 18 Drive 17 Health care 17 World 17 Research 16 Computer 15 Customer 15 Experience 15 Partner 15 Advance 14 Lead 14 Collaborate 13 Develop 13 Company 12 Health 12 Help 12 Improve 12 Build 11 Connect 11 Enable 11 People 11 Product 11 Work 11 Timeline Founding year of companys first innovation center Purpose The most frequent words in the companies mission statements Start-ups Some think of innovation as nothing more than eureka! moments. While there is an element of that, innovation is more about programmatic disciplined effort, carried out over time in a well- considered portfolio approach, than it is about serendipity. Inspiration is an ingredient, but so is perspiration. Dont forget the humans As you dive into exponentials and begin thinking more deliberately about the way you approach in- novation, it is easy to become distracted or discour- aged. You may think, This is scary and cant be true or, This is only about technology. Its important not to lose sight of the fact that for most companies, human beings are the fundamental unit of econom- ic value. For example, people remain at the center of investment processes, and they still make op- erational decisions about what innovations to test and deploy. Exploring exponential possibilities is first and foremost about driving certain human be- haviorsin your operation, and in the marketplace. Moreover, as Steven Johnson suggests, when hu- man ideas connect, innovation surely follows. With humans as the focus of your efforts, you will be able to keep exponentialsin all their mind-blowing grandeurin a proper perspective. Exponential technology watch list 137 Jonathan Knowles, head of faculty and distinguished fellow Pascal Finette, vice president of startup solutions SINGULARITY UNIVERSITY Humans are not wired to think in an exponential way. We think linearly because our lives are linear journeys: We move from sunup to sundown, from Mondays to Fridays. The idea that something could be evolving so dramatically that its rate of change must be expressed in exponents seems, on a very basic level, nonsensical. Yet exponential progress is happening, especially in technologies. Consider this very basic example: In 1997, the $46 million ASCI Red supercomputer had 1.3 teraflops of processing power, which at the time made it the worlds fastest computer.5 Today, Microsofts $499 Xbox One X gaming console has 6 teraflops of power.6 Mira, a supercomputer at Argonne National Laboratory, is a 10 petaflop machine.7 Thats ten thousand trillion floating point operations per second! Exponential innovation is not new, and there is no indication it will slow or stop. More importantly, exponential advances in computers enable exponential advancesand disruptionsin other areas. And therein lies the challenge for CIOs and other executives. How can companies ultimately harness exponential innovation rather than be disrupted by it? Consider the often-cited cautionary tale of Kodak. In the 1970s, Kodak created a .01 megapixel camera but decided to sit on the technology rather than market it.8 If you try to do what Kodak did, will somebody eventually come along and disrupt you? Should you assume that every technology can have exponential potential? In 2011, a group of researchers demonstrated a neural network AI that could recognize a cat in a videoa breakthrough that some people found funny. If they had been able to see five years into the future, they might not have laughed. Today, retailers are projecting store performance and positively impacting revenue by analyzing in-store video feeds to determine how many bags each shopper is carrying.9 Reorienting linear-thinking, quarterly revenue-focused stakeholders and decision-makers toward exponential possibilities can be challenging. Institutional resistance to change only hardens when the change under consideration has a five-year time horizon. But exponential change is already under way, and its velocity only continues to increase. The question that business and agency leaders face is not whether exponential breakthroughs will upset the status quo, but howand how much, and how soon... Our take 138 In the 2013 Spike Jonze film Her, a sensitive man on the rebound from a broken marriage falls in love with Samantha, a new operating system that is intuitive, self-aware, and empathetic.10 Studio marketers advertised the films storyline as science fiction. But was it? Ongoing advances in artificial in- telligence suggest that at some point in the future, technology may broadly match human intellectual (and social or emotional) capabilities and, in doing so, erase the boundary between humans and ma- chines.11 Known as artificial general intelligence (AGI), this advanced version of todays AI would have many capabilities that broadly match what humans call our gut instinctthe intuitive understanding we bring to unfamiliar situations that allows us to perceive, interpret, and deduce on the spot. Consider the disruptive potential of a fully real- ized AGI solution: Virtual marketers could analyze massive stores of customer data to design, market, and sell products and servicesdata from internal systems fully informed by social media, news, and market feeds. Algorithms working around the clock could replace writers altogether by generating fac- tual, complex, situation-appropriate content free of biases and in multiple languages. This list goes on. As an exponential force, AGI may someday prove profoundly transformational. However, before that day arrives, AI will have to advance far beyond its current capabilities. Existing variations of AI can do only the things that programmers tell them to do, either explicitly or through machine learning. AIs current strength lies primarily in narrow in- telligenceso-called artificial narrow intelligence (ANI), such as natural language processing, image recognition, and deep learning to build expert sys- tems. A fully realized AGI system will feature these narrow component capabilities, plus several others that currently do not yet exist: the ability to reason under uncertainty, to make decisions and act delib- erately in the world, to sense, and to communicate naturally. These general capabilities that may some- day make AGI much more human-like remain stubbornly elusive. While there have been break- throughs in neural networks, computer vision, and data mining, significant research challenges beyond computational power must be overcome for AGI to achieve its potential.12 Indeed, the most formidable challenge may lie in finding a means for technology to reason under uncertainty. This is not about har- nessing a spectrum of existing learning, language, and sensing capabilities. Its about creating some- thing entirely new that enables mechanisms to ex- plore an unfamiliar environment, draw actionable conclusions about it, and use those conclusions to complete an unfamiliar task. Three-year-old hu- mans can do this well. At present, AI cannot. Talkin bout an evolution In all likelihood, AGIs general capabilities will not appear during some eureka! moment in a lab. Rather, they will emerge over time as part of AIs on- going evolution. During the next three to five years, expect to see improvements in AIs current compo- nent capabilities. Likewise, there will likely be prog- ress made toward integrating and orchestrating these capabilities in pairs and multiples. What you probably wont see in this time horizon is the suc- cessful development, integration, and deployment of all AGI component capabilities. We believe that milestone is at least 10+ years away. (See My take below for more on this topic.) As AI use cases prog- ress into full deployment and the pace of enterprise adoption accelerates, standards will likely emerge for machine learning and other AI component capa- bilities, and eventually for AI product suites. From an enterprise perspective, many compa- nies have already begun narrow intelligence jour- neys, often by exploring potential applications for ANI components, such as pattern recognition to di- agnose skin cancer, or machine learning to improve decision-making in HR, legal, and other corporate functions. In many cases, these initial steps yield informa- tion that becomes part of an internal ANI knowl- Exponential technology watch list ARTIFICIAL G EN ERAL IN TELLIG EN CE 139 edge baseone that can be refined in the coming years as technologies advance and best practices emerge. For example, in a pioneering ANI initiative, Goldman Sachs is investing in machine learning in what will be an ongoing effort to leverage data as a strategic asset.13 Across the financial and other sec- tors, expect to see smaller applications as wellfor example, applying deep learning to emails to iden- tify patterns and generate insights into best prac- tices and insider threats. Some of these individual successes will likely be launched in greenfield initia- tives. Others may be accretive, but they too could il- luminate insights that help companies develop and refine their ANI knowledge bases. The state-of-the-art reflects progress in each sub-problem and innovation in pair-wise integra- tion. Vision + empathy = affective computing. Natu- ral language processing + learning = translation be- tween languages youve never seen before. Google Tensor Flow may be used to build sentiment analy- sis and machine translation, but its not easy to get one solution to do both well. Generality is difficult. Advancing from one domain to two is a big deal; adding a third is exponentially harder. John Launchbury, former director of the Infor- mation Innovation Office at the Defense Advanced Research Projects Agency, describes a notional ar- tificial intelligence scale with four categories: learn- ing within an environment; reasoning to plan and to decide; perceiving rich, complex, and subtle infor- mation; and abstracting to create new meanings.14 He describes the first wave of AI as handcrafted knowledge in which humans create sets of rules to represent the structure of knowledge in well- defined domains, and machines then explore the specifics. These expert systems and rules engines are strong in the reasoning category and should be important elements of your AI portfolio. Launch- bury describes the second wavewhich is currently under wayas statistical learning. In this wave, hu- mans create statistical models for specific problem domains and train them on big data with lots of la- bel data, using neural nets for deep learning. These second-wave AIs are good at perceiving and learn- ing but less so at reasoning. He describes the next wave as contextual adaptation. In this wave, AI con- structs contextual explanatory models for classes of real-world phenomena; these waves balance the in- telligence scale across all four categories, including the elusive abstracting. Though many believe that computers will never be able to accurately recognize or fully understand human emotions, advances in machine learning suggest otherwise. Machine learning, paired with emotion recognition software, has demonstrated that it is already at human-level performance in dis- cerning a persons emotional state based on tone of voice or facial expressions.15 These are critical steps in AIs evolution into AGI. Other breadcrumbs suggest that the evolution may be gaining momentum. For example, a super- computer became the first machine to pass the long- established Turing test by fooling interrogators into thinking it was a 13-year-old boy.16 (Other ex- perts proffer more demanding measures, including standardized academic tests.) Though it made hardly a ripple in the press, the most significant AGI breadcrumb appeared on January 20, 2017, when researchers at Googles AI skunkworks, DeepMind, quietly submitted a paper on arXiv titled PathNet: Evolution Channels Gradi- ent Descent in Super Neural Networks. While not exactly beach reading, this paper will be remem- bered as one of the first published architectural de- signs for a fully realized AGI solution.17 As you work in the nearer time horizons with first- and second-wave ANIs, you may explore com- bining and composing multiple sub-problem solu- tions to achieve enterprise systems that balance the intelligence categories, including abstracting. Perhaps in the longer horizons, Samantha, Spike Jonzes empathetic operating system, is not so fic- tional after all. AR TI FI CI AL G EN ER AL IN TE LL IG EN CE Tech Trends 2018: The symphonic enterprise 140 My take OREN ETZIONI, CEO ALLEN INSTITUTE FOR ARTIFICIAL INTELLIGENCE In March 2016, the American Association for Artificial Intelligence and I asked 193 AI research- ers how long it would be until we achieve artificial superintelligence, defined as an intellect that is smarter than the best human in practically every field. Of the 80 Fellows responding, roughly 67.5 percent of respondents said it could take a quar- ter century or more. 25 percent said it would likely never happen.18 Given the sheer number of AI is coming to take your job articles appearing across media, these sur- vey findings may come as a surprise to some. Yet they are grounded in certain realities. While psy- chometrics measure human IQ fairly reliably, AI psychometrics are not nearly as mature. Ill-formed problems are vague and fuzzy, and wrestling them to the ground is a hard problem. Few interactions in life have clearly defined rules, goals, and objectives, and the expectations of artificial general intelligence on such areas as lan- guage communications are squishy. How can you tell whether Ive understood a sentence properly? Improving speech recognition doesnt necessarily improve language understanding, since even simple communication can quickly get complicatedcon- sider that there are more than 2 million ways to or- der a coffee at a popular chain. Successfully creating AGI that matches human intellectual capabilities or artificial superintelligence (ASI) that surpasses themwill require dramatic improvements beyond where we are today. However, you dont have to wait for AGI to ap- pear (if it ever does) to begin exploring AIs pos- sibilities. Some companies are already achieving positive outcomes with so-called artificial narrow intelligence (ANI) applications by pairing and com- bining multiple ANI capabilities to solve more complex problems. For example, natural language processing integrated with machine learning can expand the scope of language translation; computer vision paired with artificial empathy technologies can create affective computing capabilities. Con- sider self-driving cars, which have taken the sets of behaviors needed for drivingsuch as reading signs and figuring out what pedestrians might doand converted them into something that AI can under- stand and act upon. You need specialized skillsets to achieve this lev- el of progress in your companyand currently there arent nearly enough deep learning experts to meet the demand. You also need enormous amounts of label data to bring deep learning systems to fruition, while people can learn from just a few labels. We dont even know how to represent many common concepts to the machine today. Keep in mind that the journey from ANI to AGI is not just difference in scale. It requires radical improvements and perhaps radically different tech- nologies. Be careful to distinguish what seems intel- ligent from what is intelligent, and dont mistake a clear view for a short distance. But regardless, get started. The opportunity may well justify the effort. Even current AI capabilities can offer useful solu- tions to difficult problems, not just in individual or- ganizations but across entire industries. Exponential technology watch list ARTIFICIAL G EN ERAL IN TELLIG EN CE 141 Endangered or enabled At some point in the futureperhaps within a decadequantum computers that are exponentially more powerful than the most advanced supercom- puters in use today could help address real-world business and governmental challenges. In the realm of personalized medicine, for example, they could model drug interactions for all 20,000-plus pro- teins encoded in the human genome. In climate science, quantum-enabled simulation might unlock new insights into human ecological impact.19 Another possibility: Quantum computers could render many current encryption techniques utterly useless. How? Many of the most commonly deployed en- cryption algorithms today are based on integer fac- torization of large prime numbers, which in number theory is the decomposition of a composite number into the product of smaller integers. The mathemat- ical proofs show that it would take classical comput- ers millions of years to decompose the more than 500-digit number sequences that comprise popular encryption protocols like RSA-2048 or Diffie-Hell- man. Mature quantum computers will likely be able to decompose those sequences in seconds.20 Thought leaders in the quantum computing and cybersecurity fields offer varying theories on when or how such a mass decryption event might begin, but on one point they agree: Its impact on personal privacy, national security, and the global economy would likely be catastrophic.21 Yet all is not lost. As an exponential force, quan- tum computing could turn out to be both a curse and a blessing for cryptology. The same comput- ing power that bad actors deploy to decrypt todays common security algorithms for nefarious purposes could just as easily be harnessed to create stronger quantum resistant encryption. In fact, work on de- veloping post-quantum encryption around some principles of quantum mechanics is already under way. In the meantime, private and public organiza- tions should be aware of the quantum decryption threat on the horizon, and that in the long term, they will need new encryption techniques to quan- tum-proof informationincluding techniques that do not yet exist. There are, however, several interim steps organizations can take to enhance current encryption techniques and lay the groundwork for additional quantum-resistant measures as they emerge. Understanding the quantum threat In Tech Trends 2017, we examined quantum technology, which can be defined broadly as engi- neering that exploits properties of quantum me- chanics into practical applications in computing, sensors, cryptography, and simulations. Efforts to harness quantum technology in a general-purpose quantum computer began years ago, though at pres- ent, engineering hurdles remain. Nonetheless, there is an active race under way to achieve a state of quantum supremacy in which a provable quantum computer surpasses the combined problem-solving capability of the worlds current supercomputers.22 To understand the potential threat that quan- tum computers pose to encryption, one must also understand Shors algorithm. In 1994, MIT math- ematics professor Peter Shor developed a quantum algorithm that could factor large integers very ef- ficiently. The only problem was that in 1994, there was no computer powerful enough to run it. Even so, Shors algorithm basically put asymmetric crypto- systems based on integer factorizationin particu- lar, the widely used RSAon notice that their days were numbered.23 To descramble encrypted informationfor ex- ample, a document or an emailusers need a key. Symmetric or shared encryption uses a single key that is shared by the creator of the encrypted infor- mation and anyone the creator wants to access the information. Asymmetric or public-key encryption uses two keysone that is private, and another that is made public. Any person can encrypt a message Q U AN TU M E N CR YP TI O N Tech Trends 2018: The symphonic enterprise 142 using a public key. But only those who hold the as- sociate private key can decrypt that message. With sufficient (read quantum) computing power, Shors algorithm would be able to crack two-key asym- metric cryptosystems without breaking a sweat. It is worth noting that another quantum algorithm Grovers algorithm, which also demands high levels of quantum computing powercan be used to at- tack ciphers.24 One common defensive strategy calls for larger key sizes. However, creating larger keys requires more time and computing power. Moreover, larger keys often result in larger encrypted files and sig- nature sizes. Another, more straightforward post- quantum encryption approach uses large symmet- ric keys. Symmetric keys, though, require some way to securely exchange the shared keys without exposing them to potential hackers. How can you get the key to a recipient of the encrypted informa- tion? Existing symmetric key management systems such as Kerberos are already in use, and some lead- ing researchers see them as an efficient way forward. The addition of forward secrecyusing multiple random public keys per session for the purposes of key agreementadds strength to the scheme. With forward secrecy, hacking the key of one message doesnt expose other messages in the exchange. Key vulnerability may not last indefinitely. Some of the same laws of quantum physics that are en- abling massive computational power are also driv- ing the growing field of quantum cryptography. In a wholly different approach to encryption, keys be- come encrypted within two entangled photons that are passed between two parties sharing information, Exponential technology watch list Q U AN TU M EN CRYPTIO N A view from the quantum trenches Shihan Sajeed holds a Ph.D. in quantum information science. His research focuses on the emerging fields of quantum key distribution systems (QKD), security analyses on practical QKD, and quantum non-locality. As part of this research, Dr. Sajeed hacks into systems during security evaluations to try to find and exploit vulnerabilities in practical quantum encryption. Dr. Sajeed sees a flaw in the way many people plan to respond to the quantum computing threat. Because it could be a decade or longer before a general-purpose quantum computer emerges, few feel any urgency to take action. They think, Today my data is secure, in flight and at rest. I know there will eventually be a quantum computer, and when that day comes, I will change over to a quantum-resistant encryption scheme to protect new data. And then, Ill begin methodically converting legacy data to the new scheme, Dr. Sajeed says. That is a fine plan if you think that you can switch to quantum encryption overnightwhich I do notand unless an adversary has been intercepting and copying your data over the last five years. In that case, the day the first quantum computer goes live, your legacy data becomes clear text. A variety of quantum cryptography solutions available today can help address future legacy data challenges. Be aware that the technology of quantum encryption, like any emerging technology, still has vulnerabilities and there is room for improvement, Dr. Sajeed says. But if implemented properly, this technology can make it impossible for a hacker to steal information without alerting the communicating parties that they are being hacked. Dr. Sajeed cautions that the journey to achieve a reliable implementation of quantum encryption takes longer than many people think. Theres math to prove and new technologies to roll out, which wont happen overnight, he says. Bottom line: The time to begin responding to quantums threat is now.26 143 typically via a fiber-optic cable. The no cloning theorem derives from Heisenbergs Uncertainty Principle and dictates that a hacker cannot intercept or try to change one of the photons without altering them. The sharing parties will realize theyve been hacked when the photon-encrypted keys no longer match.25 Another option looks to the cryptographic past while leveraging the quantum future. A one-time pad system widely deployed during World War II generates a randomly numbered private key that is used only to encrypt a message. The receiver of the message uses the only other copy of the match- ing one-time pad (the shared secret) to decrypt the message. Historically, it has been challenging to get the other copy of the pad to the receiver. Today, the photonic-perfect quantum communication channel described above can facilitate the key exchange. In fact, it can generate the pad on the spot during an exchange. Now what? We dont know if it will be five, 10, or 20 years before efficient and scalable quantum computers fall into the hands of a rogue government or a black hat hacker. In fact, its more likely that instead of the general-purpose quantum computer, special- purpose quantum machines will emerge sooner for this purpose. We also dont know how long it will take the cryptography community to developand provean encryption scheme that will be impervi- ous to Shors algorithm. In the meantime, consider shifting from asym- metric encryption to symmetric. Given the vulnera- bility of asymmetric encryption to quantum hacking, transitioning to a symmetric encryption scheme with shared keys and forward secrecy may help mitigate some quantum risk. Also, seek opportu- nities to collaborate with others within your indus- try, with cybersecurity vendors, and with start-ups to create new encryption systems that meet your companys unique needs. Leading practices for such collaborations include developing a new algorithm, making it available for peer review, and sharing re- sults with experts in the field to prove it is effective. No matter what strategy you choose, start now. It could take a decade or more to develop viable so- lutions, prototype and test them, and then deploy and standardize them across the enterprise. By then, quantum computing attacks could have permanent- ly disabled your organization. Q U AN TU M E N CR YP TI O N Tech Trends 2018: The symphonic enterprise 144 Exponential technology watch list RISK IM PLICATIO N S Some think it is paradoxical to talk about risk and innovation in the same breath, but coupling those capabilities is crucial when applying new tech- nologies to your business. In the same way that de- velopers dont typically reinvent the user interface each time they develop an application, there are foundational rules of risk management that, when applied to technology innovation, can both facilitate and even accelerate development rather than hin- der it. For example, having common code for core services such as access to applications, logging and monitoring, and data handling can provide a consis- tent way for developers to build applications with- out reinventing the wheel each time. To that end, organizations can accelerate the path to innovation by developing guiding principles for risk, as well as developing a common library of modularized capa- bilities for reuse. Once you remove the burden of critical and com- mon risks, you can turn your attention to those that are unique to your innovation. You should evalu- ate the new attack vectors the innovation could introduce, group and quantify them, then deter- mine which risks are truly relevant to you and your customers. Finally, decide which you will address, which you can transfer, and which may be outside your scope. By consciously embracing and manag- ing risks, you actually may move faster in scaling your project and going to market. Artificial general intelligence. AGI is like a virtual human employee that can learn, make de- cisions, and understand things. You should think about how you can protect that worker from hack- ers, as well as put controls in place to help it under- stand the concepts of security and risk. You should program your AGI to learn and comprehend how to secure data, hardware, and systems. AGIs real-time analytics could offer tremendous value, however, when incorporated into a risk man- agement strategy. Today, risk detection typically oc- curs through analytics that could take days or weeks to complete. leaving your system open to similar risks until the system is updated to prevent it from happening again. With AGI, however, it may be possible to auto- mate and accelerate threat detection and analysis. Then notification of the event and the response can escalate to the right level of analyst to verify the re- sponse and speed the action to deflect the threatin real time. Quantum computing and encryption. The current Advanced Encryption Standard (AES) has been in place for more than 40 years. In that time, some have estimated that even the most powerful devices and platforms would take decades to break AES with a 256-bit key. Now, as quantum com- puting allows higher-level computing in a shorter amount of time, it could be possible to break the codes currently protecting networks and data. Possible solutions may include generating a larger key size or creating a more robust algorithm that is more computing-intensive to decrypt. How- ever, such options could overburden your existing computing systems, which may not have the power to complete these complex encryption functions. The good news is that quantum computing also could have the power to create new algorithms that are more difficult and computing-intensive to de- crypt. For now, quantum computing is primarily still in the experimental stage, and there is time to consider designing quantum-specialized algorithms to protect the data that would be most vulnerable to a quantum-level attack. 145 JEFF MARGOLIES Jeff Margolies is a principal with Deloitte and Touche LLPs Cyber Risk Services practice, and has over 20 years of experience in advising clients on complex security challenges across a variety of industries. He has held a series of practice leadership roles and is currently focused on leading cyber risk in the cloud. In this practice, Margolies helps cloud consumers and providers solve the key challenge of maintaining their cyber risks in the public cloud. RAJEEV RONANKI Rajeev Ronanki leads Deloitte Consulting LLPs Cognitive Computing and Health Care Innovation practices as well as Deloittes innovation partnership program with Singularity University. He has more than 20 years of experience in health care and information technology, and primarily focuses on implementing cognitive solutions for personalized consumer engagement, intelligent automation, and predictive analytics. DAVID STEIER David Steier is a managing director for Deloitte Analytics with Deloitte Consulting LLPs US Human Capital practice. He also serves as Deloittes technology black belt for unstructured analytics. Using advanced analytic and visualization techniques, including predictive modeling, social network analysis, and text mining, Steier and his team of quantitative specialists help clients solve some of their most complex technical problems. AUTHORS Bottom line Though the promiseand potential challengeexponential innovations such as AGI and quantum encryption hold for business is not yet fully defined, there are steps companies can take in the near term to lay the groundwork for their eventual arrival. As with other emerging technologies, exponentials often offer competitive opportunities in adjacent innovation and early adoption. CIO, CTOs, and other executives can and should begin exploring exponentials possibilities today. Tech Trends 2018: The symphonic enterprise 146 GEOFF TUFF Geoff Tuff is a principal with Deloitte Digital and a leader of Deloitte Consulting LLPs Digital Transformation practice. He has more than 25 years of experience working with some of the worlds top companies to drive growth, innovation, and the adoption of business models to effectively manage change. MARK WHITE Mark White is the chief technologist for the US innovation office with Deloitte Consulting LLP and leads disruptive technology sensing, insight development, and experimentation. Previously, he served as chief technology officer for the US, Global, and Federal Consulting practices. White serves a variety of clients in the federal, financial services, high-tech, and telecommunications industries. AYAN BHATTACHARYA Ayan Bhattacharya is a specialist leader with Deloitte Consulting LLP, and a data analytics leader specializing in AI and cognitive transformations ranging from innovation acceleration to first of a kind advanced analytics solutions. He is responsible for growing Deloittes assets and services to clients in financial services, insurance, life science, health care, and technology, media, and telecommunications industry sectors. NIPUN GUPTA Nipun Gupta is a senior consultant with Deloitte and Touche LLPs Cyber Risk Advisory practice. Currently, he is helping build Deloittes cyber innovation ecosystemwhich consists of cybersecurity start-ups, clients, partners, and investorsto support strategic initiatives with startups incubated at DataTribe, where Deloitte is an equity investor. Risk implications IRFAN SAIF Irfan Saif is an advisory principal with Deloitte and Touche LLP and has more than 20 years of IT consulting experience, specializing in cybersecurity and risk management. He serves as the US technology industry leader for Deloittes Advisory business and is a member of Deloittes CIO Program and its Cyber Risk practice leadership teams. Exponential technology watch list 147 1. Steven Johnson, Where Good Ideas Come From: A Natural History of Innovation (N.Y.: Riverhead, 2010). 2. Doblin Deloitte, research and analysis, 201117; Bansi Nagji and Geoff Tuff, Managing your innovation portfo- lio, Harvard Business Review, May 2012. 3. Nagji and Tuff, Managing your innovation portfolio. 4. Clayton M. Christensen, The Innovators Dilemma: When New Technologies Cause Great Firms to Fail (Cambridge: Harvard Business Review Press, 1997). 5. Sebastian Anthony, The history of supercomputers, Extreme Tech, April 10, 2012. 6. Sam Prell, Does Xbox One Xs 6 teraflops really make it the most powerful console ever? Lets look closer, GamesRadar, April 3, 2017. 7. Rob Verger, Intels new chip puts a teraflop in your desktop; heres what that means, Popular Science, June 1, 2017. 8. Richard Trenholm, Photos: The history of the digital camera, CNet, November 5, 2007. 9. John Markoff, How many computers to identify a cat? 16,000, New York Times, June 25, 2012. 10. Her: A Spike Jonze love story, accessed November 15, 2017. 11. Charlotte Jee, What is artificial general intelligence?, TechWorld, August 26, 2016. 12. Eliezer Yudkowsky, Theres no fire alarm for artificial general intelligence, Machine Intelligence Research Insti- tute, October 13, 2017. 13. Matt Turner, Goldman Sachs: Were investing deeply in artificial intelligence, Business Insider, January 21, 2016. 14. John Launchbury, A DARPA perspective on artificial intelligence, DARPAtv, February 15, 2017. 15. Eric Brynjolfsson and Andrew McAfee, The business of artificial intelligence, Harvard Business Review, July 20, 2017. 16. Press Association, Computer simulating 13-year-old boy becomes first to pass the Turing test, Guardian, June 8, 2014. Note that not everyone was impressedsee, for example, Martin Robbins, Sorry, Internet, a computer didnt actually pass the Turing test, Vice, June 9, 2014. 17. Matthew Griffin, Google DeepMind publishes breakthrough artificial general intelligence architecture, Fanatical Futurist, March 15, 2017. 18. Oren Etzioni, No, the experts dont think super-intelligent AI is a threat to humanity, MIT Technology Review, September 20, 2016. 19. Peter Diamandis, What are the implications of quantum computing?, Tech Blog, 2016. 20. Matthew Green, Its the end of the world as we know it (and I feel fine), A Few Thoughts on Cryptographic Engineer- ing, April 11, 2012. 21. Meredith Rutland Bauer, Quantum computing is coming for your data, Wired, July 19, 2017. ENDNOTES Tech Trends 2018: The symphonic enterprise 148 22. Deloitte Consulting LLP, Tech Trends 2017, Exponentials Watch List, 2017. 23. Jennifer Chu, The beginning of the end for encryption schemes?, MIT News, March 3, 2016. 24. Green, Its the end of the world as we know it (and I feel fine). 25. Adam Mann, Laws of physics say quantum cryptography is unhackable. Its not, Wired, June 7, 2013. 26. Interview with Shihan Sajeed, October 30, 2017. Exponential technology watch list 149 BILL BRIGGS Global and US chief technology officer Deloitte Consulting LLP wbriggs@deloitte.com | Twitter: @wdbthree Bill Briggs nineteen-plus years with Deloitte have been spent delivering complex transformation programs for clients in a variety of industries, including financial services, health care, consumer products, telecommunications, energy, and public sector. He is a strategist with deep implementation experience, helping clients anticipate the impact that new and emerging technologies may have on their business in the futureand getting there from the realities of today. In his role as CTO, Briggs is responsible for research, eminence, and innovation, helping to define and execute the vision for Deloitte Consulting LLPs Technology practice, identifying and communicating those technology trends affecting clients businesses, and driving the strategy for Deloitte Consulting LLPs evolving technology services and offerings. As the founding global leader of Deloitte Digital, Briggs was responsible for the launch and growth of a new global practice redefining the vision of a digital consulting agency. Deloitte Digital offers a mix of creative, strategy, user experience, engineering talent, and technology services to help clients harness disruptive digital technologies to imagine, deliver, and run the futureto engage differently with customers, reshape how work gets done, and rethink the very core of their markets. EXECUTIVE EDITOR Tech Trends 2018: The symphonic enterprise 150 SEAN DONNELLY Technology Strategy and Innovation leader Deloitte LLP Sean Donnelly leads Deloittes Technology Strategy and Innovation practice in Canada. He focuses on defining and integrating business and IT strategies and developing operational capabilities within IT. With more than 20 years of consulting experience in the financial services industry, Donnelly is a trusted adviser for numerous financial institutions on the adoption of new technologies and transformation of their IT functions. As the Canadian CIO Program lead, he is responsible for communicating with the technology executive community across industries on the latest technology trends, challenges, and opportunities. MARK LILLIE EMEA Energy Resources leader Deloitte MCS Limited Mark Lillie leads the Power and Utilities practice for Deloitte North West Europe, as well as the EMEA Energy and Resources Consulting business. He is the global lead for the CIO Program and technology strategy, which includes the annual CIO survey, tech trends, CIO transition labs, and the NextGen CIO Program. Lillie specializes in organization redesign, business change, IT strategy, and transformation programs including business strategy alignment, target operating model definition, cost reduction, and IT-enabled business process transformation. He also has experience across the energy value chain including energy trading, risk management, commercial optimization and retail operations. KEVIN RUSSO Technology Strategy and Architecture leader Deloitte Touche Tohmatsu Kevin Russo is a lead partner for Deloitte Touche Tohmatsus Technology, Strategy and Architecture practice in Australia and the Asia-Pacific region. He has more than 20 years of experience in the technology industry, focusing on strategy development and implementation of emerging technology programs. Russo works with some of Australias most innovative companies in the FSI, telecommunications, public sector, and energy and resources industries. Prior to Deloitte, he held global roles in both management consulting and software industries and led account management of several large multinational clients. Russo was also involved in two technology start-ups in the United States and is a member of Deloittes innovation council. GLOBAL IMPACT AUTHORS Authors 151 GORDON SHIELDS Global Technology Strategy and Architecture leader Deloitte LLP Gordon Shields is a partner with Deloitte LLP. He leads the Analytics practice in Canada and is the global leader for the Technology, Strategy, and Architecture practice. Shields has more than 30 years of industry experience. He specializes in information system strategies, outsourcing advisory, mergers and acquisitions, systems analysis, design, and implementation with a focus on data architectures, data governance and data quality. Shields has led international projects in the health, financial, public sector, pulp and paper, outsourcing, HR transformation, mining, pharmaceuticals, and energy and resources industries. HANS VAN GRIEKEN EMEA Technology Research & Insights leader Deloitte Consulting B.V. Hans van Grieken is the EMEA technology research and insights leader with Deloittes global CIO Program. He helps shape Deloittes global research agenda in addition to identifying and driving EMEA research initiatives. Van Grieken frequently addresses conferences and corporate boardrooms on the topics of digital DNA, digital transformation, and innovation. He is a fellow of Deloittes Center for the Edge where he helps senior executives understand the fundamental technology-driven changes that shape their business world, navigate short-term challenges, and identify long- term opportunities. Van Grieken is also a part-time executive lecturer at Nyenrode Business School. KEVIN WALSH Global Consulting Technology leader Deloitte MCS Limited Kevin Walsh is the Global Consulting Technology leader with Deloitte MCS Limited, and a member of the Deloitte Global Consulting Executive. In his current role, he is responsible for the development and execution of the global strategy for Deloittes Technology Consulting business. Walsh started his career in systems implementation for businesses across Europe, and has accrued more than 25 years of experience leading the successful delivery of complex technology programs for clients in both the public- and private-sectors. He is also chair of the Technology Leadership Group for the Princes Trust, a trustee of Ada, and a Fellow of the British Computer Society. Tech Trends 2018: The symphonic enterprise 152 GLOBAL IMPACT CONTENT DEVELOPED IN COLLABORATION WITH: Maria Arroyo, Aarti Balakrishna, Redouane Bellefqih, Magda Brzezicka, Lorenzo Cerulli, Christian Combes, David Conway, Javier Corona, Heidi Custers, Eric Delgove, Freddy du Toit, Salimah Esmail, Clifford Foster, Wojciech Fraczek, Ruben Fuentes, Juan Pedro Gravel, Steve Hallam, Kim Hallenheim, Andrew Hill, Rob Hillard, Jessica Jagadesan, Jesper Kamstrup-Holm, John Karageorgiou, Andreas Klein, James Konstanczak, Karoly Kramli, Rajeev Lalwani, Patrick Laurent, Fernando Laurito, Mariadora Lepore, Michael MacNicholas, Tony Manzano, Daniel Martyniuk, Os Mata, Brad Miliken, Richard Miller, Andre Filipe Pedro, Fabio Luis Alves Pereira, Kyara Ramraj, Steve Rayment, Kathy Robins, Galit Rotstein, Goncalo Jose Santos, Rizwan Saraf, Catrina Sharpe, Paul Sin, Christophe Vallet, Andries van Dijk, Andre Vermeulen, Markku Viitanen, Gilad Wilk, Ben Wylie, and Mohamed Yusuf GLOBAL IMPACT METHODOLOGY In Q3 2017, Deloitte Consulting LLP surveyed 60 leaders at Deloitte member firms in Europe, the Middle East, Africa, Asia Pacific, and the Americas on the impact (existing and potential) of the seven trends discussed in Tech Trends 2018. Specifically, for each trend we asked them to rank their respective regions in terms of 1) relevance of the trend; 2) timeliness of each trend; and 3) readiness for the trend. We also asked each leader to provide a written perspective to support their rankings. Based on their responses, we identified 10 geographic regions in which the trends discussed in Tech Trends 2018 were either poised to advance or are already advancing: North America, South America, Northern Europe, Central Europe, Southern Europe, the Middle East, Israel, South Africa, Australia and Asia. The countries that are represented in these regions include Argentina, Australia, Belgium, Brazil, Canada, Chile, China, Czech Republic, Denmark, Finland, France, Germany, Hong Kong, India, Ireland, Israel, Italy, Japan, Latvia, Luxembourg, Mexico, Middle East, Netherlands, New Zealand, Norway, Poland, Portugal, Romania, Serbia, South Africa, Spain, Sweden, Switzerland, the United Kingdom, and the United States. We summarized respondent perspectives that applied to each of these regions. Those summary findings and regional ranking are discussed in this report and presented visually in trend-specific infographics. Authors 153 REENGINEERING TECHNOLOGY Ken Corless Cloud chief technology officer Deloitte Consulting LLP kcorless@deloitte.com Jacques de Villiers Cloud Services managing director Deloitte Consulting LLP jadevilliers@deloitte.com Chris Garibaldi Technology Strategy & Transformation principal Deloitte Consulting LLP cgaribaldi@deloitte.com Risk implications Kieran Norton Cyber Risk Services principal Deloitte & Touche LLP kinorton@deloitte.com NO-COLLAR WORKFORCE Anthony Abbatiello Human Capital Digital leader Deloitte Consulting LLP aabbatiello@deloitte.com Tim Boehm Application Management Services principal Deloitte Consulting LLP tboehm@deloitte.com Jeff Schwartz Human Capital principal Deloitte Consulting LLP jeffschwartz@deloitte.com Risk implications Sharon Chand Cyber Risk Services principal Deloitte & Touche LLP shchand@deloitte.com DIGITAL REALITY Allan Cook Operations Transformation leader Deloitte Consulting LLP allcook@deloitte.com Ryan Jones Virtual and Mixed Reality leader Deloitte Consulting LLP rcjones@deloitte.com Risk implications Ash Raghavan Deloitte Advisorys Center for Intelligent Automation & Analytics leader Deloitte & Touche LLP araghavan@deloitte.com Irfan Saif US Advisory leader, Technology Deloitte & Touche LLP isaif@deloitte.com BLOCKCHAIN TO BLOCKCHAINS Eric Piscini Global Financial Services Consulting Blockchain leader Deloitte Consulting LLP episcini@deloitte.com CHAPTER AUTHORS Tech Trends 2018: The symphonic enterprise 154 Darshini Dalal US Blockchain Lab leader Deloitte Consulting LLP ddalal@deloitte.com Risk implications David Mapgaonkar Cyber Risk Services leader Deloitte & Touche LLP dmapgaonkar@deloitte.com Prakash Santhana US Advisory managing director Deloitte Transactions and Business Analytics LLP psanthana@deloitte.com ENTERPRISE DATA SOVEREIGNTY Nitin Mittal US Analytics and Information Management leader Deloitte Consulting LLP nmittal@deloitte.com Sandeep Kumar Sharma, Ph.D. Deputy chief technology officer Deloitte Consulting LLP sandeepksharma@deloitte.com Ashish Verma Analytics and Information Management leader Deloitte Consulting LLP asverma@deloitte.com Risk implications Dan Frank US Privacy and Data Protection leader Deloitte & Touche LLP danfrank@deloitte.com API IMPERATIVE Larry Calabro Cloud Engineering leader Deloitte Consulting LLP lcalabro@deloitte.com Chris Purpura Cloud Services managing director Deloitte Consulting LLP cpurpura@deloitte.com Vishveshwara Vasa Deloitte Digital managing director Deloitte Consulting LLP vvasa@deloitte.com Risk implications Arun Perinkolam Cyber Risk Services principal Deloitte & Touche LLP aperinkolam@deloitte.com THE NEW CORE Bill Briggs Global and US chief technology officer Deloitte Consulting LLP wbriggs@deloitte.com Steven Ehrenhalt Global and US Finance Transformation principal Deloitte Consulting LLP hehrenhalt@deloitte.com Nidal Haddad Deloitte Digital chief of markets Deloitte Consulting LLP nhaddad@deloitte.com Doug Gish Supply Chain and Manufacturing Operations leader Deloitte Consulting LLP dgish@deloitte.com Adam Mussomeli Supply Chain Strategy principal Deloitte Consulting LLP amussomeli@deloitte.com Authors 155 Anton Sher Digital Finance Strategy and Transformation principal Deloitte Consulting LLP ansher@deloitte.com Risk implications Vivek Katyal Global and US Risk Analytics leader Deloitte & Touche LLP vkatyal@deloitte.com Arun Perinkolam Cyber Risk Services principal Deloitte & Touche LLP aperinkolam@deloitte.com EXPONENTIAL TECHNOLOGY WATCH LIST Mark White US Innovation Office chief technologist Deloitte Consulting LLP mawhite@deloitte.com Jeff Margolies Cyber Risk Services principal Deloitte & Touche LLP jmargolies@DELOITTE.com Rajeev Ronanki Cognitive Computing and Health Care Innovation leader Deloitte Consulting LLP rronanki@deloitte.com David Steier Deloitte Analytics managing director Deloitte Consulting LLP dsteier@deloitte.com Geoff Tuff Deloitte Digital Transformation leader Deloitte Consulting LLP gtuff@deloitte.com Ayan Bhattacharya Analytics and Information Management specialist leader Deloitte Consulting LLP aybhattacharya@deloitte.com Nipun Gupta Cyber Risk Advisory senior consultant Deloitte & Touche LLP nipgupta@deloitte.com Risk implications Irfan Saif US Advisory leader, Technology Deloitte & Touche LLP isaif@deloitte.com Tech Trends 2018: The symphonic enterprise 156 Rahul Bajpai, Charles Balders, Ranjit Bawa, William Beech, Melissa Bingham, Naaman Curtis, Traci Da- berko, Asha Dakshinamoorthy, Larry Danielson, Sukhdev Darira, Preetha Devan, Tim Dickey, Habeeb Dihu, Sean Donnelly, Tony Easterlin, Jon Eick, Nikita Garia, Ryan Gervais, Doug Gish, Lee Haverman, Erica Lee Holley, Chris Huff, Mary Hughes, Lisa Iliff, Sarah Jersild, Junko Kaji, Abrar Khan, Kim Killinger, Krishna Kumar, Sunny Mahil, Melissa Mailley, Karen Mazer, Bev McDonald, Laura McGoff, Peter Miller, Alexander Mogg, Ramani Moses, Pratyush Mulukutla, Devon Mychal, Mahima Nair, Chandra Narra, Alice Nhu, Renu Pandit, Alison Paul, Linda Pawczuk, Joanie Pearson, Alok Pepakayala, Rick Perez, Anoop R, Robert Rooks, Maximilian Schroeck, Ashley Scott, Faisal Shaikh, Alina Shapovalenko, Omer Sohail, Rithu Thomas, JT Thomson, Jonathan Trichel, and Paul Wellener LEADS Jasjit Bal, Gokul Bhaghavantha Rao, Michael Davis, Rachel Halvordson, Solomon Kassa, Alyssa Long, An- drea Reiner, and Nicholas Tawse TEAM MEMBERS Jackie Barr, Trent Beilke, Nick Boncich, Matt Butler, Sean Cremins, Jiten Dajee, Ankush Dongre, Cristin Doyle, Kevin Errico, Alex Feiszli, Inez Foong, Rob Garrett, Amy Golem, Sam Greenlief, Grace Ha, Dylan Hooe, Syed Jehangir, Yili Jiang, Nandita Karambelkar, Ava Kong, Kaitlyn Kuczer, Varun Kumar, Kartikeya Kumar, Andrew Lee, Anthony Lim, Luke Liu, Andrea Lora, Betsy Lukins, Lea Ann Mawler, Joe McAsey, Robert Miller, Talia OBrien, Deepak Padmanabhan, Sarita Patankar, Ellie Peck, Gilberto Rodriguez, Ka- trina Rudisel, Cabell Spicer, Jordan Stone, Jenna Swinney, Elizabeth Thompson, Casey Volanth, Greg Wal- drip, Myette Ware, Michelle Young, and Chris Yun CONTRIBUTORS RESEARCH TEAM Contributors and research team 157 Mariahna Moore for leading the charge and bringing your inimitable spark to Tech Trends. Amazing job building out the core team around you, setting (and exceeding) standards of excellence, while driving toward (and meeting!) what seemed like impossible deadlines. Heres to a holiday season focused on family instead of risk reviews and launch plans. Doug McWhirter for your mastery of form and function, making good on our promise to spin brilliant prose from armies of researchers, torrents of interviews, and galleries of SMEs. Tech Trends 2018 quite simply wouldnt have happened without your pen, your editorial beacon, and your perseverance. Liz Mackey for stepping into the Tech Trends fire and blowing us all away. You took the day-to-day helm and delivered in every imaginable waywith calm, patience, grace, and the right amount of tireless de- termination to keep the ship steady through the inevitable fire drills. Dana Kublin for continued singular brilliance, leading all things creativethe theme, artwork, layout, in- fographics, motion graphics, and more. Beyond your vision and artistry, your leadership and teamwork are indispensable to not just Tech Trends but the broader OCTO. Patricia Staino for making a huge impact, adding your talents with the written word to content through- out the research, spinning blindingly insightful prose across chapters, lessons, My Takes, and more. Chuck Stern for upping our marketing game, doing an excellent job with our launch planning and our broader marketing mission. While providing a much needed outside-in lens to the insanity of our ninth year Tech Trend-ing. Tracey Parry for doing an incredible job filling big shoes around external communications and PR. You brought an amazing spark to the team, while delivering above and beyond (amidst adjusting to the chaos). Youll definitely be missed, but good luck on the adventures to come. Maria Gutierrez as you jump back into the fray with the newest member of the OCTO family, bringing your talents to not just Tech Trends but our broader Signature Issue positioning. Were thrilled to have you back and cant wait to see where you take us in the new role. Stefanie Heng for jumping in wherever you could helpwriting, designing, shaping, and improving our content and the app. And for being the engine behind our client and market engagement around all things Tech Trendsnavigating through the strategic and the underlying details without missing a beat. Melissa Doody for expanding your role and impact, making your mark across creative and design. Look- ing forward to seeing your influence grow as you become a seasoned Tech Trends veteran. SPECIAL THANKS Tech Trends 2018: The symphonic enterprise 158 Deniz Oker and Nick Patton for the tremendous impact made in your inaugural Tech Trends effort helping coordinate research, and diving in to help wherever needed. Thanks for everything you did to make Tech Trends 2018 our best one yet. Mitch Derman for your great help with everything from internal communications to our latest round of Five Minutes On videos. Matthew Budman, Troy Bishop, Kevin Weier, Amy Bergstrom, and the tremendous Deloitte Insights team. Tech Trends wouldnt happen without your collaboration, your editorial brilliance, and your sup- port. You help us raise the bar every year; more importantly, youre a huge part of how we exceed those expectations. Special thanks 159 About Deloitte Insights Deloitte Insights publishes original articles, reports and periodicals that provide insights for businesses, the public sector and NGOs. Our goal is to draw upon research and experience from throughout our professional services organization, and that of coauthors in academia and business, to advance the conversation on a broad spectrum of topics of interest to executives and government leaders. Deloitte Insights is an imprint of Deloitte Development LLC. About this publication This publication contains general information only, and none of Deloitte Touche Tohmatsu Limited, its member firms, or its and their affiliates are, by means of this publication, rendering accounting, business, financial, investment, legal, tax, or other professional advice or services. This publication is not a substitute for such professional advice or services, nor should it be used as a basis for any decision or action that may affect your finances or your business. Before making any decision or taking any action that may affect your finances or your business, you should consult a qualified professional adviser. None of Deloitte Touche Tohmatsu Limited, its member firms, or its and their respective affiliates shall be responsible for any loss whatsoever sustained by any person who relies on this publication. About Deloitte Deloitte refers to one or more of Deloitte Touche Tohmatsu Limited, a UK private company limited by guarantee (DTTL), its network of member firms, and their related entities. DTTL and each of its member firms are legally separate and independent entities. DTTL (also referred to as Deloitte Global) does not provide services to clients. In the United States, Deloitte refers to one or more of the US member firms of DTTL, their related entities that operate using the Deloitte name in the United States and their respective affiliates. Certain services may not be available to attest clients under the rules and regulations of public accounting. Please see www.deloitte.com/about to learn more about our global network of member firms. Copyright  2017 Deloitte Development LLC. All rights reserved. Member of Deloitte Touche Tohmatsu Limited Sign up for Deloitte Insights updates at www.deloitte.com/insights. Follow @DeloitteInsight Follow @DeloitteOnTech dupress.deloitte.com/tech-trends